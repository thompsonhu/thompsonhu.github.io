<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bonbon Blog on Bonbon Blog</title>
    <link>/</link>
    <description>Recent content in Bonbon Blog on Bonbon Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>入门TeXLive&#43;TeXStudio</title>
      <link>/post/%E5%85%A5%E9%97%A8texlive-texstudio/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%85%A5%E9%97%A8texlive-texstudio/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;https://liam.page/&#34;&gt;Liam Huang&lt;/a&gt;曾说过：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;选择TeX Live，选择简单的人生；&lt;br /&gt;
选择MiKTeX，选择麻烦的人生；&lt;br /&gt;
选择CTeX套装，选择崩溃的人生。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;意外重新接触LaTeX之后，发现CTeX确实是个麻烦事。最开始接触LaTeX，就不断被LaTeX各种问题绊倒，可以说相当厌恶了╮(๑•́ ₃•̀๑)╭还好有友好的Markdown语法~&lt;/p&gt;
&lt;p&gt;删掉自己电脑中的CTeX套装，实践记录下如何开始TexLive+TexStudio的完美生活(*•̀ㅂ•́)و&lt;/p&gt;
&lt;div id=&#34;texlive-2018&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;安装TeXLive 2018&lt;/h2&gt;
&lt;p&gt;TeXLive的官网是&lt;a href=&#34;https://tug.org/texlive/&#34; class=&#34;uri&#34;&gt;https://tug.org/texlive/&lt;/a&gt;，按指引也可以完成下载；但我觉得用中国科技大学的镜像站会比较方便高效~所以从中科大这边下载： &lt;a href=&#34;https://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/texlive2018.iso&#34; class=&#34;uri&#34;&gt;https://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/texlive2018.iso&lt;/a&gt;&lt;/p&gt;
整个文件3.2GB还是相当大~完成下载后，以管理员身份运行&lt;strong&gt;install-tl-advanced.bat&lt;/strong&gt;，然后点击&lt;strong&gt;continue&lt;/strong&gt;（如图1所示），随后点击&lt;strong&gt;安装TeXLive&lt;/strong&gt;即可。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TEX1.PNG&#34; width = &#34;600&#34; height = &#34;600&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. 安装TeXLive页面
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;texstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;安装TexStudio&lt;/h2&gt;
&lt;p&gt;安装完TexLive后，可以说完成百分之80的工作了，TexStudio的安装相比前面的快很多（因为只有74.1MB(..•˘_˘•..)）。&lt;/p&gt;
&lt;p&gt;TexStudio的官网网址是： &lt;a href=&#34;http://texstudio.sourceforge.net/&#34; class=&#34;uri&#34;&gt;http://texstudio.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;点击网址打开后，对于Windows平台的，点击&lt;strong&gt;Download now&lt;/strong&gt;下载即可。&lt;/p&gt;
&lt;p&gt;两个安装后，就完成啦！ฅ(๑˙o˙๑)ฅ&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>卷积神经网络 Convolutional Neural Networks</title>
      <link>/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/</guid>
      <description>


&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;p&gt;Convolutional Neural Networks的中文名叫卷积神经网络，当然英文简称直接为CNN，它的创始人是著名的计算机科学家&lt;a href=&#34;http://yann.lecun.com/&#34;&gt;Yann LeCun&lt;/a&gt;，CNN和RNN（Recurrent Neural Networks）可以说是深度学习领域最常提及的两种网络模型。本篇博客参照知乎上问题&lt;a href=&#34;https://www.zhihu.com/question/52668301&#34;&gt;“CNN(卷积神经网络)是什么？有入门简介或文章吗？”&lt;/a&gt;的回答来进行介绍~&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;convolutional-neural-networks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convolutional Neural Networks开始正文！&lt;/h2&gt;
&lt;div id=&#34;cnn&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;CNN的“卷积”介绍&lt;/h3&gt;
&lt;p&gt;我们假设神经网络的输入是一张彩色的图像，那通常我们输入的是&lt;span class=&#34;math inline&#34;&gt;\(n\times m\times 3\)&lt;/span&gt;的RGB图像，下面图中是&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\times 3\)&lt;/span&gt;RGB图像的示例；其中的数字代表着图片的原始像素值。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CNN1.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. &lt;span class=&#34;math inline&#34;&gt;\(4\times 4\times 3\)&lt;/span&gt;RGB图像
&lt;/div&gt;
&lt;p&gt;卷积核是CNN的一个重要部分，卷积则是CNN的一个重要步骤。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，假设我们选取的卷积核为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 1 &amp;amp; 0\\
1 &amp;amp; 0 &amp;amp; 1
\end{vmatrix}
\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们会从原始图像的左上角开始，选取和卷积核大小相同的区域。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过水平和垂直移动不断获得新的区域，我们假设移动的步长为1，重复上面的步骤，我们可以一个新的矩阵 &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
4 &amp;amp; 3 &amp;amp; 4\\
2 &amp;amp; 4 &amp;amp; 3\\
2 &amp;amp; 3 &amp;amp; 4
\end{vmatrix}
\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CNN2.gif&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
图2. 卷积过程示例
&lt;/div&gt;
&lt;p&gt;由此，一个&lt;span class=&#34;math inline&#34;&gt;\(5\times 5\)&lt;/span&gt;的图像矩阵经过卷积得到了一个&lt;span class=&#34;math inline&#34;&gt;\(3\times 3\)&lt;/span&gt;的矩阵，生成的这个矩阵我们称为Convolved Feature或Feature Map。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有时候为了不让新生成的图片缩小，可以给原始的图像进行0元素的填充（padding）。&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CNN3.PNG&#34; width = &#34;200&#34; height = &#34;200&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
图3. 填充（padding）示意图
&lt;/div&gt;
&lt;p&gt;如图所示，原来的&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\)&lt;/span&gt;矩阵如果通过&lt;span class=&#34;math inline&#34;&gt;\(3\times 3\)&lt;/span&gt;的卷积核处理会得到&lt;span class=&#34;math inline&#34;&gt;\(2\times 2\)&lt;/span&gt;的Convolved Feature，但是在周围加一圈0元素，从&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\)&lt;/span&gt;矩阵扩充到&lt;span class=&#34;math inline&#34;&gt;\(5\times 5\)&lt;/span&gt;的矩阵的话，经过&lt;span class=&#34;math inline&#34;&gt;\(3\times 3\)&lt;/span&gt;的卷积核处理会得到&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\)&lt;/span&gt;的Convolved Feature。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cnn&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;CNN的“池化”介绍&lt;/h3&gt;
&lt;p&gt;池化（pooling）实际上是对上个操作（卷积）得到的Convolved Feature进行降维，池化有很多方法（比如取最大值，求平均，求和等等），但常用的方法有“最大池化”（池化区域内所有值的平均值作为池化结果）和“平均池化”（池化区域内所有值的最大值作为池化结果）这两种。&lt;/p&gt;
&lt;p&gt;池化的具体操作是让一个池化窗口在图片上移动，每次取窗口内的平均值或者最大值；窗口的水平和垂直移动，它移动步长取窗口本身的大小；下图是最大池化的示意图。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CNN4.PNG&#34; width = &#34;400&#34; height = &#34;400&#34; alt=&#34;Figure4&#34; /&gt;
&lt;p&gt;
图4. 最大池化示意图
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;为什么要池化层？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设输入了一张&lt;span class=&#34;math inline&#34;&gt;\(1000\times 1000\)&lt;/span&gt;的图像，我们采用100个卷积核进行提取不同的特征，其中卷积核大小为&lt;span class=&#34;math inline&#34;&gt;\(3\times 3\)&lt;/span&gt;，卷积核在原图像上移动的步长为1；若不考虑填充（padding），那么我们会得到一个&lt;span class=&#34;math inline&#34;&gt;\(998\times 998=996004\)&lt;/span&gt;的Convolved feature，那100个卷积核便会得到100个996004大小的Convolved feature；所以，一张图片最终会得到一个&lt;span class=&#34;math inline&#34;&gt;\(996004\times 100\)&lt;/span&gt;的卷积特征向量。这样上千万个特征进行图片的分类，很容易造成过拟合（overfitting）。&lt;/p&gt;
&lt;p&gt;由于图像具有空间相关性，即一个像素点和它周围的像素点在很大概率上是相似的。通过相邻的像素点进行合并（即池化），可以缩小最后得到的特征数量。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;反向传播和参数更新&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;CNN&lt;/strong&gt;的训练过程和&lt;strong&gt;全连接网络&lt;/strong&gt;的训练过程比较类似，都是先将参数随机初始化，再进行前向计算；得到最后的输出结果之后，再计算最后一层每个神经元的残差；通过&lt;strong&gt;反向传播&lt;/strong&gt;方法，可以得到所有节点的残差和损失函数对所有参数的偏导数；最后对参数进行更新。两者的架构区别主要在于卷积层和池化层。&lt;/p&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;卷积层的反向传播&lt;/h4&gt;
&lt;p&gt;我们先定义，&lt;/p&gt;
&lt;p&gt;卷积之前的矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
x_{00} &amp;amp; x_{01} &amp;amp; x_{02}\\
x_{10} &amp;amp; x_{11} &amp;amp; x_{12}\\
x_{20} &amp;amp; x_{21} &amp;amp; x_{22}
\end{vmatrix}
\]&lt;/span&gt; 卷积核的矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
k_{00} &amp;amp; k_{01}\\
k_{10} &amp;amp; k_{11}
\end{vmatrix}
\]&lt;/span&gt; 卷积之后的矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
y_{00} &amp;amp; y_{01}\\
y_{10} &amp;amp; y_{11}
\end{vmatrix}
\]&lt;/span&gt; 卷积之后的残差矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
\delta^{l+1}_{00} &amp;amp; \delta^{l+1}_{01}\\
\delta^{l+1}_{10} &amp;amp; \delta^{l+1}_{11}
\end{vmatrix}
\]&lt;/span&gt; 卷积之前的残差矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
\delta^l_{00} &amp;amp; \delta^l_{01} &amp;amp; \delta^l_{02}\\
\delta^l_{10} &amp;amp; \delta^l_{11} &amp;amp; \delta^l_{12}\\
\delta^l_{20} &amp;amp; \delta^l_{21} &amp;amp; \delta^l_{22}
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们在前向计算中，卷积操作的计算过程如下： &lt;span class=&#34;math display&#34;&gt;\[
y_{00} = x_{00}\times k_{00} + x_{01}\times k_{01} + x_{10}\times k_{10} + x_{11}\times k_{11}\\
y_{01} = x_{01}\times k_{00} + x_{02}\times k_{01} + x_{11}\times k_{10} + x_{12}\times k_{11}\\
y_{10} = x_{10}\times k_{00} + x_{11}\times k_{01} + x_{20}\times k_{10} + x_{21}\times k_{11}\\
y_{11} = x_{11}\times k_{00} + x_{12}\times k_{01} + x_{21}\times k_{10} + x_{22}\times k_{11}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;又卷积之后的残差可以由反向传播计算得到，我们可以得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta^l_{00} &amp;amp;= \frac{\partial L}{\partial x_{00}} = \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial x_{00}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times k_{00}\\
\delta^l_{01} &amp;amp;= \frac{\partial L}{\partial x_{01}} = \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial x_{01}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial x_{01}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times k_{01} + \delta^{l+1}_{01}\times k_{00}\\
\delta^l_{02} &amp;amp;= \frac{\partial L}{\partial x_{02}} = \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial x_{02}}\\
&amp;amp;=\ \delta^{l+1}_{01}\times k_{01}\\
\delta^l_{10} &amp;amp;= \frac{\partial L}{\partial x_{10}} = \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial x_{10}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial x_{10}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times k_{10} + \delta^{l+1}_{10}\times k_{00}\\
\delta^l_{11} &amp;amp;= \frac{\partial L}{\partial x_{11}} = \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial x_{11}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial x_{11}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial x_{11}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial x_{11}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times k_{11} + \delta^{l+1}_{01}\times k_{10} + \delta^{l+1}_{10}\times k_{01} + \delta^{l+1}_{11}\times k_{00}\\
\delta^l_{12} &amp;amp;= \frac{\partial L}{\partial x_{12}} = \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial x_{12}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial x_{12}}\\
&amp;amp;=\ \delta^{l+1}_{01}\times k_{11} + \delta^{l+1}_{11}\times k_{01}\\
\delta^l_{20} &amp;amp;= \frac{\partial L}{\partial x_{20}} = \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial x_{20}}\\
&amp;amp;=\ \delta^{l+1}_{10}\times k_{10}\\
\delta^l_{21} &amp;amp;= \frac{\partial L}{\partial x_{21}} = \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial x_{21}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial x_{21}}\\
&amp;amp;=\ \delta^{l+1}_{10}\times k_{11} + \delta^{l+1}_{11}\times k_{10}\\
\delta^l_{22} &amp;amp;= \frac{\partial L}{\partial x_{22}} = \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial x_{22}}\\
&amp;amp;=\ \delta^{l+1}_{11}\times k_{11}
\end{align}
\]&lt;/span&gt; 通过上述等式，我们可以将残差通过卷积层反向得到上一层的残差，接下来通过残差推导损失函数对卷积核中参数的偏导数。 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\frac{\partial L}{\partial k_{00}} &amp;amp;= \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial k_{00}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial k_{00}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial k_{00}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial k_{00}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times x_{00} + \delta^{l+1}_{01}\times x_{01} + \delta^{l+1}_{10}\times x_{10} + \delta^{l+1}_{11}\times x_{11}\\
\frac{\partial L}{\partial k_{01}} &amp;amp;= \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial k_{01}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial k_{01}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial k_{01}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial k_{01}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times x_{01} + \delta^{l+1}_{02}\times x_{01} + \delta^{l+1}_{10}\times x_{11} + \delta^{l+1}_{11}\times x_{12}\\
\frac{\partial L}{\partial k_{10}} &amp;amp;= \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial k_{10}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial k_{10}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial k_{10}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial k_{10}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times x_{010} + \delta^{l+1}_{01}\times x_{11} + \delta^{l+1}_{10}\times x_{20} + \delta^{l+1}_{11}\times x_{21}\\
\frac{\partial L}{\partial k_{11}} &amp;amp;= \frac{\partial L}{\partial y_{00}}\times \frac{\partial y_{00}}{\partial k_{11}} + \frac{\partial L}{\partial y_{01}}\times \frac{\partial y_{01}}{\partial k_{11}} + \frac{\partial L}{\partial y_{10}}\times \frac{\partial y_{10}}{\partial k_{11}} + \frac{\partial L}{\partial y_{11}}\times \frac{\partial y_{11}}{\partial k_{11}}\\
&amp;amp;=\ \delta^{l+1}_{00}\times x_{11} + \delta^{l+1}_{01}\times x_{12} + \delta^{l+1}_{10}\times x_{21} + \delta^{l+1}_{11}\times x_{22}\\
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;举个实例体会下！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;输入的数据是&lt;span class=&#34;math inline&#34;&gt;\(3\times 3\)&lt;/span&gt;的矩阵： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 2 &amp;amp; 1\\
3 &amp;amp; 2 &amp;amp; 1\\
2 &amp;amp; 1 &amp;amp; 1
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假设有两个卷积核分别为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
0.1 &amp;amp; 0.2\\
0.2 &amp;amp; 0.4
\end{vmatrix}
和
\begin{vmatrix}
-0.3 &amp;amp; 0.1\\
0.1 &amp;amp; 0.2
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假设经过两个卷积核卷积之后的残差值分别为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 3\\
2 &amp;amp; 2
\end{vmatrix}
和
\begin{vmatrix}
2 &amp;amp; 1\\
1 &amp;amp; 1
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么，第一个卷积核卷积之前各个节点的残差为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta^l_{00} &amp;amp;= \delta^{l+1}_{00}\times k_{00}\\
&amp;amp;=\ 1\times 0.1 = 0.1\\
\delta^l_{01} &amp;amp;= \delta^{l+1}_{00}\times k_{01} + \delta^{l+1}_{01}\times k_{00}\\
&amp;amp;=\ 1\times 0.2 + 3\times  0.1 = 0.5\\
\delta^l_{02} &amp;amp;= \delta^{l+1}_{01}\times k_{01}\\
&amp;amp;=\ 3\times 0.2 = 0.6\\
\delta^l_{10} &amp;amp;= \delta^{l+1}_{00}\times k_{10} + \delta^{l+1}_{10}\times k_{00}\\
&amp;amp;=\ 1\times 0.2 + 2\times 0.1 = 0.4\\
\delta^l_{11} &amp;amp;= \delta^{l+1}_{00}\times k_{11} + \delta^{l+1}_{01}\times k_{10} + \delta^{l+1}_{10}\times k_{01} + \delta^{l+1}_{11}\times k_{00}\\
&amp;amp;=\ 1\times 0.4 + 3\times 0.2 + 2\times 0.2 + 2\times 0.1 = 1.6\\
\delta^l_{12} &amp;amp;= \delta^{l+1}_{01}\times k_{11} + \delta^{l+1}_{11}\times k_{01}\\
&amp;amp;=\ 3\times 0.4 + 2\times 0.2 = 1.6\\
\delta^l_{20} &amp;amp;= \delta^{l+1}_{10}\times k_{10}\\
&amp;amp;=\ 2\times 0.2 = 0.4\\
\delta^l_{21} &amp;amp;= \delta^{l+1}_{10}\times k_{11} + \delta^{l+1}_{11}\times k_{10}\\
&amp;amp;=\ 2\times 0.4 + 2\times 0.2 = 1.2\\
\delta^l_{22} &amp;amp;= \delta^{l+1}_{11}\times k_{11}\\
&amp;amp;=\ 2\times 0.4 = 0.8
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;即第一个卷积核反向传播计算过程中卷积之前的残差为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
0.1 &amp;amp; 0.5 &amp;amp; 0.6\\
0.4 &amp;amp; 1.6 &amp;amp; 1.6\\
0.4 &amp;amp; 1.2 &amp;amp; 0.8
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理可以得到第二个卷积核反向传播计算过程中卷积之前的残差为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
-0.6 &amp;amp; -0.1 &amp;amp; 0.1\\
-0.1 &amp;amp; 0.3 &amp;amp; 0.3\\
0.1 &amp;amp; 0.3 &amp;amp; 0.2
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对于第一个卷积核，通过上面推导的公式可以计算： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\frac{\partial L}{\partial k_{00}} &amp;amp;= \delta^{l+1}_{00}\times x_{00} + \delta^{l+1}_{01}\times x_{01} + \delta^{l+1}_{10}\times x_{10} + \delta^{l+1}_{11}\times x_{11}\\
&amp;amp;=\ 1\times 1 + 3\times 2 + 2\times 3 + 2\times 2 = 17\\
\frac{\partial L}{\partial k_{01}} &amp;amp;= \delta^{l+1}_{00}\times x_{01} + \delta^{l+1}_{02}\times x_{01} + \delta^{l+1}_{10}\times x_{11} + \delta^{l+1}_{11}\times x_{12}\\
&amp;amp;=\ 1\times 2 + 3\times 1 + 2\times 2 + 2\times 1 = 11\\
\frac{\partial L}{\partial k_{10}} &amp;amp;= \delta^{l+1}_{00}\times x_{010} + \delta^{l+1}_{01}\times x_{11} + \delta^{l+1}_{10}\times x_{20} + \delta^{l+1}_{11}\times x_{21}\\
&amp;amp;=\ 1\times 3 + 3\times 2 + 2\times 2 + 2\times 1 = 15\\
\frac{\partial L}{\partial k_{11}} &amp;amp;= \delta^{l+1}_{00}\times x_{11} + \delta^{l+1}_{01}\times x_{12} + \delta^{l+1}_{10}\times x_{21} + \delta^{l+1}_{11}\times x_{22}\\
&amp;amp;=\ 1\times 2 + 3\times 1 + 2\times 1 + 2\times 1 = 9
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;则第一个卷积核的更新计算为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
k&amp;#39;_{00} &amp;amp; k&amp;#39;_{01}\\
k&amp;#39;_{10} &amp;amp; k&amp;#39;_{11}
\end{vmatrix}
=
\begin{vmatrix}
0.1 &amp;amp; 0.2\\
0.2 &amp;amp; 0.4
\end{vmatrix}
-\alpha\times 
\begin{vmatrix}
17 &amp;amp; 11\\
15 &amp;amp; 9
\end{vmatrix}
\]&lt;/span&gt; 其中&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;为学习率，&lt;span class=&#34;math inline&#34;&gt;\(k&amp;#39;_{ij}\)&lt;/span&gt;为更新之后的第一个卷积核的参数。同理，可更新第二个卷积核的参数&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level4&#34;&gt;
&lt;h4&gt;池化层的反向传播&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;平均池化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设输入的是一个&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\)&lt;/span&gt;的矩阵，池化区域是&lt;span class=&#34;math inline&#34;&gt;\(2\times 2\)&lt;/span&gt;的矩阵，经过池化后得到的是&lt;span class=&#34;math inline&#34;&gt;\(2\times 2\)&lt;/span&gt;的矩阵。我们假设在反向传播计算过程中，最后一层4个节点的残差值为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 3\\
2 &amp;amp; 4
\end{vmatrix}
\]&lt;/span&gt; 那么由于一个节点对应池化之前的4个节点，同时需要满足反向传播过程中各层的残差总和不变，所以池化之前的神经元的残差值是池化之后的残差值得平均；在这个例子中，池化之前&lt;span class=&#34;math inline&#34;&gt;\(4\times 4\)&lt;/span&gt;的神经元的残差值为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
0.25 &amp;amp; 0.25 &amp;amp; 0.75 &amp;amp; 0.75\\
0.25 &amp;amp; 0.25 &amp;amp; 0.75 &amp;amp; 0.75\\
0.5 &amp;amp; 0.5 &amp;amp; 1 &amp;amp; 1\\
0.5 &amp;amp; 0.5 &amp;amp; 1 &amp;amp; 1
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大池化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这里也用和&lt;strong&gt;平均池化&lt;/strong&gt;一样的例子，我们假设在反向传播计算过程中，最后一层4个节点的残差值为： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 3\\
2 &amp;amp; 4
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;最大池化在前向计算的过程中，需要记录被池化的&lt;span class=&#34;math inline&#34;&gt;\(2\times 2\)&lt;/span&gt;区域中哪个位置被选取（即最大值），我们假设被选中的最大值所在的位置就是下面星星所在位置： &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
* &amp;amp; - &amp;amp; - &amp;amp; -\\
- &amp;amp; - &amp;amp; * &amp;amp; -\\
- &amp;amp; - &amp;amp; - &amp;amp; *\\
- &amp;amp; * &amp;amp; - &amp;amp; -
\end{vmatrix}
\]&lt;/span&gt; 在反向传播中，将残差直接给上述星星位置，其他位置则赋为0，即 &lt;span class=&#34;math display&#34;&gt;\[
\begin{vmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 2 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 4\\
0 &amp;amp; 3 &amp;amp; 0 &amp;amp; 0
\end{vmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;代码与实现&lt;/h3&gt;
&lt;p&gt;在知乎&lt;a href=&#34;https://www.zhihu.com/question/52668301&#34;&gt;“CNN(卷积神经网络)是什么？有入门简介或文章吗？”&lt;/a&gt;这个问题上，&lt;a href=&#34;https://www.zhihu.com/question/52668301/answer/536176496&#34;&gt;“阿里云云栖社区”&lt;/a&gt;在它的答案中给出了CNN实现的代码ヾ(&lt;em&gt;´▽‘&lt;/em&gt;)ﾉ&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Import the deep learning library
import tensorflow as tf
import time
# Import the MNIST dataset
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&amp;quot;/tmp/data/&amp;quot;, one_hot=True)
# Network inputs and outputs
# The network&amp;#39;s input is a 28×28 dimensional input
n = 28
m = 28
num_input = n * m # MNIST data input 
num_classes = 10 # MNIST total classes (0-9 digits)
# tf Graph input
X = tf.placeholder(tf.float32, [None, num_input])
Y = tf.placeholder(tf.float32, [None, num_classes])
# Storing the parameters of our LeNET-5 inspired Convolutional Neural Network
weights = {
   &amp;quot;W_ij&amp;quot;: tf.Variable(tf.random_normal([5, 5, 1, 32])),
   &amp;quot;W_jk&amp;quot;: tf.Variable(tf.random_normal([5, 5, 32, 64])),
   &amp;quot;W_kl&amp;quot;: tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),
   &amp;quot;W_lm&amp;quot;: tf.Variable(tf.random_normal([1024, num_classes]))
    }
biases = {
   &amp;quot;b_ij&amp;quot;: tf.Variable(tf.random_normal([32])),
   &amp;quot;b_jk&amp;quot;: tf.Variable(tf.random_normal([64])),
   &amp;quot;b_kl&amp;quot;: tf.Variable(tf.random_normal([1024])),
   &amp;quot;b_lm&amp;quot;: tf.Variable(tf.random_normal([num_classes]))
    }
# The hyper-parameters of our Convolutional Neural Network
learning_rate = 1e-3
num_steps = 500
batch_size = 128
display_step = 10
def ConvolutionLayer(x, W, b, strides=1):
    # Convolution Layer
    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=&amp;#39;SAME&amp;#39;)
    x = tf.nn.bias_add(x, b)
    return x
def ReLU(x):
    # ReLU activation function
    return tf.nn.relu(x)
def PoolingLayer(x, k=2, strides=2):
    # Max Pooling layer
    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1],
                          padding=&amp;#39;SAME&amp;#39;)
def Softmax(x):
    # Softmax activation function for the CNN&amp;#39;s final output
    return tf.nn.softmax(x)
# Create model
def ConvolutionalNeuralNetwork(x, weights, biases):
    # MNIST data input is a 1-D row vector of 784 features (28×28 pixels)
    # Reshape to match picture format [Height x Width x Channel]
    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]
    x = tf.reshape(x, shape=[-1, 28, 28, 1])
    # Convolution Layer
    Conv1 = ConvolutionLayer(x, weights[&amp;quot;W_ij&amp;quot;], biases[&amp;quot;b_ij&amp;quot;])
    # Non-Linearity
    ReLU1 = ReLU(Conv1)
    # Max Pooling (down-sampling)
    Pool1 = PoolingLayer(ReLU1, k=2)
    # Convolution Layer
    Conv2 = ConvolutionLayer(Pool1, weights[&amp;quot;W_jk&amp;quot;], biases[&amp;quot;b_jk&amp;quot;])
    # Non-Linearity
    ReLU2 = ReLU(Conv2)
    # Max Pooling (down-sampling)
    Pool2 = PoolingLayer(ReLU2, k=2)
    # Fully connected layer
    # Reshape conv2 output to fit fully connected layer input
    FC = tf.reshape(Pool2, [-1, weights[&amp;quot;W_kl&amp;quot;].get_shape().as_list()[0]])
    FC = tf.add(tf.matmul(FC, weights[&amp;quot;W_kl&amp;quot;]), biases[&amp;quot;b_kl&amp;quot;])
    FC = ReLU(FC)
    # Output, class prediction
    output = tf.add(tf.matmul(FC, weights[&amp;quot;W_lm&amp;quot;]), biases[&amp;quot;b_lm&amp;quot;])
    return output
# Construct model
logits = ConvolutionalNeuralNetwork(X, weights, biases)
prediction = Softmax(logits)
# Softamx cross entropy loss function
loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
    logits=logits, labels=Y))
# Optimization using the Adam Gradient Descent optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_process = optimizer.minimize(loss_function)
# Evaluate model
correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
# recording how the loss functio varies over time during training
cost = tf.summary.scalar(&amp;quot;cost&amp;quot;, loss_function)
training_accuracy = tf.summary.scalar(&amp;quot;accuracy&amp;quot;, accuracy)
train_summary_op = tf.summary.merge([cost,training_accuracy])
train_writer = tf.summary.FileWriter(&amp;quot;./Desktop/logs&amp;quot;,
                                        graph=tf.get_default_graph())
# Initialize the variables (i.e. assign their default value)
init = tf.global_variables_initializer()
# Start training
with tf.Session() as sess:
    # Run the initializer
    sess.run(init)
    start_time = time.time()
    for step in range(1, num_steps+1):
        batch_x, batch_y = mnist.train.next_batch(batch_size)
        # Run optimization op (backprop)
        sess.run(training_process, feed_dict={X: batch_x, Y: batch_y})
        if step % display_step == 0 or step == 1:
            # Calculate batch loss and accuracy
            loss, acc, summary = sess.run([loss_function, accuracy, train_summary_op], feed_dict={X: batch_x,
                                                                 Y: batch_y})
            train_writer.add_summary(summary, step)
            print(&amp;quot;Step &amp;quot; + str(step) + &amp;quot;, Minibatch Loss= &amp;quot; + \
                  &amp;quot;{:.4f}&amp;quot;.format(loss) + &amp;quot;, Training Accuracy= &amp;quot; + \
                  &amp;quot;{:.3f}&amp;quot;.format(acc))
    end_time = time.time() 
    print(&amp;quot;Time duration: &amp;quot; + str(int(end_time-start_time)) + &amp;quot; seconds&amp;quot;)
    print(&amp;quot;Optimization Finished!&amp;quot;)
    # Calculate accuracy for 256 MNIST test images
    print(&amp;quot;Testing Accuracy:&amp;quot;, \
        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],
                                      Y: mnist.test.labels[:256]}))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reference&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/52668301&#34;&gt;知乎. CNN(卷积神经网络)是什么？有入门简介或文章吗？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;罗冬日. Tensorflow入门与实战&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>生成对抗网络的第二Part</title>
      <link>/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%BA%8Cpart/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%BA%8Cpart/</guid>
      <description>


&lt;p&gt;我们认为每张图片对应的是一个高维向量，我们希望能找出这一类图片所在的图像空间的分布&lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;，GAN的目的其实就是在寻找这个分布&lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;传统的方法我们会想到用最大似然估计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;首先给定一些样本数据，可以得到它的分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;；接着我们假定有一个由参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;决定的分布&lt;span class=&#34;math inline&#34;&gt;\(P_G(x;\theta)\)&lt;/span&gt;；我们希望能够找到&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，满足分布&lt;span class=&#34;math inline&#34;&gt;\(P_G(x;\theta)\)&lt;/span&gt;尽可能靠近分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;；假设&lt;span class=&#34;math inline&#34;&gt;\(P_G(x;\theta)\)&lt;/span&gt;是高斯分布（正态分布），那&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;就是均值和方差。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;中进行抽样获得一组样本数据&lt;span class=&#34;math inline&#34;&gt;\(\{x_1,x_2,\dots,x_m\}\)&lt;/span&gt;，我们可以得到似然值的表达式 &lt;span class=&#34;math display&#34;&gt;\[L = \prod_{i=1}^{m} P_G(x^i;\theta)\]&lt;/span&gt;我们希望能够找到&lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;能够使得似然值&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;最大。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;kl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;最大似然估计与最小KL散度的等价性&lt;/h2&gt;
&lt;p&gt;通过对&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;取对数，我们可以得到对数似然值，同时&lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;可以通过下式得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\theta^* &amp;amp;=\ \arg \max_{\theta} \log L\\ 
&amp;amp;=\ \arg \max_{\theta} \log \prod_{i=1}^{m} P_G(x^i;\theta)\\
&amp;amp;=\ \arg \max_{\theta} \sum_{i=1}^m \log P_G(x^i;\theta)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于样本&lt;span class=&#34;math inline&#34;&gt;\(\{x^1,x^2,\dots,x^m\}\)&lt;/span&gt;是随机抽取来自于分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;，上式可以近似求&lt;span class=&#34;math inline&#34;&gt;\(\log P_G(x;\theta)\)&lt;/span&gt;的期望的最大点，可以表示为 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\theta^* &amp;amp;\approx\ \arg \max_{\theta} E_{x\sim P_{data}}[\log P_G(x;\theta)]\\
&amp;amp;=\ \arg \max_{\theta} \int\limits_x P_{data}(x) \log P_G(x;\theta) dx
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从式子中知道，我们所求的&lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;只跟分布&lt;span class=&#34;math inline&#34;&gt;\(P_G(x;\theta)\)&lt;/span&gt;相关，我们可以在后面加上一项&lt;span class=&#34;math inline&#34;&gt;\(-\int\limits_x P_{data}(x) \log P_{data}(x)dx\)&lt;/span&gt;，这不影响求最大化下对应得&lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;，那么由上式就可以得到 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\theta^* &amp;amp;\approx\ \arg \max_{\theta} \int\limits_x P_{data}(x) \log P_G(x;\theta) dx - \int\limits_x P_{data}(x) \log P_{data}(x)dx\\
&amp;amp;=\ \arg \max_{\theta} \int\limits_x P_{data}(x) \Big[\log P_G(x;\theta) - \log P_{data}(x)\Big] dx\\
&amp;amp;=\ \arg \min_{\theta} \int\limits_x P_{data}(x) \Big[\log P_{data}(x) - \log P_G(x;\theta)\Big] dx\\
&amp;amp;=\ \arg \min_{\theta} \int\limits_x P_{data}(x) \log \frac{P_{data}(x)}{P_G(x;\theta)} dx\\
&amp;amp;=\ \arg \min_{\theta} KL(P_{data}||P_G)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从上述推导可以发现&lt;strong&gt;最大似然估计实际上等价于最小化KL散度&lt;/strong&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generatorp_g&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;用生成器Generator定义概率分布&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;是很复杂的形式，那我们很难去直接计算我们的目标值。虽然我们可以假定一些简单的已知的分布来确定&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;，比如高斯分布；但是很多情况下，高斯分布的实验结果并不是很好；所以，我们希望用一个更generalized的函数来定义&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;我们用生成器Generator（一个网络结构）来定义概率分布&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;，我们希望输入某个已知分布（比如高斯分布）随机产生的一个数&lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;，通过Generator之后可以得到&lt;span class=&#34;math inline&#34;&gt;\(x=G(z)\)&lt;/span&gt;，那么这些&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;可以构成某个复杂的分布，也可以说这个复杂的分布是我们希望得到的分布&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;，我们希望这个分布&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;能够和分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}\)&lt;/span&gt;越接近越好；从散度（Divergence）的角度来说，我们希望分布&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;和分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}\)&lt;/span&gt;的散度能够越小越好，即 &lt;span class=&#34;math display&#34;&gt;\[
G^* = \arg \min_G \text{Div}(P_G,P_{data})
\tag{1}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果是最大似然估计的话，我们会希望KL散度越小越好，即 &lt;span class=&#34;math display&#34;&gt;\[G^* = \arg \min_G KL(P_G,P_{data})\]&lt;/span&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN1.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. 生成器Generator流程示意图
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;divergence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;如何获得我们需要的散度Divergence？&lt;/h2&gt;
&lt;p&gt;由于我们无法确定&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;的分布，所以我们也无法直接计算得到他们的Divergence，当然就没办法直接用&lt;strong&gt;梯度下降&lt;/strong&gt;去找到最小的Divergence小对应的Generator。&lt;/p&gt;
&lt;p&gt;虽然我们无法知道&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;的分布，但是利用重抽样（Resample）的想法，我们可以对它们这两个分布进行抽样；对于&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;而言，我们从原数据抽取样本；对于&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;而言，我们从高斯分布抽样再通过前面确定的Generator得到样本。&lt;/p&gt;
&lt;p&gt;我们引入上一Part讲到的监督器Discriminator（我们说到Discriminator也是一个network），对于训练Discriminator的时候，假设我们的目标函数是 &lt;span class=&#34;math display&#34;&gt;\[
V(G,D) = E_{x\sim P_{data}}[\log D(x)] + E_{x\sim P_{G}}[\log (1-D(x))]
\tag{2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt;代表Generator，它在这一步是固定不变的；我们希望最大化&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;，式（2）第一项&lt;span class=&#34;math inline&#34;&gt;\(E_{x\sim P_{data}}[\log D(x)]\)&lt;/span&gt;表示从&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;得到的&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;，我们希望&lt;span class=&#34;math inline&#34;&gt;\(D(x)\)&lt;/span&gt;能够尽可能大；而对于第二项&lt;span class=&#34;math inline&#34;&gt;\(E_{x\sim P_{G}}[\log (1-D(x))]\)&lt;/span&gt;，表示从&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;得到的&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;，我们希望&lt;span class=&#34;math inline&#34;&gt;\(D(x)\)&lt;/span&gt;能够尽可能小，因为这样&lt;span class=&#34;math inline&#34;&gt;\(1-D(x)\)&lt;/span&gt;才能尽可能大；整体两部分加起来才能够做到尽可能大，实现&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;的最大化。由于抽取的样本&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;在这个环节是固定的，相当于我们需要找到一个Discriminator满足最大化&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;，即 &lt;span class=&#34;math display&#34;&gt;\[
D^* = \arg \max_D V(G,D)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;【注：使用式（2）作为目标函数相当于训练一个二分类器】&lt;/p&gt;
&lt;p&gt;当抽取的样本分散的很开的时候，即它们的散度很大的时候，我们很容易训练得到一个Discriminator能够容易区分来自两个不同分布的样本（很容易使我们的目标函数变大）；但如果抽取的样本分散的不开的时候，即它们的散度比较小时，我们训练得到的Discriminator是很难区分来自两个不同分布的样本的（很难使我们的目标函数变大）。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN2.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
图2. 生成器Discriminator流程示意图
&lt;/div&gt;
&lt;div id=&#34;vdgdivergence&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;最大化目标函数&lt;span class=&#34;math inline&#34;&gt;\(V(D,G)\)&lt;/span&gt;与散度Divergence的联系&lt;/h3&gt;
&lt;p&gt;在给定Generator情况下，我们想要找到一个Discriminator使得我们的目标函数&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;最大，依据上面式（2），我们可以得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
V(G,D) &amp;amp;=\ E_{x\sim P_{data}}[\log D(x)] + E_{x\sim P_G}[\log (1-D(x))]\\
&amp;amp;=\ \int\limits_x P_{data}(x) \log D(x) dx + \int\limits_x P_G(x) \log (1-D(x)) dx\\
&amp;amp;=\ \int\limits_x \Big[P_{data}(x) \log D(x) + P_G(x) \log (1-D(x))\Big] dx
\end{align}
\tag{3}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;给定&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;的情况下，最大化式（3）等价于最大化 &lt;span class=&#34;math display&#34;&gt;\[
P_{data}(x) \log D(x) + P_G(x) \log (1-D(x))
\tag{4}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么，原优化问题等价于找一个最优Discriminator使得式（4）最大。由于&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;固定了，那么&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;是确定的；我们将&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;记作&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;记作&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(D(x)\)&lt;/span&gt;记作&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;，那式（4）可以变化为： &lt;span class=&#34;math display&#34;&gt;\[
f(D) = a\log(D) + b\log (1-D)
\tag{5}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对式（5）求导并赋值为0，可以得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
&amp;amp; \ \frac{df(D)}{dD} = \frac{a}{D} - \frac{b}{1-D} = 0\\
\Rightarrow&amp;amp; \ \frac{a}{D} = \frac{b}{1-D}\\
\Rightarrow&amp;amp; \ a\times (1-D) = b\times D\\
\Rightarrow&amp;amp; \ D = \frac{a}{a+b}
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;将符号复原，我们知道满足式（4）最大的&lt;span class=&#34;math inline&#34;&gt;\(D^*\)&lt;/span&gt;满足 &lt;span class=&#34;math display&#34;&gt;\[
D^* = \frac{P_{data}(x)}{P_{data}(x)+P_G(x)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由二阶导数我们可以知道该点为极大值点： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\frac{d^2f(D)}{dD^2} &amp;amp;=\ -\frac{a}{D^2} - \frac{b}{1-D^2}\\
&amp;amp;=\ -\frac{a}{(\frac{a}{a+b})^2}-\frac{b}{1-(\frac{a}{a+b})^2}\\
&amp;amp;=\ -\frac{(a+b)^2}{a}-\frac{(a+b)^2}{b}\\
&amp;amp;&amp;lt;\ 0
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;将&lt;span class=&#34;math inline&#34;&gt;\(D^*\)&lt;/span&gt;带入&lt;span class=&#34;math inline&#34;&gt;\(V(G,D) = E_{x\sim P_{data}}[\log D(x)] + E_{x\sim P_{G}}[\log (1-D(x))]\)&lt;/span&gt;，我们可以得到 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\max_D V(G,D) &amp;amp;=\ V(G,D^*)\\
&amp;amp;=\ E_{x\sim P_{data}}[\log D(x)] + E_{x\sim P_G}[\log (1-D(x))]\\
&amp;amp;=\ E_{x\sim P_{data}}[\log \frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] + E_{x\sim P_G}[\log (1-\frac{P_{data}(x)}{P_{data}(x)+P_G(x)})]\\
&amp;amp;=\ E_{x\sim P_{data}}[\log \frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] + E_{x\sim P_G}[\log \frac{P_G(x)}{P_{data}(x)+P_G(x)}]\\
&amp;amp;=\ \int\limits_x P_{data}(x)\log \frac{P_{data}(x)}{P_{data}(x)+P_G(x)}dx + \int\limits_x P_G(x)\log \frac{P_G(x)}{P_{data}(x)+P_G(x)}dx\\
&amp;amp;=\ \int\limits_x P_{data}(x)\log \frac{\frac{1}{2}P_{data}(x)}{\frac{1}{2} [P_{data}(x)+P_G(x)]}dx + \int\limits_x P_G(x)\log \frac{\frac{1}{2}P_G(x)}{\frac{1}{2} [P_{data}(x)+P_G(x)]}dx\\
&amp;amp;=\ \int\limits_x P_{data}(x)\log \frac{P_{data}(x)}{\frac{1}{2} [P_{data}(x)+P_G(x)]}dx + \int\limits_x P_G(x)\log \frac{P_G(x)}{\frac{1}{2} [P_{data}(x)+P_G(x)]}dx - 2\log2\\
&amp;amp;=\ KL(P_{data} || \frac{P_{data}+P_G}{2}) + KL(P_G || \frac{P_{data}+P_G}{2}) - 2\log2
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;JS散度（Jensen-Shannon Divergence）是这样定义的： &lt;span class=&#34;math display&#34;&gt;\[
JS(P_1||P_2)=\frac{1}{2}KL(P_1||\frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2||\frac{P_1+P_2}{2})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，我们可以推得 &lt;span class=&#34;math display&#34;&gt;\[
\max_D V(G,D) = V(G,D^*) = -2\log 2 + 2JS(P_{data}||P_G)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从上面可以看出，我们在固定Generator之后，对&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;的最大化相当于计算&lt;span class=&#34;math inline&#34;&gt;\(P_{data}\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;之间的JS散度再减去2倍&lt;span class=&#34;math inline&#34;&gt;\(\log2\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;在式（1）中散度Divergence是无法直接计算的，但是从刚刚的推导中，我们知道最大化目标函数&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;可以得到散度的值，我们进一步用最大化&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;替代&lt;span class=&#34;math inline&#34;&gt;\(P_{data}\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_G\)&lt;/span&gt;之间的散度，可以得到一个Min-Max的优化问题。 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
G^* &amp;amp;=\ \arg \min_G \text{Div}(P_G,P_{data})\\
&amp;amp;=\ \arg \min_G \max_D V(G,D)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;min-max&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;求解Min-Max问题&lt;/h3&gt;
&lt;p&gt;上面我们最终得到了一个Min-Max最优化问题 &lt;span class=&#34;math display&#34;&gt;\[G^* = \arg \min_G \max_D V(G,D)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果我们手中没有Generator的话，我们无法得到&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;的最大值，在解决这个优化问题之时，我们可以按一下步骤进行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始化一个带随机参数的Generator &lt;span class=&#34;math inline&#34;&gt;\(G_0\)&lt;/span&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于&lt;span class=&#34;math inline&#34;&gt;\(i = 0,1,\dots,n\)&lt;/span&gt;，重复进行下列步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过梯度上升（Gradient Ascent）方法找到满足最大化&lt;span class=&#34;math inline&#34;&gt;\(V(G_i,D)\)&lt;/span&gt;的&lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;；（这一步等价于获得了&lt;span class=&#34;math inline&#34;&gt;\(P_{data}\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(P_{G_i}\)&lt;/span&gt;之间的JS散度）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;通过梯度下降（Gradient Descent）方法得到&lt;span class=&#34;math inline&#34;&gt;\(G_{i+1}\)&lt;/span&gt;：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta_{G_{i+1}} = \theta_{G_i} - \eta\frac{\partial V(G,D_i)}{\partial \theta_G}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;算法的大致框架得到了，但是对于细节&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;的形式我们只有式（2）；对于式（2）中的期望，实际上我们是很难得到的，在实践中，我们用样本均值来代替期望值；因此最大化&lt;span class=&#34;math inline&#34;&gt;\(V(G,D)\)&lt;/span&gt;可以转换为最大化 &lt;span class=&#34;math display&#34;&gt;\[ \tilde{V} = \frac{1}{m}\sum_{i=1}^m\log D(x^i) + \frac{1}{m}\sum_{i=1}^m\log (1-D(\tilde{x}^i)) \]&lt;/span&gt; 其中样本&lt;span class=&#34;math inline&#34;&gt;\(\{x^1,x^2,\dots,x^m\}\)&lt;/span&gt;来自分布&lt;span class=&#34;math inline&#34;&gt;\(P_{data}(x)\)&lt;/span&gt;，样本&lt;span class=&#34;math inline&#34;&gt;\(\{\tilde{x}^1,\tilde{x}^2,\dots,\tilde{x}^m\}\)&lt;/span&gt;来自分布&lt;span class=&#34;math inline&#34;&gt;\(P_G(x)\)&lt;/span&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gan&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;GAN的算法&lt;/h3&gt;
通过上面的推导介绍，我们可以总结出GAN的算法框架出来：
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN3.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
图3. GAN的算法框架
&lt;/div&gt;
&lt;p&gt;可以注意到，在训练Generator的时候，其中&lt;span class=&#34;math inline&#34;&gt;\(\tilde{V}\)&lt;/span&gt;的第一项实际上是与Generator是无关的，去掉第一项不影响我们最小化目标函数&lt;span class=&#34;math inline&#34;&gt;\(\tilde{V}\)&lt;/span&gt;。显然，整个GAN算法分为两部分，我们可以这么理解：第一步训练Discriminator实际上是度量两个分布间JS散度，而训练Generator是在最小化JS散度。&lt;/p&gt;
&lt;p&gt;从数学推导可以帮助我们更好理解GAN，这一Part就结束啦๑乛◡乛๑&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/index.html&#34;&gt;李宏毅个人主页&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>生成对抗网络的第一Part</title>
      <link>/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%B8%80part/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%B8%80part/</guid>
      <description>


&lt;p&gt;从知乎上了解到台大有位著名的教授&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html&#34;&gt;李宏毅&lt;/a&gt;超级会讲&lt;a href=&#34;https://arxiv.org/abs/1406.2661v1&#34;&gt;Generative Adversarial Networks, GAN&lt;/a&gt;技术，所以慕名而到Youtube找到他的上课视频成为他的“课外学生”。李教授真的厉害，形象生动地讲解GAN的各个知识点。那么，我把我学到的整理为一篇博客，尝试作为一名“GAN路上的导游”。&lt;/p&gt;
&lt;p&gt;Yann LeCun是Facebook的AI研究部门的Director，同时也是NYU（New York University）的一位教授，维基百科上是这么介绍他：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;He is the Chief Artificial Intelligence Scientist at Facebook AI Research, and he is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNN), and is a founding father of convolutional nets.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;做Deep Learning的人多多少少会听过这个名字，他曾经这样回答了Quora论坛上的一个问题（What are some recent and potentially upcoming breakthroughs in unsupervised learning?）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Adversarial training is the coolest thing since sliced bread.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里sliced bread的中文意思是切片面包，但其实这里是表示了有一个好东西问世，给某个领域带来了巨大发展，维基百科这么说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The phrase “the greatest thing since sliced bread” is a common hyperbole used to praise an invention or development.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这也说明了GAN推进了整个领域的发展。Yann LeCun对GAN也有过这样极高的评价：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This, and the variations that are now being proposed is the most interesting idea in the last 10 years in ML, in my opinion.&lt;/p&gt;
&lt;/blockquote&gt;
李教授统计了ICASSP（International Conference on Acoustics, Speech and Signal Processing）的文章题目涵盖关键词的数量：
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN1.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. ICASSP文章题目涵盖关键词的数量变化图
&lt;/div&gt;
&lt;p&gt;很明显，从17年的2篇Adversarial到18年的42篇Adversarial，同年增长了21倍！相当惊人！既然GAN这么Popular又是这么酷炫，那么我们就开始正文吧！(๑•̀ㅂ•́)و✧&lt;/p&gt;
&lt;div id=&#34;gangan&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;什么是GAN？说GAN就干！&lt;/h1&gt;
&lt;p&gt;GAN里面主要分为Generator和Discriminator这两部分，其实原理很简单，Generator是负责训练样本并能生成对的Output，而Discriminator像是一位老师，看看Generator这位学生交的作业质量怎么样，会给Generator的作业一个分数。下面我们更详细地介绍他们这两部分~&lt;/p&gt;
&lt;div id=&#34;generator&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;一无所知的Generator生成器&lt;/h2&gt;
Generator其实就是neural network (NN)，它的输入是向量，那我们如果丢一个向量到Generator里面，它就能产生某个Output（可能是一张相片或者一句话等等）
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN2.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
图2. Generator生成器的示例图
&lt;/div&gt;
&lt;p&gt;李教授酷爱二次元，所以他举了这样的例子，丢一些向量给生成图片的Generator就生成了一些二次元的图片；另外，对应句子生成的例子，丢一些向量给生成句子的Generator就生成了一些句子。简单来说，我们给Generator这个function（NN其实就是一个复杂的function）赋值，它就会产生对应的结果。&lt;/p&gt;
我们以图片为例，输入的向量中的每一个元素，可能对应着图片中不同的特征。假设第一位是改变头发的长短特征，那从下图中可以看到0.1改为3后，图片中的女孩从短头发变为长头发；假设向量倒数第二位是改变头发的颜色特征，那从下图可以看到5.4改为2.4后，图片中的女孩从紫色变为了蓝色；假设向量倒数第一位是改变嘴巴特征，那从下图可以看到0.9改为3.5后，图片中的女孩从小嘴巴变为了张开嘴巴。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN3.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
图3. 输入向量对结果输出的影响
&lt;/div&gt;
&lt;p&gt;在实际操作中，如果我们通过大量的样本让Generator训练，使其能够输出与图片尽可能相似的结果，那这样就只是普通的NN（神经网络），但我们想要更高级！想要输出的图片质量更好！而GAN满足了我们的需求，它的idea妙就妙在搞多了一个Discriminator（监督器），审判Generator输出的结果是不是真的“好”。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;discriminator&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;超严厉的Discriminator监督器&lt;/h2&gt;
Discriminator也是一个NN，但是它的输入是一张图片或是一句话（Generator的输出）。而它的输出是一个数值，这个数值代表了这张图片的质量如何，数值越大，那图片的质量就越好，越像是真实的图片；相反，数值越小，图片质量越差。下面可以看到不同质量的二次元图片对应着不同的得分数值~
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN4.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure4&#34; /&gt;
&lt;p&gt;
图4. 不同二次元图片对应不同的得分
&lt;/div&gt;
&lt;p&gt;前面大致讲了一下Generator和Discriminator的关系，但是不算很生动详细！下面我来举个栗子！&lt;/p&gt;
我们可以把Generator和Discriminator当做捕食者和被捕食者，那Pokemon里面鸟系对虫系就有着威慑能力，天生虫系会怕鸟系嘛，这很合理╮(๑•́ ₃•̀๑)╭
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN5.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure5&#34; /&gt;
&lt;p&gt;
图5. 小智的比比鸟和绿毛虫的初次相遇
&lt;/div&gt;
&lt;p&gt;其实一开始绿毛虫（一代Generator）就很怕波波（一代Discriminator）嘛，所以它就会进化成铁甲蛹（二代Generator），那波波个子小就拿它没办法了，吃也吃不了╮(๑•́ ₃•̀๑)╭所以波波也进化了变成了比比鸟（二代Discriminator）。那现在比比鸟翅膀大了，爪子一夹，把铁甲蛹抓到空中再丢下来（极其残忍！），铁甲蛹也会痛！所以铁甲蛹不甘示弱，它接着进化成巴大蝴（三代Generator）！这下比比鸟没办法它也进化成比雕（三代Discriminator），它以为比雕可能会搞得定巴大蝴！奈何巴大蝴也有翅膀了，还有催眠粉！比雕觉得没办法了，就这样吧，两人实力相当了！&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN6.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure6&#34; /&gt;
&lt;p&gt;
图6. Generator和Discriminator的相互关系
&lt;/div&gt;
&lt;p&gt;回到现实！这里的巴大蝴就是我们的最终Generator（这里以三代为例，实际需要N代），那它所生成的图片可以让最终的Discriminator认为是真实的，这就达到了我们的目的(*•̀ㅂ•́)و&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GAN的算法框架&lt;/h2&gt;
&lt;p&gt;我们了解了Generator和Discriminator的基本知识后，我们来看看算法~&lt;/p&gt;
&lt;p&gt;首先随机产生了两个NN作为Generator和Discriminator，然后不断循环：固定Generator调Discriminator的参数，再固定Discriminator调Generator的参数。具体过程如下所示：&lt;/p&gt;
在第一步中固定Generator调Discriminator的参数，对于从Database出来的真实案例，我们希望Discriminator给高分；对于Generator生成的案例，我们希望Discriminator给低分。Discriminator通过训练会在这个过程中学会给真实的案例高分，给假的案例低分。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN7.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure7&#34; /&gt;
&lt;p&gt;
图7. 固定Generator下训练Discriminator
&lt;/div&gt;
在下一步中我们固定Discriminator调Generator的参数，我们希望调整Generator后，我们给一个向量生成一个案例，这个案例通过Discriminator得到的分数能够尽量高。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN8.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure8&#34; /&gt;
&lt;p&gt;
图8. 固定Discriminator下训练Generator
&lt;/div&gt;
如果我们写成Pseudocode（伪代码），就变成下面这样：
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN9.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure9&#34; /&gt;
&lt;p&gt;
图9. 关于GAN算法的伪代码
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;unsupervised-conditional-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unsupervised Conditional Generation非监督的条件生成器&lt;/h1&gt;
&lt;p&gt;通常在普通的神经网络方法下，但是我们需要对应的样本来帮助我们生成我们需要的图片；我们给一个输入，再给一个Label告诉机器，你看到这个输入就需要有这样的Label的输出，但如果对于某些样本我们刚好没有对应Label的话，但我们手中有其他类似的，那我们可以通过非监督的条件生成器来生成我们想要的结果。&lt;/p&gt;
我们希望能够创造一个Generator，输入一个来自Domain X的样本，可以输出一个对应在Domain Y的样本。&lt;strong&gt;这相当于一种风格转化的案例。&lt;/strong&gt;举个例子，现在许多人喜欢拍照用滤镜，通常我们拍的普通相片是没有带滤镜的，那现在我希望能够得到水彩画形式的相片，如下所示：
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN10.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure10&#34; /&gt;
&lt;p&gt;
图10. 变成水彩画形式的相片
&lt;/div&gt;
&lt;div id=&#34;direct-transformation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本的直接转化问题（Direct Transformation）&lt;/h2&gt;
&lt;p&gt;像上面叙述的例子，其实普通相片到油画形式的相片，只是&lt;strong&gt;色彩质地&lt;/strong&gt;有所区别，但是总体的框架基本不变，相当于说只是小部分修改了我们输入的相片，那Direct Transformation就足够帮我们处理这个问题了。&lt;/p&gt;
通常我们会用GAN的技术来实现，GAN其实也是可以解决这个问题，如果Generator的层数很少，不是那么复杂，在Discrimiantor的监督下生成油画型的图片跟输入的图片差距不会太大。但是如果Generator很复杂的情况下，Generator是存在可能会生成在Domain Y的相片与在Domain X的相片差距很大。即使在Discriminator中拿到了很高的分数，但是与原始输入的样本差距甚远，如下图所示：
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN11.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure11&#34; /&gt;
&lt;p&gt;
图11. 普通GAN的弱点
&lt;/div&gt;
&lt;p&gt;在Domain X的河道图输入之后，尽管训练得到的Generator产生了艺术型的油画图，但是明显上图中的梵高自画像不是我们希望得到的输出，但它确实是属于Domain Y类型的图片。&lt;/p&gt;
&lt;div id=&#34;cycle-gan&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cycle GAN&lt;/h3&gt;
存在上述的问题，那么我们想在生成Domain Y的图片之后，我们可以做一个逆函数（NN）来返回去检验这个图片，看看能否恢复成我们输入图片的样子；当然，我们需要Discriminator帮助我们将输入的图片训练生成在Domain Y的图片。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN12.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure12&#34; /&gt;
&lt;p&gt;
图12. Cycle GAN处理过程示意图
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;stargan&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;StarGAN&lt;/h3&gt;
&lt;p&gt;如果现在我们不仅仅希望普通相片可以变成一张油画照，我们还希望可以变成黑白照或者素描照，那我们的案例就变得更复杂，需要多个Domain，而且我们希望能够在多个Domain里面互转。假设我们有普通照片，油画照，黑白照和素描照这四种类型照片，那其实我们需要创建&lt;span class=&#34;math inline&#34;&gt;\(C_4^2\)&lt;/span&gt;个Cycle GAN来解决这样一个大问题，使得在这四个Domain之间实现互转（如下图(a)所示）。&lt;/p&gt;
&lt;p&gt;2017年arXiv上Yunjey Choi等人发表了文章&lt;a href=&#34;https://arxiv.org/abs/1711.09020&#34;&gt;StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&lt;/a&gt;，StarGAN的方便之处是在于只学习了一个Generator，就可以在多个Domain之间实现互转（如下图(b)所示）。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN13.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure13&#34; /&gt;
&lt;p&gt;
图13. Cross-domain models和StarGAN的示意图
&lt;/div&gt;
&lt;p&gt;下面我们通过原文提供的案例来进一步了解StarGAN：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;首先，我们先&lt;strong&gt;训练Discriminator&lt;/strong&gt;。这个Discriminator的输入有真实的照片和假的照片，我们希望Discriminator可以输出判断输入的照片是真的还是假的；同时希望可以输出判断真实的照片属于哪一个Domain。在下图案例可以看到，我们真实判断的Domain是&lt;span class=&#34;math inline&#34;&gt;\(0\ 0\ 1\ 0\ 1\)&lt;/span&gt;相当于真实照片是一个棕色头发年轻的女性角色。在这个地方可以注意到，我们只在考虑CelebA label，但是没有考虑RaFD label，而这个是由Mask vector所控制的（先设定为&lt;span class=&#34;math inline&#34;&gt;\(1\ 0\)&lt;/span&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;接着我们以真实照片（&lt;strong&gt;棕色头发年轻的女性角色&lt;/strong&gt;）和我们希望得到的Domain（&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\ 0\ 0\ 1\ 1\)&lt;/span&gt;&lt;/strong&gt;）作为我们&lt;strong&gt;训练Generator&lt;/strong&gt;的输入，我们希望输出得到目标Domain的照片（转化案例是希望得到一个&lt;strong&gt;黑色头发年轻的男性角色&lt;/strong&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;利用Cycle GAN的想法，我们用输出的照片（&lt;strong&gt;黑色头发年轻的男性角色&lt;/strong&gt;）和我们原始的Domain（&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(0\ 0\ 1\ 0\ 1\)&lt;/span&gt;&lt;/strong&gt;）作为另外一个Generator的输入，希望得到和原始一模一样的照片（&lt;strong&gt;棕色头发年轻的女性角色&lt;/strong&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;最后呢~将第二步训练得到的照片作为Discriminator的输入，训练Discriminator判断能不能认为输入的照片是真实的照片，并且是属于我们希望得到的Domain（&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\ 0\ 0\ 1\ 1\)&lt;/span&gt;&lt;/strong&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;循环前面第二到第四步，直到第四步中Discriminator认为第二步所输出的照片是真实的且属于Domain（&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(1\ 0\ 0\ 1\ 1\)&lt;/span&gt;&lt;/strong&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
同理，我们可以让Mask vector为&lt;span class=&#34;math inline&#34;&gt;\(0\ 1\)&lt;/span&gt;，不考虑CelebA label了而是考虑RaFD label，即考虑情绪的变换。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN14.PNG&#34; width = &#34;600&#34; height = &#34;700&#34; alt=&#34;Figure14&#34; /&gt;
&lt;p&gt;
图14. 来自原Paper的案例
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;projection-to-common-space&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;投影到共有的空间（Projection to Common Space）&lt;/h2&gt;
&lt;p&gt;那如果想要&lt;strong&gt;转化的结果跟你原来输入的样本结果差别很大&lt;/strong&gt;，对于图片而言，可能&lt;strong&gt;画风突变&lt;/strong&gt;！比如从真人头像到二次元的漫画头像，这时没办法简单地进行Direct Transformation了，需要利用Projection这样的技术。如果我们先通过编码器获得latent variables，再通过解码器获得我们想要的输出，这样就有可能做到比较大的变换。&lt;/p&gt;
&lt;strong&gt;问题&lt;/strong&gt;&lt;br /&gt;
对于两个Domain的大变化的互转，我们希望可以先分别对两个不同Domain的样本做Auto-Encoder，同时最小化重建的误差（Minimizing reconstruction error）。我们假设Domain X是漫画版本闪电侠，我们希望直接通过图片转化成真人版本的闪电侠（Domain Y），我们按刚刚说的流程，实现的流程如下图所示。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN15.PNG&#34; width = &#34;700&#34; height = &#34;500&#34; alt=&#34;Figure15&#34; /&gt;
&lt;p&gt;
图15. 漫画闪电侠与真人版的互换
&lt;/div&gt;
但是这样做存在问题就是Domain X做好的Auto-Encoder跟Domain Y做好的Auto-Encoder是完全没有联系的，这种情况下可能我输入一张闪电侠的漫画图片，通过Y的解码器（Decoder）之后，没办法得到闪电侠的真人图片，而是得到了绿箭侠的真人图片(๑•́ ₃ •̀)
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN16.PNG&#34; width = &#34;700&#34; height = &#34;500&#34; alt=&#34;Figure16&#34; /&gt;
&lt;p&gt;
图16. 漫画闪电侠的变换结果出错的可能性
&lt;/div&gt;
【注：美剧闪电侠第五季的第九集和美剧绿箭第七季的第九集中，Oliver Queen变成了闪电侠。。。Barry Allen变成了绿箭侠。。。源自异世界的剧情_(:з」∠)_ 】
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;GAN21.PNG&#34; width = &#34;500&#34; height = &#34;700&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;回到正题！！！&lt;/p&gt;
&lt;strong&gt;方法1&lt;/strong&gt;&lt;br /&gt;
那有一种方法呢，就是在获得中间的latent variables之前时，两个encoder最后有几层是共享相同参数的；同样在进入decoder部分时，前面几层也是共享相同参数的。这样在获得latent variables的时候，能够尽可能落在相同的latent space。这样的方法出现在文章&lt;a href=&#34;https://arxiv.org/abs/1606.07536&#34;&gt;Coupled Generative Adversarial Networks&lt;/a&gt;和文章&lt;a href=&#34;https://arxiv.org/abs/1703.00848&#34;&gt;Unsupervised Image-to-Image Translation Networks&lt;/a&gt;。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN17.PNG&#34; width = &#34;700&#34; height = &#34;500&#34; alt=&#34;Figure17&#34; /&gt;
&lt;p&gt;
图17. 共享参数的方法示意图
&lt;/div&gt;
&lt;strong&gt;方法2&lt;/strong&gt;&lt;br /&gt;
另外一种方法就是我们加一个Domain Discriminator，对中间产生的latent variables进行判定，判定产生的latent variables是来自&lt;span class=&#34;math inline&#34;&gt;\(EN_X\)&lt;/span&gt;还是来自&lt;span class=&#34;math inline&#34;&gt;\(EN_Y\)&lt;/span&gt;，那么两个Encoder就会训练使得产生的latent variables能够骗过Discriminator。这样相当于这个Domain Discriminator促使两个Encoder产生的latent variables来自相同的分布。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN18.PNG&#34; width = &#34;700&#34; height = &#34;500&#34; alt=&#34;Figure18&#34; /&gt;
&lt;p&gt;
图18. 加入Domain Discriminator的示意图
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;方法3&lt;/strong&gt;&lt;br /&gt;
利用Cycle GAN的想法，我们还可以输入一张我们想要转换的图片（比如输入是漫画闪电侠），通过Domain X的encoder和Domain Y的decoder得到目标输出结果；然后，将这个结果作为Domain Y的encoder的输入，再通过Domain X的decoder得到我们想要转换的图片，当然我们会希望重建误差尽可能小。&lt;/p&gt;
另外，我们可以加入两个Discriminator来判断两个decoder生成的图片是否属于各自相对应的Domain，这样的想法就有用在ComboGAN上，ComboGAN的文章全名叫做&lt;a href=&#34;https://arxiv.org/abs/1712.06909&#34;&gt;ComboGAN: Unrestrained Scalability for Image Domain Translation&lt;/a&gt;。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN19.PNG&#34; width = &#34;700&#34; height = &#34;500&#34; alt=&#34;Figure19&#34; /&gt;
&lt;p&gt;
图19. Cycle GAN想法下的流程示意图
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;方法4&lt;/strong&gt;&lt;br /&gt;
除了最小化重建误差，我们也可以最小化从Domain X和Domain Y分别编码得到的latent variables。跟方法3有点相似，先输入一张我们想要转换的图片（比如输入是漫画闪电侠），通过Domain X的encoder得到latent variables，再通过Domain Y的decoder得到目标输出结果；然后，将这个结果作为Domain Y的encoder的输入，可以再次得到latent variables。其中这两次获得的latent variables，我们希望它们能够越接近越好。那这样的方法就有用在DTN和XGAN上，它们的文章全名分别为&lt;a href=&#34;https://arxiv.org/abs/1611.02200&#34;&gt;Unsupervised Cross-Domain Image Generation&lt;/a&gt;和&lt;a href=&#34;https://arxiv.org/abs/1711.05139&#34;&gt;XGAN: Unsupervised Image-to-Image Translation for Many-to-Many Mappings&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;更多的应用！语音变换！&lt;/h3&gt;
其实这项技术还可以用在语音变换上，可能生活中我们希望做一个变声器，我们说一句话但是扬声器出来的是另外一个人的声音。其实阿笠博士在20年前就已经给柯南一个变声器了，每次柯南都用来假装毛利小五郎的声音(..•˘_˘•..)
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;GAN20.PNG&#34; width = &#34;500&#34; height = &#34;500&#34; alt=&#34;Figure20&#34; /&gt;
&lt;p&gt;
图20. 柯南的蝴蝶结变声器
&lt;/div&gt;
&lt;p&gt;结束基础普及知识的第一Part！！！第二Part再从基础理论来看GAN！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/index.html&#34;&gt;李宏毅个人主页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/DQNNMiAP5lw&#34;&gt;李宏毅，Youtube：GAN Lecture 1 (2018): Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.2661v1&#34;&gt;I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial networks,” in Advances in Neural Information Processing Systems (NIPS), 2014. 1, 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.09020&#34;&gt;Y. Choi, M. Choi, M. Kim, J.-W. Ha, S. Kim, and J. Choo, “Stargan: Unified generative adversarial networks for multi-domain image-toimage translation,” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. 1, 3, 6, 7, 8, 9, 10&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>深度神经网络基础</title>
      <link>/post/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</guid>
      <description>


&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;神经元及神经网络基础结构&lt;/h1&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN1.PNG&#34; width = &#34;400&#34; height = &#34;200&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. 神经元的组成（源自维基百科）
&lt;/div&gt;
&lt;p&gt;神经元这个图大多数理科生在高中生物课本都学过~神经网络则由许许多多的神经元所组成，通常一个神经元具有多个树突，主要用来接收消息；轴突只有一条，相当于我们定义的一个计算过程；而轴突尾部的许许多多轴突末梢，将传递信息给其他神经元。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN2.PNG&#34; width = &#34;400&#34; height = &#34;200&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
图2. 神经网络基础结构
&lt;/div&gt;
&lt;p&gt;通常这里的非线性函数会用上各式各样的激活函数，比如Sigmoid函数，tanh函数和ReLu函数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sigmoid函数&lt;/strong&gt;&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[f(z) = \frac{1}{1+e^{-z}}\]&lt;/span&gt; &lt;strong&gt;tanh函数&lt;/strong&gt;&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[f(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}\]&lt;/span&gt; &lt;strong&gt;ReLu函数&lt;/strong&gt;&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[f(z) = \max(0,z)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2019-01-05-深度神经网络基础_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;神经网络基础认知&lt;/h1&gt;
我们把许多神经元组合起来就可以得到一个神经网络，由于有输入的数据和我们想得到的输出数据，便会有“输入层”（Input layer）和“输出层”（Output layer）；中间的神经元则组成了“隐藏层”（Hidden layer）。在下面图3中，输入层有3个神经元，隐藏层有4个神经元，输出层有2个神经元。在实际情况中，输入层和输出层通常是固定的，而隐藏层的层数和节点数则可以自由调节。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN3.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
图3. 神经网络基础层级结构
&lt;/div&gt;
&lt;p&gt;我们假设一个全连接的网络结构，其中隐藏层只有一层。另外，假设输入层和隐藏层之间的边的权值构成的矩阵为 &lt;span class=&#34;math display&#34;&gt;\[
\left [
\begin{matrix}
w_{11} &amp;amp; w_{12} &amp;amp; w_{13} \\
w_{21} &amp;amp; w_{22} &amp;amp; w_{23} \\
w_{31} &amp;amp; w_{32} &amp;amp; w_{33}
\end{matrix}
\right ]
\]&lt;/span&gt; 其中，第一列的&lt;span class=&#34;math inline&#34;&gt;\(w_{11}, w_{21}, w_{31}\)&lt;/span&gt;代表的是输入层的点&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;分别连接隐藏层的三个节点的边的权值；第二列的&lt;span class=&#34;math inline&#34;&gt;\(w_{12}, w_{22}, w_{32}\)&lt;/span&gt;代表的是输入层的点&lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;分别连接隐藏层的三个节点的边的权值；第三列的&lt;span class=&#34;math inline&#34;&gt;\(w_{13}, w_{23}, w_{33}\)&lt;/span&gt;代表的是输入层的点&lt;span class=&#34;math inline&#34;&gt;\(x_3\)&lt;/span&gt;分别连接隐藏层的三个节点的边的权值。&lt;/p&gt;
&lt;p&gt;图中的“+1”点代表我们添加了一个值b，称其为偏置项。那么，隐藏层的节点可以由下计算得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
a_1 = w_{11}\times x_1 + w_{12}\times x_2 + w_{13}\times x_3 + b_1\\
a_2 = w_{21}\times x_1 + w_{22}\times x_2 + w_{23}\times x_3 + b_2\\
a_3 = w_{31}\times x_1 + w_{32}\times x_2 + w_{33}\times x_3 + b_3
\end{align}
\tag{1}
\]&lt;/span&gt; 由于线性计算的表现能力比较差，所以考虑用非线性函数进行计算，即使用激活函数&lt;span class=&#34;math inline&#34;&gt;\(f(\cdot)\)&lt;/span&gt;（前面已提及）。（1）式可以变换为（2）式： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
a_1 = f(w_{11}\times x_1 + w_{12}\times x_2 + w_{13}\times x_3 + b_1)\\
a_2 = f(w_{21}\times x_1 + w_{22}\times x_2 + w_{23}\times x_3 + b_2)\\
a_3 = f(w_{31}\times x_1 + w_{32}\times x_2 + w_{33}\times x_3 + b_3)
\end{align}
\tag{2}
\]&lt;/span&gt; 将（2）式改写为矩阵运算形式（3）式： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\boldsymbol{a} = f \begin{pmatrix} \begin{pmatrix} w_{11},w_{12},w_{13}\\w_{21},w_{22},w_{23}\\w_{31},w_{32},w_{33} \end{pmatrix} \begin{pmatrix} x_1\\x_2\\x_3 \end{pmatrix} + \begin{pmatrix} b_1\\b_2\\b_3 \end{pmatrix} \end{pmatrix} = f(\boldsymbol{W}x+\boldsymbol{B})
\end{align}
\tag{3}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN4.PNG&#34; width = &#34;400&#34; height = &#34;400&#34; alt=&#34;Figure4&#34; /&gt;
&lt;p&gt;
图4. 简单全连接网络中层之间的计算方式
&lt;/div&gt;
当我们增加隐藏层的层数，便可以构成更复杂的网络，即深度神经网络。
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN5.PNG&#34; width = &#34;600&#34; height = &#34;400&#34; alt=&#34;Figure5&#34; /&gt;
&lt;p&gt;
图5. 深度神经网络示意图
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;loss-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;损失函数（Loss Function）&lt;/h1&gt;
&lt;p&gt;训练数据通常是一系列“输入-输出”数据对组成的集合，我们希望输入一个数据，尽可能与配对的输出数据相同。那么网络的输出结果和实际的真实结果差多少，我们需要一定数学形式进行量化，所以引入了损失函数（Loss Function）。常见的损失函数有以下几种：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0-1损失函数&lt;/strong&gt;&lt;br /&gt;
如果预测值和真实值一样，则损失值为0；若不等，则为1；公式表达为： &lt;span class=&#34;math display&#34;&gt;\[
L(y,f(x)) = \begin{cases}
1, &amp;amp; y = f(x)\\
0, &amp;amp; y \neq f(x)
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;绝对值损失函数（1-范数形式）&lt;/strong&gt;&lt;br /&gt;
通过预测值和真实值之差的绝对值进行衡量，公式表达为： &lt;span class=&#34;math display&#34;&gt;\[
L(y,f(x)) = |y-f(x)|
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;均方误差损失函数（2-范数形式）&lt;/strong&gt;&lt;br /&gt;
通过计算预测值和真实值之差的平方再求均值，可得到均方误差，公式表达为： &lt;span class=&#34;math display&#34;&gt;\[
L(y,f(x)) = \frac{1}{n}\sum_{i=1}^n(y_i-f(x_i))^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;优化算法&lt;/h1&gt;
&lt;div id=&#34;gradient-descent-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;梯度下降法（Gradient Descent Method）&lt;/h2&gt;
&lt;p&gt;传统的梯度下降法是通过计算损失函数的一阶导数作为方向进行下降计算，计算方法可表示为： &lt;span class=&#34;math display&#34;&gt;\[
W_{ij} = W_{ij} - \alpha\frac{\partial}{\partial W_{ij}}L(w,b)\\
b_i = b_i - \alpha\frac{\partial}{\partial b_i}L(w,b)
\]&lt;/span&gt; 其中&lt;span class=&#34;math inline&#34;&gt;\(W_{ij}\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt;是需要优化的参数，&lt;span class=&#34;math inline&#34;&gt;\(L(w,b)\)&lt;/span&gt;是损失函数，&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;在深度学习中通常称为学习率（learning rate），在机器学习或最优化计算领域中我们通常称为步长（stepsize）。&lt;/p&gt;
&lt;p&gt;传统的梯度下降法需要计算&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;个梯度，即样本数量的梯度个数，在数据越来越大的时代，这会大大降低我们需要的计算速度，因此也产生了随机梯度下降（Stochastic gradient descent）这一类的方法。随机梯度下降通常随机选取某个样本并计算其相应导数，作为所有样本相同的导数进行计算，这种方法在实践上有不错的效果。当然，我们可以随机选取一小批样本，样本数量记为batch size，将batch size个样本的导数进行累加后求均值作为所有样本相同的导数，再进一步计算；这种方法我们称为小批量随机梯度下降法（mini-batch stochastic gradient descent）。&lt;/p&gt;
&lt;p&gt;虽然梯度下降直接快速，但是也有一定的不足，由于我们需要选取stepsize，若stepsize太大，那可能无法达到优化问题的最优点；若stepsize太小，则收敛速度太慢，大大降低了模型训练速度。同时，不变的stepsize可能会使结果无法收敛到全局最优解，并可能停在局部最小值（局部最优解），当然很容易陷入到“鞍点”。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;NN6.PNG&#34; width = &#34;400&#34; height = &#34;400&#34; alt=&#34;Figure6&#34; /&gt;
&lt;p&gt;
图6. “鞍点”示意图
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;momentummomentum-optimizer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Momentum优化器（Momentum Optimizer）&lt;/h2&gt;
&lt;p&gt;Momentum优化器也可称为基于动量的优化算法，其中参数的更新会根据梯度的变化而变化：动量再梯度连续指向同一方向上时会增加，而在梯度方向变化时会减小；这样可以更快地收敛并减少震荡。公式表示为： &lt;span class=&#34;math display&#34;&gt;\[
v_t^{W} = \gamma \times v_{t-1}^{W} + \alpha \times \frac{\partial}{\partial W_{ij}}L(w,b)\\
W_{ij} = W_{ij} - v_t^{W}\\
v_t^{b} = \gamma \times v_{t-1}^{b} + \alpha \times \frac{\partial}{\partial b_i}L(w,b)\\
b_i = b_i - v_t^{b}
\]&lt;/span&gt; 其中，&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;是动量更新值，通常取0.9。这样，基于Momentum的随机梯度下降可以更快地收敛，并减少陷入局部最优点的概率。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adagradadaptive-gradient-optimizer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adagrad优化器（Adaptive Gradient Optimizer）&lt;/h2&gt;
&lt;p&gt;Momentum优化器虽然加速了参数的更新并加速收敛，但存在缺点是没有对不同的参数进行区别对待。Adagrad优化器则基于这样的梯度优化思想：根据参数自适应地更新学习率（也为步长stepsize），对于不频繁更新的参数做较大更新，而对于频繁更新的参数做较小的更新。&lt;/p&gt;
&lt;p&gt;Adagrad对于每个参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_{t,i}\)&lt;/span&gt;，在每个时间点&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;使用不同的学习率。首先我们先考虑Adagrad的单参数情况，为了公式形式的整洁，我们记各个时间点&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;的参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_{t,i}\)&lt;/span&gt;下的目标函数梯度为&lt;span class=&#34;math inline&#34;&gt;\(g_{t,i}\)&lt;/span&gt;： &lt;span class=&#34;math display&#34;&gt;\[g_{t,i} = \frac{\partial}{\partial \theta_{t,i}}L(\theta_{t,i})\]&lt;/span&gt; 在Adagrad的更新规则中，我们会根据每个时间点&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;对每个参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_{t+1,i}\)&lt;/span&gt;基于上次已经计算过的梯度&lt;span class=&#34;math inline&#34;&gt;\(\theta_{t,i}\)&lt;/span&gt;来修改步长： &lt;span class=&#34;math display&#34;&gt;\[\theta_{t+1,i} = \theta_{t,i} - \frac{\alpha}{\sqrt{G_{t,ii}+\epsilon}}\times g_{t,i}\]&lt;/span&gt; 其中，&lt;span class=&#34;math inline&#34;&gt;\(G_{t,ii}\in R^{d\times d}\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(G_{t,ii}\)&lt;/span&gt;是一个对角矩阵，其对角元素&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;时刻参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_{t,i}\)&lt;/span&gt;的梯度平方和，&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;是一个光滑项，防止分母为0，通常取1e-8级别的数。另外，&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;使用默认值0.01。Adagrad有个缺点就是其分母实际上累积了梯度的平方，会使得步长（学习率）越来越小。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adadelta&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adadelta优化器&lt;/h2&gt;
&lt;p&gt;Adadelta是对Adagrad的改进，通过用过去计算的梯度平方的均值代替单纯的累加梯度平方，可以避免一味地降低步长。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;时刻的梯度平方均值表示为： &lt;span class=&#34;math display&#34;&gt;\[
E[g^2]_{t,i} = \gamma\times E[g^2]_{t-1,i} + (1-\gamma)\times g_{t,i}^2
\]&lt;/span&gt; 其中，&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;和前面提到的Momentum优化器中的&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;类似，通常取0.9。将累积梯度平方更改为梯度平方均值，可得到： &lt;span class=&#34;math display&#34;&gt;\[\theta_{t+1,i} = \theta_{t,i} - \frac{\alpha}{\sqrt{E_t+\epsilon}}\times g_{t,i}\]&lt;/span&gt; 另外，我们还想要变换分子的&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;，将&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;改为&lt;span class=&#34;math inline&#34;&gt;\(\sqrt{E[\Delta\theta^2]_t+\epsilon}\)&lt;/span&gt;，便得到Adadelta的计算形式，以上内容可以总结为： &lt;span class=&#34;math display&#34;&gt;\[
E[g^2]_{t,i} = \gamma\times E[g^2]_{t-1,i} + (1-\gamma)\times g_{t,i}^2\\
E[\Delta\theta^2]_{t,i} = \gamma\times E[\Delta\theta^2]_{t-1,i} + (1-\gamma)\times \Delta\theta_{t,i}^2\\
\theta_{t+1,i} = \theta_{t,i} - \frac{\sqrt{E[\Delta\theta^2]_{t-1,i}+\epsilon}}{\sqrt{E[g^2]_{t,i}+\epsilon}}\times g_{t,i}
\]&lt;/span&gt; 显然，我们不再需要提前设定步长了。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adamadaptive-moment-estimation-optimizer-adam-optimizer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adam优化器（Adaptive Moment Estimation Optimizer, Adam Optimizer）&lt;/h2&gt;
&lt;p&gt;Adam也是个人名，圣经中说他是世上的第一个人类也是第一个男人，接着和夏娃结为夫妻，过上了幸福的生活…跑远了！回正题！其实Adam的全称中文是自适应矩估计，它不仅像Adadelta一样存储过去梯度平方&lt;span class=&#34;math inline&#34;&gt;\(v_t\)&lt;/span&gt;的平均值之外，还保留了像Momentum一样的保留了过去梯度&lt;span class=&#34;math inline&#34;&gt;\(m_t\)&lt;/span&gt;，其计算公式为： &lt;span class=&#34;math display&#34;&gt;\[
m_t = \beta_1m_{t-1} + (1-\beta_1)g_t\\
v_t = \beta_2v_{t-1} + (1-\beta_2)g_t^2
\]&lt;/span&gt; 由于&lt;span class=&#34;math inline&#34;&gt;\(m_t\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(v_t\)&lt;/span&gt;在计算上会存在偏差，所以进行了偏差校正： &lt;span class=&#34;math display&#34;&gt;\[
\hat{m_t} = \frac{m_t}{1-\beta_1^t}\\
\hat{v_t} = \frac{v_t}{1-\beta_2^t}
\]&lt;/span&gt; Adam的更新规则： &lt;span class=&#34;math display&#34;&gt;\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v_t}+\epsilon}}\times \hat{m_t}\]&lt;/span&gt; 其中，&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;通常取0.9，&lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt;通常取0.999，&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;通常取1e-8。大多实验表明，Adam比其他自适应学习算法表现更优。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;算法表现效果&lt;/h2&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;http://ruder.io/content/images/2016/09/saddle_point_evaluation_optimizers.gif&#34; alt=&#34;Figure7&#34; /&gt;
&lt;p&gt;
图7. 不同优化器的随机梯度下降法在鞍点处的不同表现
&lt;/div&gt;
&lt;p&gt;注：动图来源于Sebastian Ruder的文章，由&lt;a href=&#34;https://twitter.com/alecrad&#34;&gt;Alec Radford&lt;/a&gt;制作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;题外话（跳过这段吧~）&lt;/strong&gt;&lt;br /&gt;
在整理学习优化算法的时候，发现一件有趣的事。我边看着《Tensorflow入门与实战》的第四章边学习优化算法，同时网上边找找资料帮助理解。然而有趣的是我找到了一位业界大神Sebastian Ruder的主页，并看到了他在2016年1月6日写下了&lt;em&gt;An overview of gradient descent optimization algorithms&lt;/em&gt;。看着看着我发现手中拿的书竟然是电脑屏幕上显示的文章的中文版，我便好奇地寻找手中这本实战书的出版时间 —— 2018年2月17日。怪哉怪哉~再翻翻书，发现并无任何引用。算了，回归主题！（Reference选了日期比较前的S.R.大佬的文章作为引用）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;backpropagation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;反向传播算法（Backpropagation）&lt;/h1&gt;
&lt;p&gt;反向传播算法是目前用来训练人工神经网络（Artificial Neural Network，ANN）的最常用且最有效的算法。首先我们先定义变量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(v_i^{(l)}\)&lt;/span&gt;：第&lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;层的第&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;个节点的输入值，&lt;span class=&#34;math inline&#34;&gt;\(v_i^{(l)} = \sum_{j=0}^n w_{ij}^{(l)}a_j^{(l-1)} + b_i^{(l)}\)&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(a_i^{(l)}\)&lt;/span&gt;：第&lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;层的第&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;个节点的输出值，&lt;span class=&#34;math inline&#34;&gt;\(a_i^{(l)} = f(v_i^{(l)})\)&lt;/span&gt;，其中&lt;span class=&#34;math inline&#34;&gt;\(f(\cdot)\)&lt;/span&gt;是激活函数；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(w_{ij}^{(l)}\)&lt;/span&gt;：第&lt;span class=&#34;math inline&#34;&gt;\(l-1\)&lt;/span&gt;层的第&lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;个节点到第&lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;层的第&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;个节点的权值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_i^{(l)}\)&lt;/span&gt;：第&lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;层计算第&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;个节点的输入值时的偏置项的值；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;：神经网络的总层数；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(\cdot)\)&lt;/span&gt;：激活函数，例如sigmoid函数，tanh函数或者ReLu函数；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(L(w,b)\)&lt;/span&gt;：整体损失函数，常用的损失函数为&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{2n}\sum_{i=1}^n(y_i-f(x_i))^2\)&lt;/span&gt;，其中n是样本的个数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;反向传播计算过程的细节如下所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;参数初始化&lt;/strong&gt;&lt;br /&gt;
随机初始化网络中的各层的参数&lt;span class=&#34;math inline&#34;&gt;\(w_{ij}^{(l)}\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(b_i^{(l)}\)&lt;/span&gt;，且满足&lt;span class=&#34;math inline&#34;&gt;\(N(0,\ 0.01)\)&lt;/span&gt;分布的随机数；&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;前向传播&lt;/strong&gt;&lt;br /&gt;

&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;NN3.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以图3中隐藏层的第一个节点（从上往下数第一个）为例，对于这个节点而言，其输入信号为： &lt;span class=&#34;math display&#34;&gt;\[v_1^{(2)} = a_1^{(1)}\times w_{11}^{(2)} + a_2^{(1)}\times w_{12}^{(2)} + a_3^{(1)}\times w_{13}^{(2)} + b_1^{(2)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理，我们可以得到该层的其他节点的计算： &lt;span class=&#34;math display&#34;&gt;\[
v_2^{(2)} = a_1^{(1)}\times w_{21}^{(2)} + a_2^{(1)}\times w_{22}^{(2)} + a_3^{(1)}\times w_{23}^{(2)} + b_2^{(2)}\\
v_3^{(2)} = a_1^{(1)}\times w_{31}^{(2)} + a_2^{(1)}\times w_{32}^{(2)} + a_3^{(1)}\times w_{33}^{(2)} + b_3^{(2)}\\
v_4^{(2)} = a_1^{(1)}\times w_{41}^{(2)} + a_2^{(1)}\times w_{42}^{(2)} + a_3^{(1)}\times w_{43}^{(2)} + b_4^{(2)}\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;若用矩阵形式进行表达： &lt;span class=&#34;math display&#34;&gt;\[V^{(2)} = A^{(1)}\times W^{(2)} + B^{(2)}\]&lt;/span&gt; 其中， &lt;span class=&#34;math display&#34;&gt;\[
V^{(2)} = (v_1^{(2)}, v_2^{(2)}, v_3^{(2)}, v_4^{(2)})\\
A^{(1)} = (a_1^{(1)}, a_2^{(1)}, a_3^{(1)})\\
W^{(2)} = \begin{pmatrix}
w_{11}^{(2)} &amp;amp; w_{21}^{(2)} &amp;amp; w_{31}^{(2)} &amp;amp; w_{41}^{(2)}\\
w_{12}^{(2)} &amp;amp; w_{22}^{(2)} &amp;amp; w_{32}^{(2)} &amp;amp; w_{42}^{(2)}\\
w_{13}^{(2)} &amp;amp; w_{23}^{(2)} &amp;amp; w_{33}^{(2)} &amp;amp; w_{43}^{(2)}
\end{pmatrix}\\
B^{(2)} = (b_1^{(2)}, b_2^{(2)}, b_3^{(2)}, b_4^{(2)})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;再经过激活函数（非线性函数）变换后得到： &lt;span class=&#34;math display&#34;&gt;\[A^{(2)} = f(V^{(2)})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理，经由 &lt;span class=&#34;math display&#34;&gt;\[
V^{(3)} = A^{(2)}\times W^{(3)} + B^{(3)}\\
A^{(3)} = f(V^{(3)})
\]&lt;/span&gt; 可以得到最终输出。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;反向传播&lt;/strong&gt;&lt;br /&gt;
首先对于最后一层节点的偏导数，其实我们很容易得到，我们定义神经网络总共有&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;层，对于最后一层即第&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;层（输出层），根据偏导数的定义：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta_i^{(K)} =&amp;amp;\ \frac{\partial}{\partial v_i^{(K)}}L(w,b)\\
=&amp;amp;\ \frac{\partial L(w,b)}{\partial a_i^{(K)}}\times \frac{\partial a_i^{(K)}}{\partial v_i^{(K)}}\\
=&amp;amp;\ \frac{\partial L(w,b)}{\partial a_i^{(K)}}\times f&amp;#39;(v_i^{(K)})
\end{align}
\tag{4}
\]&lt;/span&gt; 明显的是，&lt;span class=&#34;math inline&#34;&gt;\(a_i^{(K)}\)&lt;/span&gt;是最后一层（即输出层）的输出值，&lt;span class=&#34;math inline&#34;&gt;\(f&amp;#39;(v_i^{(K)})\)&lt;/span&gt;则是激活函数对&lt;span class=&#34;math inline&#34;&gt;\(v_i^{(K)}\)&lt;/span&gt;的导数。&lt;/p&gt;
&lt;p&gt;对（4）式进一步推导可以得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta_i^{(K)} =&amp;amp;\ \frac{\partial}{\partial a_i^{(K)}}\Big[\frac{1}{2n_K}\sum_{j=1}^{n_K}\Big(y_j-a_j^{(K)}\Big)^2\Big]\times f&amp;#39;(v_i^{(K)})\\
=&amp;amp;\ -\frac{1}{n_k}(y_i-a_i^{(K)})\times f&amp;#39;(v_i^{(K)})
\end{align}
\]&lt;/span&gt; 其中，&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;是样本对应的正确值，&lt;span class=&#34;math inline&#34;&gt;\(n_K\)&lt;/span&gt;是第K层节点个数。&lt;/p&gt;
&lt;p&gt;因此，可得到最后一层（第K层）的计算公式： &lt;span class=&#34;math display&#34;&gt;\[
\delta_i^{(K)} = -\frac{1}{n_k}(y_i-a_i^{(K)})\times f&amp;#39;(v_i^{(K)})
\tag{5}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么对于第&lt;span class=&#34;math inline&#34;&gt;\(K-1\)&lt;/span&gt;层的偏导数，可以根据第&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;层的计算出来： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta_i^{(K-1)} =&amp;amp;\ \frac{\partial}{\partial v_i^{(K-1)}}L(w,b)\\
=&amp;amp;\ \frac{\partial}{\partial v_i^{(K-1)}}\Big[\frac{1}{2n_K}\sum_{j=1}^{n_K}\Big(y_j-a_j^{(K)}\Big)^2\Big]\\
=&amp;amp;\ \frac{1}{2n_K}\Big[\frac{\partial}{\partial v_i^{(K-1)}} \sum_{j=1}^{n_K}\Big(y_j-f(v_j^{(K)})\Big)^2\Big]
\end{align}
\tag{6}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;利用连续函数的求导和求和顺序可互换，（6）式可以推得： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta_i^{(K-1)} =&amp;amp;\ -\frac{1}{n_K} \sum_{j=1}^{n_K} \Big[(y_j-f(v_j^{(K)}))\times \frac{\partial}{\partial v_i^{(K-1)}}f(v_j^{(K)})\Big]\\
=&amp;amp;\ -\frac{1}{n_K} \sum_{j=1}^{n_K} \Big[(y_j-f(v_j^{(K)}))\times \frac{\partial f(v_j^{(K)})}{\partial v_i^{(K)}}\times \frac{\partial v_i^{(K)}}{\partial v_i^{(K-1)}} \Big]\\
=&amp;amp;\ \sum_{j=1}^{n_K} \Big[-\frac{1}{n_K} (y_j-f(v_j^{(K)}))\times f&amp;#39;(v_j^{(K)})\times \frac{\partial v_i^{(K)}}{\partial v_i^{(K-1)}} \Big]
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;联合（5）式，由（6）式可以得到： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\delta_i^{(K-1)} =&amp;amp;\ \sum_{j=1}^{n_K} \Big[ \delta_i^{(K)}\times \frac{\partial v_i^{(K)}}{\partial v_i^{(K-1)}} \Big]\\
=&amp;amp;\ \sum_{j=1}^{n_K}\Bigg[ \delta_i^{(K)}\times \frac{\partial }{\partial v_i^{(K-1)}}\Big[ \sum_{m=0}^{n_{K-1}}a_m^{(K-1)}\times w_{jm}^{(K)}+b_j^{(K)} \Big]\Bigg]\\
=&amp;amp;\ \sum_{j=1}^{n_K}\Bigg[ \delta_i^{(K)}\times \frac{\partial }{\partial v_i^{(K-1)}}\Big[ \sum_{m=0}^{n_{K-1}}f(v_m^{(K-1)})\times w_{jm}^{(K)}+b_j^{(K)} \Big]\Bigg]\\
=&amp;amp;\ \sum_{j=1}^{n_K}\Bigg[ \delta_i^{(K)}\times f&amp;#39;(v_i^{(K-1)})\times w_{ji}^{(K)} \Bigg]\\
=&amp;amp;\ \Bigg[\sum_{j=1}^{n_K}\Big[ \delta_i^{(K)}\times w_{ji}^{(K)} \Big]\Bigg] \times f&amp;#39;(v_i^{(K-1)})
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，可得到第K-1层的计算公式： &lt;span class=&#34;math display&#34;&gt;\[
\delta_i^{(K-1)} = \Bigg[\sum_{j=1}^{n_K}\Big[ \delta_i^{(K)}\times w_{ji}^{(K)} \Big]\Bigg] \times f&amp;#39;(v_i^{(K-1)})
\tag{7}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同理，用&lt;span class=&#34;math inline&#34;&gt;\(K-2\)&lt;/span&gt;替换&lt;span class=&#34;math inline&#34;&gt;\(K-1\)&lt;/span&gt;，用&lt;span class=&#34;math inline&#34;&gt;\(K-1\)&lt;/span&gt;替换&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;，则可计算第&lt;span class=&#34;math inline&#34;&gt;\(K-2\)&lt;/span&gt;层的偏导数。 &lt;span class=&#34;math display&#34;&gt;\[
\delta_i^{(K-2)} = \Bigg[\sum_{j=1}^{n_{K-1}}\Big[ \delta_i^{(K-1)}\times w_{ji}^{(K-1)} \Big]\Bigg] \times f&amp;#39;(v_i^{(K-2)})
\tag{7}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同样的，可以根据（7）式计算得到网络中所有节点的偏导数。&lt;/p&gt;
&lt;p&gt;回归我们的参数迭代公式： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
w_{ij}^{(l)} =&amp;amp;\ w_{ij}^{(l)} - \alpha\times \frac{\partial}{\partial w_{ij}^{(l)}}L(w,b)\\
b_i^{(l)} =&amp;amp;\ b_i^{(l)} - \alpha\times \frac{\partial}{\partial b_i^{(l)}}L(w,b)
\end{align}
\tag{8}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对于后面的偏导数部分，我们可以加以处理，对于参数&lt;span class=&#34;math inline&#34;&gt;\(w_{ij}^{(l)}\)&lt;/span&gt;部分： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\frac{\partial L(w,b)}{\partial w_{ij}^{(l)}} =&amp;amp;\ \frac{\partial L(w,b)}{\partial v_i^{(l)}}\times \frac{\partial  v_i^{(l)}}{\partial w_{ij}^{(l)}}\\
=&amp;amp;\ \delta_i^{(l)}\times \frac{\partial v_i^{(l)}}{\partial w_{ij}^{(l)}}\\
=&amp;amp;\ \delta_i^{(l)}\times \frac{\partial }{\partial w_{ij}^{(l)}}\Big[\sum_{j=0}^{n_{l-1}}a_j^{(l-1)}\times w_{ij}^{(l)}+b_i^{(l)}\Big]\\
=&amp;amp;\ \delta_i^{(l)}\times a_j^{(l-1)}
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对于参数&lt;span class=&#34;math inline&#34;&gt;\(b_i^{(l)}\)&lt;/span&gt;部分： &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\frac{\partial L(w,b)}{\partial b_i^{(l)}} =&amp;amp;\ \frac{\partial L(w,b)}{\partial v_i^{(l)}}\times \frac{\partial v_i^{(l)}}{\partial b_i^{(l)}}\\
=&amp;amp;\ \delta_i^{(l)}\times \frac{\partial}{\partial b_i^{(l)}}\Big[\sum_{j=0}^{n_{l-1}}a_j^{(l-1)}\times w_{ij}^{(l)}+b_i^{(l)}\Big]\\
=&amp;amp;\ \delta_i^{(l)}
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因此，由（8）式可以推得 &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
w_{ij}^{(l)} =&amp;amp;\ w_{ij}^{(l)} - \alpha\times \delta_i^{(l)}\times a_j^{(l-1)}\\
b_i^{(l)} =&amp;amp;\ b_i^{(l)} - \alpha\times \delta_i^{(l)}
\end{align}
\tag{8}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Over！反向传播算法到此结束！&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://ruder.io/optimizing-gradient-descent/index.html&#34;&gt;Sebastian Ruder. An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>关于Rmarkdown生成中文内容pdf的那些事</title>
      <link>/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</guid>
      <description>


&lt;p&gt;缘于某人用Rmarkdown搞不出中文内容的pdf而引发一场激战之下，TT只能忍气吞声继续走上帮人帮到底的道路，于是网上搜出一大堆关于Rmarkdown生成中文pdf的麻烦事。无奈，众里寻它千百度，最终发现解决问题的YAML模板及相关的解决方案，怕在接下来的日子可能遭受同样的折磨，并以扩充Blog文章为前提，书写此文。&lt;/p&gt;
首先，让我们先在RStudio菜单栏选择Tools并点击Global Options。选择Sweaver并按图勾选，最后点OK~
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;RMD2PDF.PNG&#34; width = &#34;500&#34; height = &#34;470&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
Figure1. 可爱的Global Options窗口
&lt;/div&gt;
&lt;p&gt;然后.Rmd文件中的YAML模板如下设置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- 
title: &amp;quot;我是一个Test文档的标题&amp;quot; 
author: &amp;quot;我是一个Test文档的作者名称&amp;quot; 
date: &amp;quot;我是一个Test文档的写作日期&amp;quot; 
CJKmainfont: Microsoft YaHei
output:
  pdf_document:
    includes:
      header-includes:
        - \usepackage{xeCJK}
    keep_tex: yes
    latex_engine: xelatex
---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注：介个模板用上了大微软的雅黑字体，如若想修改，那请继续摸索摸索。（T.T累了不想改了~）&lt;/p&gt;
&lt;p&gt;搞定！Over！愿你的探索之路不与我一样艰辛((٩(//̀Д/́/)۶))&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;课外补充：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关于Rmarkdown to pdf的美好世界&lt;br /&gt;
如果你也被这样的问题所困扰，那么你会发现R界的大佬&lt;a href=&#34;https://yihui.name/&#34;&gt;谢益辉&lt;/a&gt;搞了个包叫&lt;a href=&#34;https://github.com/rstudio/rticles&#34;&gt;rticles&lt;/a&gt;，直接提供template给你写中文文档。然而，无奈Tex世界的混乱，还是遇到奇奇怪怪的乱七八糟的问题，但是大佬说大家用&lt;a href=&#34;https://yihui.name/tinytex/&#34;&gt;TinyTex&lt;/a&gt;吧，那将提供Rmarkdown to pdf的一片美好世界。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Variational Auto-Encoder</title>
      <link>/post/variational-auto-encoder/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/variational-auto-encoder/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;We assume the observed variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a random sample from an &lt;strong&gt;unknown underlying process&lt;/strong&gt;, whose &lt;strong&gt;true distribution&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(p^*(x)\)&lt;/span&gt; is &lt;strong&gt;unknown&lt;/strong&gt;. We attempt to approximate this underlying process with a chosen model &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x)\)&lt;/span&gt;, with parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[x\sim p_{\theta}(x)\]&lt;/span&gt; We always talk about learning like &lt;strong&gt;Deep Learning&lt;/strong&gt;, and actually the &lt;strong&gt;learning&lt;/strong&gt; is the process of searching for a value of the parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; in model &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x)\)&lt;/span&gt;, which can approximate the true distribution of the data, denoted by &lt;span class=&#34;math inline&#34;&gt;\(p^*(x)\)&lt;/span&gt;. In other words, &lt;span class=&#34;math display&#34;&gt;\[p_{\theta}(x)\approx p^*(x)\]&lt;/span&gt; Latent variables are variables that are part of the model, but which we don’t observe, and are therefore not part of the dataset. We typically use &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; to denote such latent variables.&lt;/p&gt;
&lt;p&gt;The marginal distribution over the observed variables &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x)\)&lt;/span&gt;, is given by: &lt;span class=&#34;math display&#34;&gt;\[
p_{\theta}(x) = \int p_{\theta}(x,z) dz = \int p_{\theta}(z) p_{\theta}(x|z) dz
\]&lt;/span&gt; We use the term &lt;strong&gt;deep latent variable model (DLVM)&lt;/strong&gt; to denote a &lt;strong&gt;latent variable model&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x,z)\)&lt;/span&gt; whose distributions are parameterized by neural networks.&lt;/p&gt;
&lt;div id=&#34;example-dlvm-for-multivariate-bernoulli-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example DLVM for multivariate Bernoulli data&lt;/h2&gt;
&lt;p&gt;A simple example DLVM for binary data &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, with a spherical Gaussian latent space, and a factorized Bernoulli obervation model &lt;span class=&#34;math display&#34;&gt;\[
p(z) = \mathcal{N}(0,\text{I})\\
\text{p} = \text{DecoderNeuralNet}_{\theta}(z)\\
\begin{align}
\log p(x|z) =&amp;amp; \sum_{j=1}^J \log p(x_j|z) = \sum_{j=1}^J \text{Bernoulli}(x_j,p_j)\\
=&amp;amp; \sum_{j=1}^Jx_j \log p_j + (1-x_j)\log (1-p_j)
\end{align}
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(0\leq p_j\leq 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, we easily get &lt;span class=&#34;math inline&#34;&gt;\(p(x,z) = p(x|z)\times p(z)\)&lt;/span&gt; by the term we described above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some problem&lt;/h2&gt;
&lt;p&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x,z)\)&lt;/span&gt; is efficient to compute. Since the intractability of &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x)\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x) = \int p_{\theta}(x,z) dz\)&lt;/span&gt;), the posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(z|x)\)&lt;/span&gt; is also intractable, because their densities are related through the basic identity: &lt;span class=&#34;math display&#34;&gt;\[p_{\theta}(z|x) = \frac{p_{\theta}(x,z)}{p_{\theta}(x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;How can we perform efficient approximate posterior inference and efficient approximate maximum likelihood estimation in deep latent variable models, in the presence of large datasets?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;similar-method-like-dlvm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Similar method like DLVM&lt;/h2&gt;
&lt;p&gt;We introduce a parametric inference model &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x)\)&lt;/span&gt; (also called as &lt;strong&gt;encoder&lt;/strong&gt;)in this part and we try to optimize the variational parameters &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; such that: &lt;span class=&#34;math display&#34;&gt;\[q_{\phi}(z|x) \approx p_{\theta}(z|x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Similar to &lt;strong&gt;DLVM&lt;/strong&gt;, the distribution of &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x)\)&lt;/span&gt; also can be parameterized using deep neural networks. In this case, the variational parameters &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; include the weights and biases of the neural network. For example: &lt;span class=&#34;math display&#34;&gt;\[
(\mu,\sigma) = \text{EncoderNeuralNet}_{\phi}(x)\\
q_{\phi}(z|x) = \mathcal{N}(\mu,\text{diag}(\sigma^2))
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;evidence-lower-bound-elbo-and-kl-divergence&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Evidence lower bound (ELBO) and KL divergence&lt;/h1&gt;
&lt;p&gt;The optimization objective of the variational autoencoder is the &lt;strong&gt;evidence lower bound&lt;/strong&gt;, abbreviated as ELBO. An alternative term for this objective is &lt;strong&gt;variational lower bound&lt;/strong&gt;. We can obtain the lower bound by: &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\log p_{\theta}(x) =&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x)] = \mathbb{E}_{q_{\phi}(z|x)} \Big[\log\Big[ \frac{p_{\theta}(x,z)}{p_{\theta}(z|x)}\Big]\Big]\\
=&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x)}\Big[\log\Big[\frac{p_{\theta}(x,z)}{q_{\phi}(z|x)}\frac{q_{\phi}(z|x)}{p_{\theta}(z|x)}\Big]\Big]\\
=&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x)}\Big[\log\Big[\frac{p_{\theta}(x,z)}{q_{\phi}(z|x)}\Big]\Big] + \mathbb{E}_{q_{\phi}(z|x)}\Big[\log\Big[\frac{q_{\phi}(z|x)}{p_{\theta}(z|x)}\Big]\Big]\\
=&amp;amp;\ \mathcal{L}_{\theta,\phi}(x) + KL[q_{\phi}(z|x)||p_{\theta}(z|x)]\\
\geq&amp;amp;\ \mathcal{L}_{\theta,\phi}(x)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;kl-divergence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;KL divergence&lt;/h2&gt;
&lt;p&gt;We want to find a good probability distribution &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x)\)&lt;/span&gt; (‘good’ means the efficient computation) to approximate the true posterior probability &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(z|x)\)&lt;/span&gt;, where the &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; is the latent variable. &lt;strong&gt;KL divergence&lt;/strong&gt; can measure the distance well between these two distribution. For the discrete probability situation, the &lt;strong&gt;KL divergence&lt;/strong&gt; can be written as &lt;span class=&#34;math display&#34;&gt;\[KL(q||p) = \sum q(x)\log \frac{q(x)}{p(x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;example-of-1-dimension-guassian-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example of 1-dimension Guassian distribution&lt;/h3&gt;
&lt;p&gt;Supposed that we have two random variables &lt;span class=&#34;math inline&#34;&gt;\(x_1, x_2\)&lt;/span&gt; w.r.t the guassian distribution &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}(\mu_1,\sigma_1^2),\mathcal{N}(\mu_2,\sigma_2^2)\)&lt;/span&gt; respectively.&lt;/p&gt;
&lt;p&gt;Recall that the density function of guassian distribution &lt;span class=&#34;math display&#34;&gt;\[
\mathcal{N}(\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]&lt;/span&gt; Then &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL(p_1,p_2) =&amp;amp;\ \int p_1(x)\log \frac{p_1(x)}{p_2(x)}dx\\
=&amp;amp;\ \int p_1(x)(\log p_1(x) - \log p_2(x))dx\\
=&amp;amp;\ \int p_1(x)(\log \frac{1}{\sqrt{2\pi\sigma_1^2}}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}} - \log \frac{1}{\sqrt{2\pi\sigma_2^2}}e^{-\frac{(x-\mu_2)^2}{2\sigma_2^2}})dx\\
=&amp;amp;\ \int p_1(x)(-\log \sqrt{2\pi \sigma_1^2} - \frac{(x-\mu_1)^2}{2\sigma_1^2} + \log \sqrt{2\pi \sigma_2^2} + \frac{(x-\mu_2)^2}{2\sigma_2^2})dx\\
=&amp;amp;\ \int p_1(x)(-\frac{1}{2}\log2\pi-\log\sigma_1+\frac{1}{2}\log2\pi+\log\sigma_2 - (\frac{(x-\mu_1)^2}{2\sigma_1^2}-\frac{(x-\mu_2)^2}{2\sigma_2^2}))dx\\
=&amp;amp;\ \int p_1(x)(\log\frac{\sigma_2}{\sigma_1} - (\frac{(x-\mu_1)^2}{2\sigma_1^2}-\frac{(x-\mu_2)^2}{2\sigma_2^2}))dx\\
=&amp;amp;\ \int p_1(x)(\log\frac{\sigma_2}{\sigma_1})dx + \int p_1(x)(\frac{(x-\mu_2)^2}{2\sigma_2^2})dx - \int p_1(x)(\frac{(x-\mu_1)^2}{2\sigma_1^2})dx\\
=&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{1}{2\sigma_2^2}\int p_1(x)(x-\mu_2)^2dx - \frac{1}{2\sigma_1^2}\int p_1(x)(x-\mu_1)^2dx
\end{align}
\]&lt;/span&gt; Since &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = \int p_1(x)(x-\mu_1)^2dx\)&lt;/span&gt;, then &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL(p_1,p_2) =&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{1}{2\sigma_2^2}\int p_1(x)(x-\mu_2)^2dx - \frac{1}{2}\\
=&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{1}{2\sigma_2^2}\int p_1(x)(x - \mu_1 + \mu_1 - \mu_2)^2dx - \frac{1}{2}\\
=&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{1}{2\sigma_2^2}[\int p_1(x)(x-\mu_1)^2dx+\int p_1(x)(\mu_1-\mu_2)^2dx+2\int p_1(x)(x-\mu_1)(\mu_1-\mu_2)dx] - \frac{1}{2}\\
\end{align}
\]&lt;/span&gt; We know that &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 = \int x p_1(x)dx\)&lt;/span&gt;, so &lt;span class=&#34;math inline&#34;&gt;\(2\int p_1(x)(x-\mu_1)(\mu_1-\mu_2)dx = 2(\mu_1-\mu_2)[\int xp_1(x)dx - \mu_1] = 0\)&lt;/span&gt;, thus &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL(p_1,p_2) =&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{1}{2\sigma_2^2}[\int p_1(x)(x-\mu_1)^2dx + (\mu_1-\mu_2)^2] - \frac{1}{2}\\
=&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2+(\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}\\
\end{align}
\]&lt;/span&gt; If we suppose that the &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}(\mu_2,\sigma_2^2)\)&lt;/span&gt; is standard guassian distribution, &lt;span class=&#34;math inline&#34;&gt;\(\mu_2 = 0, \sigma_2^2 = 1\)&lt;/span&gt;, so &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL =&amp;amp;\ \log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2+(\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}\\
=&amp;amp;\ \log1 - \log\sigma_1 + \frac{\sigma_1^2+(\mu_1 - 0)^2}{2} - \frac{1}{2}\\
=&amp;amp;\ -\log\sigma_1 + \frac{\sigma_1^2+\mu_1^2}{2} - \frac{1}{2}\\
\end{align}
\]&lt;/span&gt; We expect that the &lt;strong&gt;KL&lt;/strong&gt; can be as small as possible, we calculate its derivative, then we get &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial KL}{\partial \sigma_1} = -\frac{1}{\sigma_1} + \sigma_1\\
\frac{\partial KL}{\partial \mu_1} = \mu_1
\]&lt;/span&gt; We let them equal to zero, then we get &lt;span class=&#34;math display&#34;&gt;\[
-\frac{1}{\sigma_1} + \sigma_1 = 0 \Rightarrow \sigma_1 = 1\\
\mu_1 = 0
\]&lt;/span&gt; which means that the &lt;strong&gt;KL&lt;/strong&gt; becomes the minimum when &lt;span class=&#34;math inline&#34;&gt;\(x_2 \sim \mathcal{N}(0,1)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;minimization-of-kl-divergence&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Minimization of KL divergence&lt;/h3&gt;
&lt;p&gt;If we want to use the ELBO to approximate the log-likelihood, then we need to minimize the &lt;span class=&#34;math inline&#34;&gt;\(D_{KL}[q_{\phi}(z|x)||p_{\theta}(z|x)]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;From &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL[q_{\phi}(z|x)||p_{\theta}(z|x)] =&amp;amp;\ \int q_{\phi}(z|x) \log \frac{q_{\phi}(z|x)}{p_{\theta}(z|x)} dz\\
=&amp;amp;\ \int q_{\phi}(z|x) [\log q_{\phi}(z|x) - \log  p_{\theta}(z|x)]dz
\end{align}
\]&lt;/span&gt; and Bayesian formula &lt;span class=&#34;math display&#34;&gt;\[
p_{\theta}(z|x) = \frac{p_{\theta}(x|z)*p_{\theta}(z)}{p_{\theta}(x)}
\]&lt;/span&gt; We can get &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL[q_{\phi}(z|x)||p_{\theta}(z|x)] =&amp;amp;\ \int q_{\phi}(z|x) [\log q_{\phi}(z|x) - \log  \frac{p_{\theta}(x|z)*p_{\theta}(z)}{p_{\theta}(x)}]dz\\
=&amp;amp;\ \int q_{\phi}(z|x) [\log q_{\phi}(z|x) -\log  p_{\theta}(x|z) - \log p_{\theta}(z) + \log p_{\theta}(x)]dz\\
=&amp;amp;\  \int q_{\phi}(z|x) [\log q_{\phi}(z|x) -\log  p_{\theta}(x|z) - \log p_{\theta}(z)]dz + \log p_{\theta}(x)\\
=&amp;amp;\ KL[q_{\phi}(z|x)||p_{\theta}(z)] - \int q_{\phi}(z|x) \log p_{\theta}(x|z)dz + \log p_{\theta}(x)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When the data &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; are provided, then last term in the right side &lt;span class=&#34;math inline&#34;&gt;\(\log p_{\theta}(x)\)&lt;/span&gt; becomes constant, and we wish the &lt;span class=&#34;math inline&#34;&gt;\(D_{KL}[q_{\phi}(z|x)||p_{\theta}(z|x)]\)&lt;/span&gt; can be as small as possible.&lt;/p&gt;
&lt;p&gt;Thus, the optimization problem becomes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\min\limits_x D_{KL}[q_{\phi}(z|x)||p_{\theta}(z)]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\max\limits_x \int q_{\phi}(z|x) \log p_{\theta}(x|z)dz\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It also can be written as &lt;span class=&#34;math display&#34;&gt;\[\min_x KL[q_{\phi}(z|x)||p_{\theta}(z)] - \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Although we can obtain our new optimization problem, the problem actually is difficult to solve, and thus we would like to straightly optimize the &lt;strong&gt;ELBO&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;variational-auto-encoder&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Variational Auto-Encoder&lt;/h1&gt;
&lt;div id=&#34;connection-with-em&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Connection with EM&lt;/h2&gt;
&lt;p&gt;For standard EM algorithms, the posterior is often known, &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x) = q(z|x) = p_{\theta}(z|x)\)&lt;/span&gt;, then the &lt;strong&gt;KL&lt;/strong&gt; term becomes zero, so &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\log p_{\theta}(x) = \mathcal{L}_{\theta}(x) =&amp;amp;\ \mathbb{E}_{q(z|x)}\Big[\log\Big[\frac{p_{\theta}(x,z)}{q(z|x)}\Big]\Big]\\
=&amp;amp;\ \mathbb{E}_{q(z|x)}[\log p_{\theta}(x,z)] - \mathbb{E}_{q(z|x)}[\log q(z|x)]
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above step is indeed the E-step in the standard EM algorithm. The M-step would be &lt;span class=&#34;math display&#34;&gt;\[\theta_{\text{new}} = \arg \max_\theta L_{\theta}(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stochastic-gradient-based-optimization-of-the-elbo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stochastic gradient-based optimization of the ELBO&lt;/h2&gt;
&lt;p&gt;From the &lt;strong&gt;Evidence lower bound (ELBO)&lt;/strong&gt; part, we obtain the inequality fomula as &lt;span class=&#34;math inline&#34;&gt;\(\log p_{\theta}(x) \geq \mathcal{L}_{\theta,\phi}(x)\)&lt;/span&gt;. Recall that EM algorithm is one of the special case of Minorize-Maximization (MM) algorithm, and &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{L}_{\theta,\phi}(x)\)&lt;/span&gt; can be considered as the surrogate function in MM algorithm, so we would get the maximum of log-likelihood by maximizing the lower bound.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;VAE1.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
Figure1. The EM algorithm involves alternatel computing a lower bound on the log likelihood for the current parameter values and then maximizing this bound to obtain the new parameter values.
&lt;/div&gt;
&lt;p&gt;Given a dataset with i.i.d. data, the ELBO objective is the sum (or average) of individual-datapoint ELBO’s: &lt;span class=&#34;math display&#34;&gt;\[
\mathcal{L}_{\theta,\phi}(\mathcal{D})=\sum_{x\in\mathcal{D}}\mathcal{L}_{\theta,\phi}(x)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Apparantly, the individual-datapoint ELBO and its gradient &lt;span class=&#34;math inline&#34;&gt;\(\nabla_{\theta,\phi}\mathcal{L}_{\theta,\phi}(x)\)&lt;/span&gt; is intractable in general.&lt;/p&gt;
&lt;div id=&#34;the-sgvb-estimator-and-auto-encoding-vb-aevb-algorithm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The SGVB estimator and Auto-Encoding VB (AEVB) algorithm&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Reparamterization trick&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; be a continuous random variable and &lt;span class=&#34;math inline&#34;&gt;\(z\sim q_{\phi}(z|x)\)&lt;/span&gt; be some conditional distribution. It is often possible to express the random variable &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; as a deterministic variable &lt;span class=&#34;math inline&#34;&gt;\(z=g_{\phi}(\epsilon,x)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is an auxiliary variable with independent marginal &lt;span class=&#34;math inline&#34;&gt;\(p(\epsilon)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We suppose that the recognition model &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x)\)&lt;/span&gt; can be written as some differentiable transformation of another randome variable &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g_{\phi}(\epsilon,x)\)&lt;/span&gt;, and we can form a simple Monte Carlo estimator &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\mathcal{L}}_{\theta,\phi}(x)\)&lt;/span&gt; of the individual-datapoint ELBO: &lt;span class=&#34;math display&#34;&gt;\[
\epsilon \sim p(\epsilon)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;so we can get our generic Stochastic Gradient Variational Bayes (SGVB) estimator from the lower bound &lt;span class=&#34;math display&#34;&gt;\[
\tilde{\mathcal{L}}_{\theta,\phi}^{A}(x^{(i)}) = \frac{1}{L}\sum_{l=1}^L[\log p_{\theta}(x^{(i)},z^{(i,l)}) - \log q_{\phi}(z^{(i,l)}|x^{(i)})]
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(z^{(i,l)} = g_{\phi}(\epsilon^{(i,l)},x^{(i)}),\quad \epsilon^{(i,l)} \sim p(\epsilon)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We try to decompose the &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{L}_{\theta,\phi}(x)\)&lt;/span&gt;, and we get &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\mathcal{L}_{\theta,\phi}(x^{(i)}) =&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x^{(i)})}\Big[\log\frac{p_{\theta}(x^{(i)},z)}{q_{\phi}(z|x^{(i)})}\Big]\\
=&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x^{(i)})}\Big[\log\frac{p_{\theta}(x^{(i)}|z)p_{\theta}(z)}{q_{\phi}(z|x^{(i)})}\Big]\\
=&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x^{(i)})}\Big[\log p_{\theta}(x^{(i)}|z)-\log\frac{q_{\phi}(z|x^{(i)})}{p_{\theta}(z)}\Big]\\
=&amp;amp;\ \mathbb{E}_{q_{\phi}(z|x^{(i)})}[\log p_{\theta}(x^{(i)}|z)]-KL[q_{\phi}(z|x^{(i)})||p_{\theta}(z)]
\end{align}
\]&lt;/span&gt; The final equality showed the same object result (In Minimization of KL divergence section).&lt;/p&gt;
&lt;p&gt;With this equality, we also can obtain another estimator &lt;span class=&#34;math display&#34;&gt;\[
\tilde{\mathcal{L}}_{\theta,\phi}^{B}(x^{(i)}) = \mathbb{E}_{q_{\phi}(z|x^{(i)})}[\log p_{\theta}(x^{(i)}|z)]-KL[q_{\phi}(z|x^{(i)})||p_{\theta}(z)]\\
=\frac{1}{L}\sum_{l=1}^L\log p_{\theta}(x^{(i)}|z^{(i,l)})-KL[q_{\phi}(z|x^{(i)})||p_{\theta}(z)]
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(z^{(i,l)} = g_{\phi}(\epsilon^{(i,l)},x^{(i)}),\quad \epsilon^{(i,l)} \sim p(\epsilon)\)&lt;/span&gt;. Given multiple datapoints from a dataset &lt;span class=&#34;math inline&#34;&gt;\(\text{X}\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; datapoints, we can construct an estimator of the marginal likelihood lower bound of the full dataset, based on minibatches: &lt;span class=&#34;math display&#34;&gt;\[
\mathcal{L}_{\theta,\phi}(\text{X})\simeq\tilde{\mathcal{L}}_{\theta,\phi}^{M}(\text{X}^M)=\frac{N}{M}\sum_{i=1}^M\tilde{\mathcal{L}}_{\theta,\phi}(x^{(i)})
\]&lt;/span&gt; where the minibatch &lt;span class=&#34;math inline&#34;&gt;\(\text{X}^M=\{x^{(i)}\}_{i=1}^M\)&lt;/span&gt; is randomly drawn sample of &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; datapoints from the full dataset &lt;span class=&#34;math inline&#34;&gt;\(\text{X}\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; datapoints. In the paper &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;, author set &lt;span class=&#34;math inline&#34;&gt;\(M = 100, L = 1\)&lt;/span&gt; in their experiments.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;VAE2.PNG&#34; width = &#34;700&#34; height = &#34;250&#34; alt=&#34;Figure2&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;variational-auto-encoder-with-specific-case&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variational Auto-Encoder with specific case&lt;/h2&gt;
&lt;p&gt;We know that we can not perform the algorithm that we describe above, because we don’t know the distributions of &lt;span class=&#34;math inline&#34;&gt;\(\epsilon, p_{\theta}(x|z), q_{\phi}(z|x), p_{\theta}(z)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g_{\phi}(\epsilon,x)\)&lt;/span&gt;. In reality, like author described in the paper, we firstly let the prior over the latent variables be the centered isotropic multivariate Guassian &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(z) = \mathcal{N}(0,\text{I})\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;variational-approxiamte-posterior-q_phizxi&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variational approxiamte posterior &lt;span class=&#34;math inline&#34;&gt;\(q_{\phi}(z|x^{(i)})\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Let the variational approxiamte posterior be a multivariate Guassian with a diagonal covariance structure: &lt;span class=&#34;math display&#34;&gt;\[
q_{\phi}(z|x^{(i)}) = \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\mu^{(i)},\sigma^{(i)}\)&lt;/span&gt; denote the variational mean and s.d. evaluated by datapoint &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Then a valid reparameterization is &lt;span class=&#34;math inline&#34;&gt;\(z=\mu+\sigma\epsilon\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is an auxiliary noise variable &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\sim \mathcal{N}(0,\text{I})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; be the dimensionality of &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu^{(i)}_j, \sigma^{(i)}_j\)&lt;/span&gt; denote the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th element. Recall that &lt;span class=&#34;math display&#34;&gt;\[
\mathbb{E}[z] = \int z p(z) dz\\
\mathbb{E}[z^2] = \int z^2 p(z) dz\\
\text{Var}[z] = \mathbb{E}[z^2] - \mathbb{E}^2[z]
\]&lt;/span&gt; Then, &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\int q_{\phi}(z|x^{(i)})\log p_{\theta}(z)dz =&amp;amp;\ \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})\log \mathcal{N}(0,\text{I})dz\\
=&amp;amp;\ \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})(\log \frac{1}{\sqrt{2\pi}})dz - \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I}) \frac{z^2}{2}dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi)\int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})dz - \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I}) \frac{z^2}{2}dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\int z^2 \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J\mathbb{E}_{ q_{\phi}(z_j|x^{(i)})}[z_j^2]\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J\Big[\mathbb{E}_{ q_{\phi}(z_j|x^{(i)})}^2[z_j]+\text{Var}_{ q_{\phi}(z_j|x^{(i)})}[z_j]\Big]\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J(\mu_j^2+\sigma_j^2)
\end{align}
\]&lt;/span&gt; and &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\int q_{\phi}(z|x^{(i)})\log q_{\phi}(z|x^{(i)})dz =&amp;amp;\ \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})\log \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})dz\\
=&amp;amp;\ \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})\log \Big[\frac{1}{\sqrt{2\pi\sigma^{(i)^2}}}\exp(\frac{-(z-\mu^{(i)})^2}{2\sigma^{(i)^2}})\Big]dz\\
=&amp;amp;\ \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})\Big[-\frac{1}{2}\log 2\pi - \frac{1}{2}\log \sigma^{(i)^2} - \frac{(z-\mu^{(i)})^2}{2\sigma^{(i)^2}}\Big]dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})\Big[\frac{\log \sigma^{(i)^2}}{2} - \frac{(z-\mu^{(i)})^2}{2\sigma^{(i)^2}}\Big]dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \int \mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I}) \Big[\frac{1}{2}\log \sigma^{(i)^2} - \frac{z^2-2\mu^{(i)}z+\mu^{(i)^2}}{2\sigma^{(i)^2}}\Big]dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{J=1}^J\log \sigma_j^{(i)^2} + \int \frac{1}{2\sigma^{(i)^2}}\mathcal{N}(\mu^{(i)},\sigma^{(i)^2}\text{I})(z^2-2\mu^{(i)}z+\mu^{(i)^2})dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J\log \sigma_j^{(i)^2} + \frac{1}{2}\sum_{j=1}^J\frac{\mu^{(i)^2}+\sigma^{(i)^2}-2\mu^{(i)^2}+\mu^{(i)^2}}{\sigma^{(i)^2}}\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J(1+\log \sigma_j^{(i)^2})
\end{align}
\]&lt;/span&gt; Therefore, &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
-KL[q_{\phi}(z|x^{(i)})||p_{\theta}(z)] =&amp;amp; - \int q_{\phi}(z|x^{(i)})\log \frac{q_{\phi}(z|x^{(i)})}{p_{\theta}(z)}dz\\
=&amp;amp;\ - \int q_{\phi}(z|x^{(i)})[\log q_{\phi}(z|x^{(i)}) - \log p_{\theta}(z)]dz\\
=&amp;amp;\ \int q_{\phi}(z|x^{(i)})[\log p_{\theta}(z) - \log q_{\phi}(z|x^{(i)})]dz\\
=&amp;amp;\ -\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J(\mu_j^2+\sigma_j^2) - \Big[-\frac{J}{2}\log(2\pi) - \frac{1}{2}\sum_{j=1}^J(1+\log \sigma_j^{(i)^2})\Big]\\
=&amp;amp;\ \frac{1}{2}\sum_{j=1}^J(1+\log \sigma_j^{(i)^2}-\mu_j^2-\sigma_j^2)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;true-posterior-p_thetaxz&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;True posterior &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x|z)\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;We supposed that the true posterior &lt;span class=&#34;math inline&#34;&gt;\(p_{\theta}(x|z)\)&lt;/span&gt; be a multivariate Gaussian (in case of real-valued data) or Bernoulli (in case of binary data) whose distribution parameters are computed from &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; with a MLP (Multi-Layer Perceptron).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bernoulli MLP as decoder&lt;/strong&gt;&lt;br /&gt;
If the data are binary data, then we would choose &lt;span class=&#34;math display&#34;&gt;\[
\log p_{\theta}(x|z) = \sum_{j=1}^Dx_j \log y_j + (1-x_j)\log (1-y_j)
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(y = f_\sigma(W_2\tanh(W_1z+b_1)+b_2)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(f_\sigma(\cdot)\)&lt;/span&gt; is the elementwise sigmoid activation function and &lt;span class=&#34;math inline&#34;&gt;\(\theta=\{W_1,W_2,b_1,b_2\}\)&lt;/span&gt; are the weights and biases of the MLP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gaussian MLP as decoder&lt;/strong&gt;&lt;br /&gt;
Let decoder be a mutivariate Guassian with a diagonal covariance structure: &lt;span class=&#34;math display&#34;&gt;\[
\log p_{\theta}(x|z) = \log \mathcal{N}(\mu,\sigma^2\text{I})
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\mu = W_4h+b_4,\ \log\sigma^2 = W_5h+b_5,\ h = \tanh(W_3Z+b_3)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\{W_3,W_4,W_5,b_3,b_4,b_5\}\)&lt;/span&gt; are the weights and biases of the MLP and part of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analysis in case of binary data&lt;/strong&gt;&lt;br /&gt;
Recall the second estimator we describe above &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\mathcal{L}_{\theta,\phi}(\text{X})\simeq&amp;amp;\ \tilde{\mathcal{L}}_{\theta,\phi}^{B}(x^{(i)})\\
=&amp;amp;\ \frac{1}{L}\sum_{l=1}^L\log p_{\theta}(x^{(i)}|z^{(i,l)}) - KL[q_{\phi}(z|x^{(i)})||p_{\theta}(z)]\\
=&amp;amp;\ \frac{1}{L}\sum_{l=1}^L\log p_{\theta}(x^{(i)}|z^{(i,l)}) + \frac{1}{2}\sum_{j=1}^J(1+\log \sigma_j^{(i)^2}-\mu_j^2-\sigma_j^2)
\end{align}
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(z^{(i,l)} = \mu^{(i)} + \sigma^{(i)}\epsilon^{(l)}, \epsilon^{l}\sim p(\epsilon)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\log p_{\theta}(x|z) = \sum_{j=1}^Dx_j \log y_j + (1-x_j)\log (1-y_j)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-variational-auto-encoder-in-python&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using Variational Auto-Encoder in python&lt;/h1&gt;
&lt;div id=&#34;import-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import packages&lt;/h2&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;function-for-visualizing-batch-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Function for visualizing batch images&lt;/h2&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def VisConcatImg(batch_images, title):
    batch_size = np.shape(batch_images)[0]
    sqrt_size = int(batch_size ** 0.5)
    batch_images = batch_images.reshape(batch_size, 28, 28)
    row_concatenated = [np.concatenate(batch_images[i*sqrt_size : (i+1)*sqrt_size], axis=1) for i in range(sqrt_size)]
    concatenated = np.concatenate(row_concatenated, axis=0)
    plt.imshow(concatenated, cmap=&amp;#39;gray&amp;#39;)
    plt.title(title)
    plt.axis(&amp;#39;off&amp;#39;)
    plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mnist-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MNIST Dataset&lt;/h2&gt;
&lt;p&gt;The MNIST includes 60000 training samples and 10000 testing samples. Each sample is a 784-dimensional vector (28??28), with pixel values in [0, 1], which can be assumed as multivariate Bernoulli variables.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Downloading MNIST dataset
mnist = input_data.read_data_sets(&amp;#39;./mnist&amp;#39;, one_hot=False)
# VAE for MNIST
class VAE(object):
    def __init__(self, x_size=28*28, hidden1_size=100, hidden2_size=400, hidden3_size=100, hidden4_size=400, z_size=20, learning_rate=1e-4):
        self.x_size = x_size
        self.hidden1_size = hidden1_size
        self.hidden2_size = hidden2_size
        self.hidden3_size = hidden3_size
        self.hidden4_size = hidden4_size
        self.z_size = z_size
        self.learning_rate = learning_rate
        self.x = tf.placeholder(tf.float32, [None, x_size])
        self.epsilon = tf.placeholder(tf.float32, [None, z_size]) # sample from N(0,1) for every step
        with tf.variable_scope(&amp;#39;encoder&amp;#39;):
            self.encoder()
        with tf.variable_scope(&amp;#39;decoder&amp;#39;):
            self.decoder()
        with tf.variable_scope(&amp;#39;loss&amp;#39;):
            self.compute_loss()
        with tf.variable_scope(&amp;#39;train&amp;#39;):
            self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.total_loss)
    def encoder(self):
        self.hidden1 = tf.layers.dense(self.x, units=self.hidden1_size, activation=tf.nn.relu)
        self.hidden2 = tf.layers.dense(self.hidden1, units=self.hidden2_size, activation=tf.nn.relu)
        self.mu = tf.layers.dense(self.hidden2, units=self.z_size)
        self.sigma = tf.layers.dense(self.hidden2, units=self.z_size, activation=tf.exp)
        self.z = tf.add(self.mu, tf.multiply(self.epsilon, self.sigma))
        
    def decoder(self):
        self.hidden3 = tf.layers.dense(self.z, units=self.hidden3_size, activation=tf.nn.relu)
        self.hidden4 = tf.layers.dense(self.hidden3, units=self.hidden4_size, activation=tf.nn.relu)
        self.y = tf.layers.dense(self.hidden4, units=self.x_size, activation=tf.nn.sigmoid)
        
    # adding 1e-8 before taking the logarithm to avoid numerical instability.
    def compute_loss(self):
        self.recons_loss = tf.reduce_mean(tf.reduce_sum(-(self.x * tf.log(self.y + 1e-8) + (1 - self.x) * tf.log(1 - self.y + 1e-8)), 1))
        self.KL_loss = tf.reduce_mean(-0.5 * tf.reduce_sum(1 + 2 * tf.log(self.sigma + 1e-8) - tf.square(self.mu) - tf.square(self.sigma), 1))
        self.total_loss = self.recons_loss + self.KL_loss
        
# Training VAE
model = VAE()
BATCH_SIZE = 100
EPOCHS = 50
STEPS = int(60000 / BATCH_SIZE)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
for e in range(EPOCHS):
    for i in range(STEPS):
        train_data, _ = mnist.train.next_batch(batch_size=BATCH_SIZE)
        ep = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=BATCH_SIZE)
        sess.run(model.train_op, feed_dict={model.x: train_data, model.epsilon: ep})
    REloss, KLloss, Tloss = sess.run([model.recons_loss, model.KL_loss, model.total_loss], feed_dict={model.x: train_data, model.epsilon: ep})
    print(&amp;#39;Epoch: &amp;#39;, e, &amp;#39;| reconstruction loss: &amp;#39;, REloss, &amp;#39;| KL loss:&amp;#39;, KLloss, &amp;#39;| total loss: &amp;#39;, Tloss)
# Visualizing results
test_data, _ = mnist.test.next_batch(batch_size=50)
VisConcatImg(test_data, &amp;#39;raw images&amp;#39;)
ep = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=50)
latent, recons_x = sess.run([model.mu, model.y], feed_dict={model.x: test_data, model.epsilon: ep})
VisConcatImg(recons_x, &amp;#39;reconstructed images&amp;#39;)
randoms = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=50)
generated_x = sess.run(model.y, feed_dict={model.z: randoms})
VisConcatImg(generated_x, &amp;#39;generated images&amp;#39;)
sess.close()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;result&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Result&lt;/h2&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;VAE3.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
Figure3. Raw Images
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;VAE4.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure4&#34; /&gt;
&lt;p&gt;
Figure4. Reconstructed Images
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;VAE5.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure5&#34; /&gt;
&lt;p&gt;
Figure5. Generated Images
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2014. 5, 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/eeyangc/Statistical-Machine-Learning&#34;&gt;Yang Can. VAE_demo in python. 2018,12,31&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>小菜鸟的入门TensorFlow</title>
      <link>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/</guid>
      <description>


&lt;div id=&#34;tensorflow&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;迈出TensorFlow世界的第一步&lt;/h1&gt;
&lt;div id=&#34;tensorflow&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;安装TensorFlow&lt;/h2&gt;
&lt;p&gt;鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议你跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 &lt;a href=&#34;https://www.anaconda.com/&#34;&gt;Anaconda&lt;/a&gt;，快捷高效，下载引导详见图1。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS1.PNG&#34; width = &#34;500&#34; height = &#34;300&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
图1. 下载Anaconda
&lt;/div&gt;
&lt;div id=&#34;anaconda&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;设置水土不服的Anaconda&lt;/h3&gt;
&lt;p&gt;首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过&lt;code&gt;conda --version&lt;/code&gt;看看是否成功安装了Anaconda。一般会得到版本信息，如下所示&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda 4.5.12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么，Anaconda安装成功！&lt;/p&gt;
&lt;p&gt;下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;python3.5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;创建python3.5环境&lt;/h3&gt;
&lt;p&gt;首先，由于目前TensoFlow官方Only支持python3.5版本，而且在写本文的这个时候，Anaconda官方最新版本中的python是3.7版本，所以我们需要创建一个python3.5的新环境。&lt;/p&gt;
&lt;p&gt;首先在系统菜单栏找到并点击Anaconda Navigator，然后选择Enviroments（如图2所示），然后点击Create创建新环境：&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS2.PNG&#34; width = &#34;650&#34; height = &#34;330&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
图2. Environments界面
&lt;/div&gt;
&lt;p&gt;我们命名为&lt;em&gt;tensorflow&lt;/em&gt;，并选择python3.5的版本：&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS3.PNG&#34; width = &#34;350&#34; height = &#34;180&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
图3. 创建新环境窗口
&lt;/div&gt;
&lt;p&gt;安装成功后，Environments界面多了一个我们创建的命名为tensorflow的python3.5的环境，并自动预先安装一些基础的库。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS4.PNG&#34; width = &#34;650&#34; height = &#34;330&#34; alt=&#34;Figure4&#34; /&gt;
&lt;p&gt;
图4. 安装成功后的python3.5环境
&lt;/div&gt;
&lt;p&gt;搞定python3.5的环境后，我们顺便在python3.5环境下安装常用的&lt;strong&gt;jupyter notebook&lt;/strong&gt;和&lt;strong&gt;spyder&lt;/strong&gt;。先选择Home界面，然后可以看到&lt;strong&gt;jupyter notebook&lt;/strong&gt;和&lt;strong&gt;spyder&lt;/strong&gt;下方均显示&lt;strong&gt;Install&lt;/strong&gt;，当然就点击&lt;strong&gt;Install&lt;/strong&gt;，就等着Anaconda Navigator帮我们搞定啦！安装成功后，它们下方会变成&lt;strong&gt;Launch&lt;/strong&gt;（如图5所示）。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS5.PNG&#34; width = &#34;650&#34; height = &#34;350&#34; alt=&#34;Figure5&#34; /&gt;
&lt;p&gt;
图5. 安装jupyter和spyder成功后的Home界面
&lt;/div&gt;
&lt;p&gt;如果要在Anaconda prompt界面启动python3.5环境，很简单，一行命令！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda activate tensorflow&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的tensorflow其实是我们的python3.5环境的命名~&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;piptensorflow-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;通过pip安装我们的主角TensorFlow ٩(๑&amp;gt; ₃ &amp;lt;)۶з&lt;/h3&gt;
&lt;p&gt;搞定一切基础的部分后，接下来就开始用pip安装我们TensorFlow的CPU版本了~我们先激活python3.5的环境并用pip安装tensorflow&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda activate tensorflow
pip install tensorflow&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;旋转跳跃~闭着眼~睁开眼后就搞定了你要的TensorFlow (●´▽｀●) 下面我们先测试一下，在激活python3.5之后，输入&lt;code&gt;python&lt;/code&gt;运行python，然后输入下面的命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tensorflow as tf
hello = tf.constant(&amp;#39;Hello, TensorFlow!&amp;#39;)
sess = tf.Session()
print(sess.run(hello))
a = tf.constant(1)
b = tf.constant(2)
c = sess.run(a+b)
print(&amp;quot;1 + 2 = %d&amp;quot; % c)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果输出了&lt;br /&gt;
‘Hello, TensorFlow!’&lt;br /&gt;
1 + 2 = 3&lt;br /&gt;
那么恭喜你，TensorFlow安装成功！！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Attention!&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CPU有个利器(๑•̀_•́๑)&lt;br /&gt;
当我使用&lt;code&gt;sess = tf.Session()&lt;/code&gt;的时候，对话框告诉我：&lt;br /&gt;
2018-12-26 15:03:57.708274: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2&lt;br /&gt;
然后一脸懵，杰是个啥？&lt;br /&gt;
感恩必应搜索，感恩维基百科！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;高级矢量扩展（AVX）是英特尔在2008年3月提出的英特尔和AMD微处理器的x86指令集体系结构的扩展，英特尔首先通过Sandy Bridge处理器在2011年第一季度推出，随后由AMD推出Bulldozer处理器在2011年第三季度.AVX提供了新功能，新指令和新编码方案。 特别是，AVX引入了融合乘法累加（FMA）操作，加速了线性代数计算，即点积，矩阵乘法，卷积等。几乎所有机器学习训练都涉及大量这些操作，因此将会支持AVX和FMA的CPU（最高达300％）更快。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而对话框想告诉我，我的CPU支持AVX，让我赶紧用上它！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tensorflow as tf
import os
os.environ[&amp;#39;TF_CPP_MIN_LOG_LEVEL&amp;#39;] = &amp;#39;2&amp;#39;
sess = tf.Session()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样就不会出现警告了~&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;目前觉得不重要的part(๑•̀_•́๑)&lt;br /&gt;
&lt;strong&gt;查看Windows系统下机器的GPU信息&lt;/strong&gt;&lt;br /&gt;
首先打开“运行”对话框并在“运行”对话框中输入“dxdiag”（如图6），此时会打开“DirextX诊断工具”窗口，再通过选择“显示”标签便可查到机器的GPU信息（如图7）。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS6.PNG&#34; width = &#34;360&#34; height = &#34;200&#34; alt=&#34;Figure6&#34; /&gt;
&lt;p&gt;
图6. 输入dxdiag命令
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;TS7.PNG&#34; width = &#34;650&#34; height = &#34;470&#34; alt=&#34;Figure7&#34; /&gt;
&lt;p&gt;
图7. 查看机器GPU信息
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;简单提及安装GPU版本TensorFlow&lt;/strong&gt;&lt;br /&gt;
如果你觉得运行的速度不满足你的需求，那么你可以选择用上GPU版本的TensorFlow，那将帮助你火箭般的速度运行！下面简单带过如何安装TensorFlow的GPU版本~由于具体操作复杂，暂且跳过~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install tensorflow-gpu&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;—— —— —— —— —— —— —— 这是一条分割线 —— —— —— —— —— —— ——&lt;/p&gt;
&lt;p&gt;上面操作呢…有时候jupyter和spyder会出现一些路径的问题_(:з」∠)_&lt;/p&gt;
&lt;p&gt;所以我还是直接下载带Python3.5的&lt;a href=&#34;https://repo.anaconda.com/archive/Anaconda3-4.2.0-Windows-x86_64.exe&#34;&gt;Anaconda&lt;/a&gt;吧~&lt;/p&gt;
&lt;p&gt;点击上面Anaconda即可下载(..•˘_˘•..)&lt;/p&gt;
&lt;p&gt;—— —— —— —— —— —— —— 这是另一条分割线 —— —— —— —— —— —— ——&lt;/p&gt;
&lt;p&gt;下载Python3.5的Anaconda可能也有乱七八糟的错误_(:з」∠)_&lt;/p&gt;
&lt;p&gt;所以直接稳妥的方法就是用Anaconda prompt执行下面的命令~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda create --name python35 python=3.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;安装完成后会提示你&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# To activate this environment, use
#
#     $ conda activate python35
#
# To deactivate an active environment, use
#
#     $ conda deactivate&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接着先激活python3.5的环境，就可以用pip安装tensorflow&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda activate python35
pip install tensorflow&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Jupyter下设置python3.5的内核&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果不做一些设置操作，默认Jupyter打开还是会以默认Anaconda下的python版本，由于目前已经到了python3.7的版本了，那在Jupyter下使用Tensorflow必定会出问题。&lt;/p&gt;
&lt;p&gt;首先打开Anaconda Prompt并安装&lt;code&gt;ipykernel&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install ipykernel&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;安装成功后，执行下面命令就可以了~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python  -m ipykernel install --user&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;打开Jupyter就会发现可以运行Tensorflow了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Expectation-Maximization Algorithm</title>
      <link>/post/expectation-maximization-algorithm/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/expectation-maximization-algorithm/</guid>
      <description>


&lt;p&gt;From some on-line article, it is interesting that we can consider EM algorithm as some Chinese Kungfu manuals and it contains 9 levels of perspectives. With such metaphor, I can feel how this method powerful it is. Now, I want to share my view with you.&lt;/p&gt;
&lt;div id=&#34;introduction-to-the-em-algorithm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction to the EM algorithm&lt;/h2&gt;
&lt;p&gt;Expectation-Maximization (EM) algorithm is an important method to solve the maximum likelihood problem with latent variables in statistics. It is widely used in Machine Learning because it can simplify many difficult problems. One of the famous and classical application is &lt;strong&gt;gaussian mixture model&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;basic-probability-theory&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic probability theory&lt;/h3&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(p(x|\theta)\)&lt;/span&gt; be the probability density function of random variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is the parameter of the density function, then we know that the basic probability property is &lt;span class=&#34;math display&#34;&gt;\[
p(\text{x};\theta) \geq 0, \int_{-\infty}^{+\infty}p(\text{x};\theta) d\text{x} = 1.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we take the expectation of x, we get &lt;span class=&#34;math display&#34;&gt;\[
\mathbb{E}[\text{x}] = \int\text{x}p(\text{x};\theta) d\text{x}
\]&lt;/span&gt; In the integral, we know that the &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{E}[\text{x}]\)&lt;/span&gt; involves &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; but not &lt;span class=&#34;math inline&#34;&gt;\(\text{x}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If we generalize it to function and let &lt;span class=&#34;math inline&#34;&gt;\(f(\text{x})\)&lt;/span&gt; be a function of &lt;span class=&#34;math inline&#34;&gt;\(\text{x}\)&lt;/span&gt;. Similarly, the expectation of &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; is given by &lt;span class=&#34;math display&#34;&gt;\[
\mathbb{E}[f] = \int f(\text{x})p(\text{x};\theta) d\text{x}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With the similar result, we know that the &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{E}[f]\)&lt;/span&gt; involves &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; but not &lt;span class=&#34;math inline&#34;&gt;\(\text{x}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;motivation-of-the-em-algorithm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Motivation of the EM algorithm&lt;/h3&gt;
&lt;p&gt;At the beginning, we denote that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{X}\)&lt;/span&gt;: Set of all observed data (incomplete-data)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\text{Z}\)&lt;/span&gt;: Set of all latent variables&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;: Set of all model parameters&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{ \text{X,Z} \}\)&lt;/span&gt;: Each observation in &lt;span class=&#34;math inline&#34;&gt;\(\text{X}\)&lt;/span&gt; is corresponding value of the latent variable &lt;span class=&#34;math inline&#34;&gt;\(\text{Z}\)&lt;/span&gt; (complete-data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then the log-likelihood function can be written as &lt;span class=&#34;math display&#34;&gt;\[
L(\text{X};\theta) = \ln p(\text{X};\theta) = \ln \{ \sum_{\text{Z}}p(\text{X}, \text{Z};\theta) \}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is too hard to straightly solve the problem with &lt;span class=&#34;math inline&#34;&gt;\(\ln\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt;. The likelihood function for the complete data set simply takes the form &lt;span class=&#34;math inline&#34;&gt;\(\ln p(\text{X,Z}|\theta)\)&lt;/span&gt;, and we shall suppose that maximization of this complete-data log-likelihood function is straightforward.&lt;/p&gt;
&lt;p&gt;In practice, we are not given the latent variable &lt;span class=&#34;math inline&#34;&gt;\(\text{Z}\)&lt;/span&gt; but we know the posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\text{Z}|\text{X};\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-level-1-of-the-em-algorithm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Level 1 of the EM algorithm&lt;/h3&gt;
&lt;p&gt;In the level 1, we just need to know the basic knowledge of EM algorithm.&lt;/p&gt;
&lt;p&gt;In the &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{E}\)&lt;/span&gt;-step, we use the current parameter values &lt;span class=&#34;math inline&#34;&gt;\(\theta_{\text{old}}\)&lt;/span&gt; to find the posterior distribution of the latent variables given by &lt;span class=&#34;math inline&#34;&gt;\(p(\text{Z}|\text{X};\theta_{\text{old}})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Then, we would use this posterior distribution to find the expectation of the &lt;strong&gt;complete-data&lt;/strong&gt; log-likelihood evaluated for some general parameter value &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. This expectation, denoted &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{Q}(\theta,\theta_{\text{old}})\)&lt;/span&gt;, is given by &lt;span class=&#34;math display&#34;&gt;\[
\mathcal{Q}(\theta,\theta_{\text{old}}) = \mathbb{E}_{\text{Z}|\text{X};\theta_{\text{old}}}[\ln p(\text{X,Z};\theta)] = \sum_{\text{Z}} \ln p(\text{X,Z};\theta)p(\text{Z}|\text{X};\theta_{\text{old}})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{M}\)&lt;/span&gt; (Maximization) step, we determine the revised parameter estimate &lt;span class=&#34;math inline&#34;&gt;\(\theta_{\text{new}}\)&lt;/span&gt; by maximizing the function &lt;span class=&#34;math display&#34;&gt;\[
\theta_{\text{new}} = \arg \max_\limits{\theta} \mathcal{Q}(\theta,\theta_{\text{old}})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since the &lt;strong&gt;complete-data&lt;/strong&gt; log-likelihood involves unobversed data &lt;span class=&#34;math inline&#34;&gt;\(\text{Z}\)&lt;/span&gt;, we use &lt;strong&gt;Expectation&lt;/strong&gt; to eliminate the uncertainty, and the function &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{E}_{\text{Z}|\text{X},\theta_{\text{old}}}[\ln p(\text{X,Z}|\theta)]\)&lt;/span&gt; does not involve &lt;span class=&#34;math inline&#34;&gt;\(\text{Z}\)&lt;/span&gt; but involve &lt;span class=&#34;math inline&#34;&gt;\((\theta,\theta_{\text{old}})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can summarize the procedure as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;While &lt;span class=&#34;math inline&#34;&gt;\(\theta_{\text{new}} - \theta_{old} &amp;gt; \epsilon\)&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\quad\)&lt;/span&gt; Expectation-Step on log likelihood function: &lt;span class=&#34;math display&#34;&gt;\[
\mathcal{Q}(\theta,\theta_{\text{old}}) = \mathbb{E}_{\text{Z}|\text{X};\theta_{\text{old}}}[\ln p(\text{X,Z};\theta)]= \sum_{\text{Z}} \ln p(\text{X,Z};\theta)p(\text{Z}|\text{X};\theta_{\text{old}})
\]&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\quad\)&lt;/span&gt; Maximization-Step on &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{Q}(\theta,\theta_{\text{old}})\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[
\theta_{\text{new}} = \arg \max_\limits{\theta} \mathcal{Q}(\theta,\theta_{\text{old}})
\]&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;the-level-2-of-the-em-algorithm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Level 2 of the EM algorithm&lt;/h3&gt;
&lt;p&gt;After writting down the pseudocode of EM algorithm, we want to know the reason that we can use expectation to approximate the maximum log-likelihood by repeating &lt;strong&gt;Expectation&lt;/strong&gt; and &lt;strong&gt;Maximization&lt;/strong&gt;. In other words, we want to prove that &lt;span class=&#34;math display&#34;&gt;\[
\arg \max_\theta \mathbb{E}_{\text{Z}|\text{X};\theta_{\text{old}}}[\ln p(\text{X};\theta)] \approx \arg \max_\theta \ln p(\text{X};\theta)
\]&lt;/span&gt; where the joint distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\text{X}, \text{Z};\theta)\)&lt;/span&gt; is governed by a set of parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Next we introduce a distribution &lt;span class=&#34;math inline&#34;&gt;\(q(\text{Z})\)&lt;/span&gt; defined over the latent variables.&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math display&#34;&gt;\[
p(\text{X},\text{Z};\theta) = p(\text{Z}|\text{X};\theta)p(\text{X};\theta)
\]&lt;/span&gt; and &lt;span class=&#34;math display&#34;&gt;\[
\sum_\text{Z}q(\text{Z}) = 1
\]&lt;/span&gt; we can get decomposition by &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\ln p(\text{X};\theta) =&amp;amp;\ \ln \frac{p(\text{X},\text{Z};\theta)}{p(\text{Z}|\text{X};\theta)}\\
=&amp;amp;\ \ln p(\text{X},\text{Z};\theta) - \ln p(\text{Z}|\text{X};\theta) + \ln q(\text{Z}) - \ln q(\text{Z})\\
=&amp;amp;\ \ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})} - \ln \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}\\
=&amp;amp; \sum_\text{Z}q(\text{Z}) \{ \ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})} - \ln \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})} \}\\
=&amp;amp;\ \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})} - \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}\\
=&amp;amp;\ \mathcal{L}(q,\theta) + KL(q||p)
\end{align}
\]&lt;/span&gt; where &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\mathcal{L}(q,\theta) = \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})}\\
KL(q||p) = - \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We call the &lt;span class=&#34;math inline&#34;&gt;\(KL(q||p)\)&lt;/span&gt; as the Kullback-Leibler divergence (KL divergence, also known as relative entropy).&lt;/p&gt;
&lt;p&gt;Recall that &lt;strong&gt;Jensen’s inequality&lt;/strong&gt; holds for convex function &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;. &lt;span class=&#34;math display&#34;&gt;\[
\mathbb{E}[f(x)] \geq f(\mathbb{E}[x])
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Applying Jensen’s inequality in KL divergence, we have &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
KL(q||p) =&amp;amp; - \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})} = -\mathbb{E}_q[\ln\{\frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}\} ]\\
\geq&amp;amp; -\ln \mathbb{\text{E}_q}[\frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}] = -\ln \sum_\text{Z} q(\text{Z}) \frac{p(\text{Z}|\text{X};\theta)}{q(\text{Z})}\\
=&amp;amp; -\ln \sum_\text{Z} p(\text{Z}|\text{X};\theta) = -\ln 1\\ =&amp;amp;\ 0
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we let &lt;span class=&#34;math inline&#34;&gt;\(q(\text{Z}) = p(\text{Z}|\text{X};\theta)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(p(\text{X},\text{Z};\theta) = p(\text{Z}|\text{X};\theta)p(\text{X};\theta)\)&lt;/span&gt;, then &lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\mathcal{L}(q,\theta) =&amp;amp; \sum_\text{Z}q(\text{Z}) \ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})} = \mathbb{E}_q[\ln \frac{p(\text{X},\text{Z};\theta)}{q(\text{Z})}]\\
=&amp;amp;\ \mathbb{E}_{\text{Z}|\text{X};\theta}[\ln p(X;\theta)]
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, we can get the result that &lt;span class=&#34;math inline&#34;&gt;\(\ln p(\text{X};\theta) \geq \mathcal{L}(q,\theta) = \mathbb{E}_{\text{Z}|\text{X};\theta}[\ln p(X;\theta)]\)&lt;/span&gt;, so we can say that &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{L}(q,\theta) = \mathbb{E}_{\text{Z}|\text{X};\theta}[\ln p(X;\theta)]\)&lt;/span&gt; is the low bound of &lt;span class=&#34;math inline&#34;&gt;\(\ln p(\text{X};\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;EM1.PNG&#34; width = &#34;300&#34; height = &#34;300&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
Figure1. The EM algorithm involves alternatel computing a lower bound on the log likelihood for the current parameter values and then maximizing this bound to obtain the new parameter values.
&lt;/div&gt;
&lt;p&gt;Actually, EM algorithm is one of the special case of Minorize-Maximization (MM) algorithm, and &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{L}(q,\theta)\)&lt;/span&gt; can be considered as the &lt;strong&gt;surrogate function&lt;/strong&gt; in MM algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Made by Thompson</title>
      <link>/privacy/</link>
      <pubDate>Thu, 20 Dec 2018 18:00:00 +0800</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;©️ 2018 $\cdot$ Made by Thompson Hu.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coordinate Descent Algorithm</title>
      <link>/post/coordinate-descent-algorithm/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/coordinate-descent-algorithm/</guid>
      <description>


&lt;div id=&#34;coordinate-descent-framework&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Coordinate Descent Framework&lt;/h3&gt;
&lt;p&gt;At the begining of this section, we start to discuss three different types of function.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Given convex, differentiable function &lt;span class=&#34;math inline&#34;&gt;\(f: \mathbb{R}^n \to \mathbb{R}\)&lt;/span&gt;, we know &lt;span class=&#34;math inline&#34;&gt;\(f(x+\delta \cdot e_i)\geq f(x)\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; because &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x) = (\frac{\partial f}{\partial x_1}(x),\dots,\frac{\partial f}{\partial x_n}(x)) = 0\)&lt;/span&gt;. Here, &lt;span class=&#34;math inline&#34;&gt;\(e_i = (0,\dots,1,\dots,0) \in \mathbb{R}^n\)&lt;/span&gt;, the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;th standard basis vactor.&lt;/li&gt;
&lt;/ol&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CD1.PNG&#34; width = &#34;200&#34; height = &#34;200&#34; alt=&#34;Figure1&#34; /&gt;
&lt;p&gt;
Figure1. Convex and differential function &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Given convex but not differentiable function &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, we can not found a global minimizer.&lt;/li&gt;
&lt;/ol&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CD2.PNG&#34; width = &#34;400&#34; height = &#34;200&#34; alt=&#34;Figure2&#34; /&gt;
&lt;p&gt;
Figure2. Convex but not differential function &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;
&lt;/div&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Given convex &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; and each convex but not differentiable &lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;, so we get &lt;span class=&#34;math inline&#34;&gt;\(f(x)=g(x)+\sum_{i=1}^n h_i(x_i)\)&lt;/span&gt;. In this function, the non-smooth part is called as &lt;strong&gt;separable&lt;/strong&gt;.&lt;br /&gt;
For any &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, we get
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
f(y) - f(x) \geq&amp;amp; \nabla g(x)^T (y-x) + \sum_{i=1}^n [h_i(y_i)-h_i(x_i)]\\
=&amp;amp; \sum\limits_{i=1}^n [\nabla_ig(x)(y_i-x_i)+h_i(y_i)-h_i(x_i)] \geq 0
\end{align}\]&lt;/span&gt;
Thus, we can get global minimizer.&lt;/li&gt;
&lt;/ol&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;CD3.PNG&#34; width = &#34;400&#34; height = &#34;200&#34; alt=&#34;Figure3&#34; /&gt;
&lt;p&gt;
Figure3. Convex, not differential but separable function &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;
&lt;/div&gt;
If we get a function with the formula like &lt;span class=&#34;math inline&#34;&gt;\(f(x) = g(x) + \sum_{i=1}^n h_i(x_i)\)&lt;/span&gt;, where the &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; is convex and differentiable function, each &lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt; is convex functions, then we can use coordinate descent to find global minimizer. The procedure is following: start with some initial guess &lt;span class=&#34;math inline&#34;&gt;\(x^{(0)}\)&lt;/span&gt;, and repeat
&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
x_1^{(k)} \in&amp;amp; \mathop{\arg\min}_{x_1} f(x_1,x_2^{(k-1)},x_3^{(k-1)},\dots,x_n^{(k-1)})\\
x_2^{(k)} \in&amp;amp; \mathop{\arg\min}_{x_2} f(x_1^{(k)},x_2,x_3^{(k-1)},\dots,x_n^{(k-1)})\\
x_3^{(k)} \in&amp;amp; \mathop{\arg\min}_{x_3} f(x_1^{(k)},x_2^{(k)},x_3,\dots,x_n^{(k-1)})\\
\cdots&amp;amp; \\
x_n^{(k)} \in&amp;amp; \mathop{\arg\min}_{x_n} f(x_1^{(k)},x_2^{(k)},x_3^{(k)},\dots,x_n)\\
\end{align}\]&lt;/span&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(k=1,2,3,\dots,K\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; after we solve for &lt;span class=&#34;math inline&#34;&gt;\(x_i^{(k)}\)&lt;/span&gt;, we use its new value from then on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coordinate-descent-for-linear-regression-with-convex-penalties&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Coordinate descent for linear regression with convex penalties&lt;/h3&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
