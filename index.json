[{"authors":null,"categories":["Deep Learning"],"content":" 目标检测是计算机视觉一个重要的领域，希望让计算机可以自己自动找出某张图片（某个视频的某一帧画面）中的物体，并认出它们是什么，这是一个具有挑战又有趣的任务。本文主要对YOLO(You Only Look Once)模型进行探讨并在TensorFlow上实现，YOLOv1是YOLO的第一个版本（YOLO version1），虽然它的目标检测效果不咋滴，但是现在YOLO进化到了第三个版本了，是一个极其强大的工具。为了更好的学习YOLOV3，那也需要领会它前辈YOLOv1的精髓所在。YOLOv1的作者有四个大佬，Joseph Redmon大佬喜欢用C语言，他们也用C语言搭建Darknet并实现了YOLOv1，这也让众多YOLO信徒不知如何用TensorFlow来领悟其中的奥妙。github找到零零散散几个有关于YOLOv1的，但是大多数只有检测过程，而没有训练过程。几番周折，找到了既有训练又能检测的代码。本文参照hizhangp的Github仓库代码，对模型进行介绍和探讨，同时对代码进行解读并实际完成目标检测。\nYou Only Look Once, 你不要看我第二次（//▽//） YOLOv1采用一个单独的CNN模型实现end-to-end的目标检测，它的思想正如它paper的标题一般，你只看一次，就能看出图片中有什么东西，达到跟人类基本一样的探索功能。就像你看到下面这只可爱的黄色电气鼠，一瞄就知道是皮卡丘！\n 图1. 我是谁？皮卡丘！  YOLO(本文指YOLO version1)的大体检测框架是：首先通过转换图像为\\(448\\times 448\\)大小的输入，在图像输入之后YOLO会将其分为\\(S\\times S\\)的grid cell（小格子）。每一个grid cell会产生B个边界框（Bounding Box），每个Bounding Box会附带一个置信度值。原文中设定了每张图像分为\\(7\\times 7\\)的grid cell，每个grid cell产生2个Bounding Boxes，那所有的grid cell总共会生成98($772)个边界框；另外原文设定了检测物体的类别数为20。需要注意的是，在原文中多次出现exist和appear的词，表示grid cell中包含了object，但其实更准确的是表示object的中心点出现在这个grid cell中。在完成训练阶段之后，通过非极大值抑制来去除多余的边界框并完成检测（后面会补充介绍非极大值抑制的内容）~\n 图2. YOLO检测系统细节图  YOLO模型训练阶段（Traning）解析 YOLO检测网络包含了24个卷积层和2个全连接层，其中也运用了最大池化层，如图3所示：\n 图3. YOLO检测网络图  其中激活函数使用了leaky relu函数： \\[ \\phi(x) = \\left\\{ \\begin{array}{l} x,\\quad\\ \\ \\text{if}\\ \\ x\u0026gt;0\\\\ 0.1x,\\ \\text{otherwise} \\end{array} \\right. \\]\n最终模型网络输出的是一个\\(7\\times 7\\times 30\\)的张量（Tensor），这里我们可以看作49(\\(7\\times 7\\))个grid cells，其中每个grid cell中涉及30个通道（channel）。这30个channels中有2组对应2个Bounding Boxes的信息（总共占用10(\\(2\\times 5\\))个channels），剩下的20个channels对应的是20个检测类的概率。\n前5个channels（张量的第1-5d的位置）中的参数分别是第一个Bounding Box（黄色边界框）的四个坐标值以及相应的置信度。这四个坐标(\\(x,y,w,h\\))中(\\(x,y\\))是物体中心点相对于左上角的坐标值，(\\(w,h\\))是Bounding Box的宽和高，以中心点坐标就可以确定Bounding Box的大小。\n 图4. 第一个Bounding Box对应的值   图5. (\\(x,y,w,h\\))坐标值的含义  同理，第二个Bounding Box（黄色边界框）的参数对应的是张量的第6-10的位置（如图6所示），同样是(\\(x,y,w,h\\))这四个坐标值以置信度值。\n说了好几次置信度(confidence)这个词，具体是如何定义的呢？如何计算的呢？其实它只是一个概率和交并比（IoU）的乘积： \\[ \\text{confidence} = Pr(\\text{Object})\\times \\text{IOU}^{\\text{truth}}_{\\text{pred}} \\]\n如果中心点存在的，那么\\(Pr(\\text{Object})=1\\)，则置信度可以表示为：\n confidence = 紫色边界框(truth)和黄色边界框(pred)的IOU\n 如果物体不存在，即中心点不存在，那么\\(Pr(\\text{Object})=0\\)，则置信度为0。\n原文是这样描述的：\n Formally we define confidence as \\(Pr(\\text{Object}) * \\text{IOU}^{\\text{truth}}_{\\text{pred}}\\). If no object exists in that cell, the confidence scores should be zero. Otherwise we want the confidence score to equal the intersection over union (IOU) between the predicted box and the ground truth.\n  图6. 第二个Bounding Box对应的值  IOU的定义 这里又多次提及了交并比IOU，下面就IOU定义进行介绍：\n假设存在两个矩形框，它们的交集部分叫做Intersection，它们的并集部分叫做Union，那么它们的比就是交并比IOU。\n 图7. IOU的计算定义  最后的20个通道为20类物体的对应概率，如果第一个预测的是猫（cat）的概率的话，我们可以表示为\\(Pr(\\text{Cat|Object})\\)，即存在Object情况下物体时Cat的条件概率。\n原文中这样说到：\n We only predict one set of class probabilities per grid cell, regardless of the number of boxes B.\n  The predictions are encoded as an \\(S\\times S\\times(B*5+C)\\) tensor.\n 无论有多少个Bounding Boxes，都只会计算一次概率，最终预测结果会被编码为\\(S\\times S\\times(B*5+C)\\)的张量。\n 图8. 后20个通道对应20类物体概率   最重要的Part - Loss function 整体Loss function可以分为三个部分：坐标误差，IOU误差和分类误差；误差均用平方和来衡量。整体上看，可以发现一些特殊的记号：\\(\\mathbb{1}_{ij}^{obj}\\)，\\(\\mathbb{1}_{ij}^{noobj}\\)和\\(\\mathbb{1}_{i}^{obj}\\)。\n \\(\\mathbb{1}_{i}^{obj}\\) denotes if object appears in cell \\(i\\) and \\(\\mathbb{1}_{ij}^{obj}\\) denotes that the \\(j^{th}\\) bounding box predictor in cell \\(i\\) is “responsible” for that prediction.\n 它们的定义是这样的： \\[ \\begin{array}{l} \\mathbb{1}_{ij}^{obj} = \\left\\{ \\begin{array}{l} {1，}{\\text{存在Object且若第j个BBox对第i个grid cell负责}}\\\\ {0，}{\\text{否则}} \\end{array} \\right.\\\\ \\mathbb{1}_{ij}^{noobj} = \\left\\{ \\begin{array}{l} {1，}{\\text{如果grid cell不包含Object}}\\\\ {0，}{\\text{否则}} \\end{array} \\right.\\\\ \\mathbb{1}_{i}^{obj} = \\left\\{ \\begin{array}{l} {1，}{\\text{如果grid cell存在Object}}\\\\ {0，}{\\text{否则}} \\end{array} \\right. \\end{array} \\] 这里的负责可以假设其拥有最高IOU。\n首先，坐标误差很明显的就是Bounding Box的坐标(\\(x,y,w,h\\))和真实的Bounding Box的坐标(\\(\\hat{x},\\hat{y},\\hat{w},\\hat{h}\\))的误差，其中(\\(w,h\\))用根号来表示的目的是为了缩小大的Object相比小的Object的坐标带来的误差影响；关于平方根原文是这么解释的：\n Sum-squared error also equally weights errors in large boxes and small boxes. Our error metric should reflect that small deviations in large boxes matter less than in small boxes. To partially address this we predict the square root of the bounding box width and height instead of the width and height directly.\n 第二部分的IOU误差其实也是前面提到的confidence的误差，这里计算了包含Object的Bounding Box的confidence误差，也计算量不包含Object的Bounding Box的confidence误差。由于一张图像中大部分grid cell是不包含Object的，它们的confidence也就趋于0，这就会变相放大包含Object的grid cell的损失函数在计算梯度时的影响，使得模型不稳定，训练时会趋于发散。因此，通过调节参数\\(\\lambda_{coord}\\)和\\(\\lambda{noobj}\\)来改善问题；作者设定\\(\\lambda_{coord}=5\\)和\\(\\lambda{noobj}=0.5\\)。原文这么阐述：\n Also, in every image many grid cells do not contain any object. This pushes the “confidence” scores of those cells towards zero, often overpowering the gradient from cells that do contain objects. This can lead to model instability, causing training to diverge early on. To remedy this, we increase the loss from bounding box coordinate predictions and decrease the loss from confidence predictions for boxes that don’t contain objects. We use two parameters, \\(\\lambda_{coord}\\) and \\(\\lambda{noobj}\\) to accomplish this. We set \\(\\lambda_{coord}=5\\) and \\(\\lambda{noobj}=0.5\\).\n 第三部分分类误差是衡量了各种检测物体类别的条件概率的误差。上笔记图！\n 图9. Loss function各部分的含义  训练过程的思路就这么多了！开始Detection部分！\n  YOLO模型测试阶段（Detection）解析 在Detection阶段主要用了条件概率公式： \\[ Pr(\\text{Class}_i|\\text{Object})*Pr(Object)*\\text{IOU}^{\\text{truth}}_{\\text{pred}}=Pr(\\text{Class}_i)*\\text{IOU}^{\\text{truth}}_{\\text{pred}} \\]\n显然，第一部分\\(Pr(\\text{Class}_i|\\text{Object})\\)是后面20个channels中存储的条件概率，第二部分\\(Pr(Object)*\\text{IOU}^{\\text{truth}}_{\\text{pred}}\\)则是每个Bounding Box对应的置信度，如图10所示。对于图像中某个grid cell，其中张量进行乘法运算（图10中蓝色部分相乘），可以得到一列类的得分向量，图中黄色矩形条表示第一个Bounding Box的类得分向量。\n 图10. 第一个Bounding Box中条件概率公式各部分对应张量的不同通道位置相乘  同理，第二个Bounding Box也执行相同的乘法操作。\n 图11. 第二个Bounding Box中条件概率公式各部分对应张量的不同通道位置相乘  对每个grid cell重复上述操作，每个grid cell若有两个Bounding Boxes，则得到两列类得分向量，如图12所示。\n 图12. 每个grid cell的两个Bounding Boxes中执行乘法操作  如果图像分为\\(7\\times 7\\)个grid cell，每个grid cell产生2个Bounding Boxes，那总共会生成98列得分向量。我们设定一定的阈值，比如0.2；小于0.2的得分我们设置得分为0。再通过降序排列，进一步执行NMS（非极大值抑制，Non-Maximum Suppression）操作，去除多余的Bounding Boxes（如图13所示）。\n 图13. 得分矩阵的处理  非极大值抑制（Non-max suppression） 我们以第一类dog为例，假设实际只有四个框（橙色边界框/青色边界框/蓝色边界框/紫色边界框）圈到了图像中的物体狗，它们对应的得分为(0.8 / 0.5 / 0.3 / 0.2)。非极大值抑制实际上是通过设定一定IOU阈值，从第一个框开始遍历，如果两个框的IOU大于设定的阈值，那么我们可以认为这两个框相似度很大，检测的是同一个物体，但是得分较大的框更好的圈出了检测的物体；所以保留得分大的框，把另外一个去除。如果两个框的IOU小于设定的阈值，则保留继续后面的判断。对于得分为0的框则不判断。  图14. NMS过程（一）  由于排序后排后的边界框对应的得分都为0，所以不再拿第一个边界框与其他比较；下一步取第二个不为零的框作为最大得分框，与后面的边界框进行IOU判断，与上面的步骤一致。  图15. NMS过程（二）  我们假定只有四个边界框的得分非零，现在只剩下两个边界框得分不为零了，这样第一类的边界框得分判定结束；同理，对其他类进行NMS操作。  图16. NMS过程（三）  完成上述的NMS操作后，取出边界框得分向量中的最大得分以及其对应的类别，如果这个得分是大于0的，就在图像上画下边界框以及标出对应的类别；否则丢弃当前边界框。对所有的得分向量重复上述操作。  图17. 提取边界框（Bounding Box）     YOLO代码解析与实践 训练 首先，从hizhangp的Github上下载YOLO version1在TensorFlow复现的代码。由于我们用Pascal VOC数据集进行训练，所以我们需要先对数据集的图像进行处理。\npascal_voc.py文件 import os import xml.etree.ElementTree as ET import numpy as np import cv2 import pickle import copy import yolo.config as cfg class pascal_voc(object): def _init_(self, phase, rebuild=False): # config.py中参数已经设置完毕并通过cfg.调用 # devkil_path存放VOCdevkit的路径 self.devkil_path = os.path.join(cfg.PASCAL_PATH, \u0026#39;VOCdevkit\u0026#39;) # data_path是数据存放在VOC2007中的路径 self.data_path = os.path.join(self.devkil_path, \u0026#39;VOC2007\u0026#39;) # 缓存路径 self.cache_path = cfg.CACHE_PATH # 批量大小 self.batch_size = cfg.BATCH_SIZE # 图像大小 self.image_size = cfg.IMAGE_SIZE # 图像分割为Grid Cell的数量，图像分割为多少块 self.cell_size = cfg.CELL_SIZE # 识别object中可能出现的类 self.classes = cfg.CLASSES # 将可能出现的类转换为字典(dictionary) # range()产生从0到self.classes的长度减1的序列; # 若len(self.classes)=20, # 则产生[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19] # zip()打包为元组的列表 # dict()构造字典 self.class_to_ind = dict(zip(self.classes, range(len(self.classes)))) # config中FLIPPED设置为True self.flipped = cfg.FLIPPED # _init_函数的输入变量 self.phase = phase self.rebuild = rebuild # 其他参数 self.cursor = 0 self.epoch = 1 self.gt_labels = None self.prepare() def image_read(self, imname, flipped=False): # 读取图像 image = cv2.imread(imname) # resize图像为image_size大小 image = cv2.resize(image, (self.image_size, self.image_size)) # opencv读取的是bgr格式,转换为rgb格式,并字段类型转换为float32 image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) # 归一化到[-1,1] image = (image / 255.0) * 2.0 - 1.0 # flipped为翻转 # ::n代表序列中每第n项; -1指从倒数开始截取 # ::-1会将序列从头到尾颠倒 if flipped: image = image[:, ::-1, :] return image def load_pascal_annotation(self, index): # 加载图片数据 # Load image and bounding boxes info from XML file in the PASCAL VOC format imname = os.path.join(self.data_path, \u0026#39;JPEGImages\u0026#39;, index + \u0026#39;.jpg\u0026#39;) im = cv2.imread(imname) # im = cv2.resize(im, [self.image_size, self.image_size]) h_ratio = 1.0 * self.image_size / im.shape[0] w_ratio = 1.0 * self.image_size / im.shape[1] # 置信度(1) + Bounding Box坐标(2-5) + 20类class(6-25) label = np.zeros((self.cell_size, self.cell_size, 25)) filename = os.path.join(self.data_path, \u0026#39;Annotations\u0026#39;, index + \u0026#39;.xml\u0026#39;) tree = ET.parse(filename) objs = tree.findall(\u0026#39;object\u0026#39;) for obj in objs: bbox = obj.find(\u0026#39;bndbox\u0026#39;) # Make pixel indexes 0-based x1 = max(min((float(bbox.find(\u0026#39;xmin\u0026#39;).text) - 1) * w_ratio, self.image_size - 1), 0) y1 = max(min((float(bbox.find(\u0026#39;ymin\u0026#39;).text) - 1) * h_ratio, self.image_size - 1), 0) x2 = max(min((float(bbox.find(\u0026#39;xmax\u0026#39;).text) - 1) * w_ratio, self.image_size - 1), 0) y2 = max(min((float(bbox.find(\u0026#39;ymax\u0026#39;).text) - 1) * h_ratio, self.image_size - 1), 0) cls_ind = self.class_to_ind[obj.find(\u0026#39;name\u0026#39;).text.lower().strip()] boxes = [(x2 + x1) / 2.0, (y2 + y1) / 2.0, x2 - x1, y2 - y1] x_ind = int(boxes[0] * self.cell_size / self.image_size) y_ind = int(boxes[1] * self.cell_size / self.image_size) if label[y_ind, x_ind, 0] == 1: continue label[y_ind, x_ind, 0] = 1 label[y_ind, x_ind, 1:5] = boxes label[y_ind, x_ind, 5 + cls_ind] = 1 return label, len(objs) def load_labels(self): cache_file = os.path.join(self.cache_path, \u0026#39;pascal_\u0026#39; + self.phase + \u0026#39;_gt_labels.pkl\u0026#39;) if os.path.isfile(cache_file) and not self.rebuild: print(\u0026#39;Loading gt_labels from: \u0026#39; + cache_file) with open(cache_file, \u0026#39;rb\u0026#39;) as f: gt_labels = pickle.load(f) return gt_labels print(\u0026#39;Processing gt_labels from: \u0026#39; + self.data_path) if not os.path.exists(self.cache_path): os.makedirs(self.cache_path) if self.phase == \u0026#39;train\u0026#39;: txtname = os.path.join(self.data_path, \u0026#39;ImageSets\u0026#39;, \u0026#39;Main\u0026#39;, \u0026#39;trainval.txt\u0026#39;) else: txtname = os.path.join(self.data_path, \u0026#39;ImageSets\u0026#39;, \u0026#39;Main\u0026#39;, \u0026#39;test.txt\u0026#39;) with open(txtname, \u0026#39;r\u0026#39;) as f: self.image_index = [x.strip() for x in f.readlines()] gt_labels = [] # 通过load_pascal_annotation()函数将所有图像读取出来 # 一个一个做成label并存放在gt_labels里面,同时保存在pickle里面 for index in self.image_index: label, num = self.load_pascal_annotation(index) if num == 0: continue imname = os.path.join(self.data_path, \u0026#39;JPEGImages\u0026#39;, index + \u0026#39;.jpg\u0026#39;) gt_labels.append({\u0026#39;imname\u0026#39;: imname, \u0026#39;label\u0026#39;: label, \u0026#39;flipped\u0026#39;: False}) print(\u0026#39;Saving gt_labels to: \u0026#39; + cache_file) with open(cache_file, \u0026#39;wb\u0026#39;) as f: pickle.dump(gt_labels, f) return gt_labels def prepare(self): gt_labels = self.load_labels() if self.flipped: print(\u0026#39;Appending horizontally-flipped training examples ...\u0026#39;) gt_labels_cp = copy.deepcopy(gt_labels) for idx in range(len(gt_labels_cp)): gt_labels_cp[idx][\u0026#39;flipped\u0026#39;] = True gt_labels_cp[idx][\u0026#39;label\u0026#39;] = gt_labels_cp[idx][\u0026#39;label\u0026#39;][:, ::-1, :] for i in range(self.cell_size): for j in range(self.cell_size): if gt_labels_cp[idx][\u0026#39;label\u0026#39;][i, j, 0] == 1: gt_labels_cp[idx][\u0026#39;label\u0026#39;][i, j, 1] = self.image_size - 1 - gt_labels_cp[idx][\u0026#39;label\u0026#39;][i, j, 1] gt_labels += gt_labels_cp np.random.shuffle(gt_labels) self.gt_labels = gt_labels return gt_labels def get(self): # np.zeros()创建指定大小的数组，数组元素以 0 来填充 images = np.zeros((self.batch_size, self.image_size, self.image_size, 3)) labels = np.zeros((self.batch_size, self.cell_size, self.cell_size, 25)) count = 0 while count \u0026lt; self.batch_size: # 调用self类中gt_labels,cursor和函数image_read() imname = self.gt_labels[self.cursor][\u0026#39;imname\u0026#39;] flipped = self.gt_labels[self.cursor][\u0026#39;flipped\u0026#39;] images[count, :, :, :] = self.image_read(imname, flipped) labels[count, :, :, :] = self.gt_labels[self.cursor][\u0026#39;label\u0026#39;] count += 1 self.cursor += 1 if self.cursor \u0026gt;= len(self.gt_labels): np.random.shuffle(self.gt_labels) self.cursor = 0 self.epoch += 1 return images, labels  再看看网络搭建的yolo_net.py文件 import numpy as np import tensorflow as tf import yolo.config as cfg import tensorflow.contrib.slim as slim # slim = tf.contrib.slim class YOLONet(object): def __init__(self, is_training=True): # 从config中获取预测的类 self.classes = cfg.CLASSES # 预测的类的数量(类别数) self.num_class = len(self.classes) # 图像尺寸 self.image_size = cfg.IMAGE_SIZE # Grid cell的数量 self.cell_size = cfg.CELL_SIZE # 每个Grid cell生成Bounding Box的数量 self.boxes_per_cell = cfg.BOXES_PER_CELL # 输出尺寸: S * S * (C + B * 5) self.output_size = (self.cell_size * self.cell_size) * (self.num_class + self.boxes_per_cell * 5) self.scale = 1.0 * self.image_size / self.cell_size self.boundary1 = self.cell_size * self.cell_size * self.num_class self.boundary2 = self.boundary1 + self.cell_size * self.cell_size * self.boxes_per_cell self.object_scale = cfg.OBJECT_SCALE self.noobject_scale = cfg.NOOBJECT_SCALE self.class_scale = cfg.CLASS_SCALE self.coord_scale = cfg.COORD_SCALE # 学习率 self.learning_rate = cfg.LEARNING_RATE # 批量尺寸 self.batch_size = cfg.BATCH_SIZE # 激活函数leaky_relu的参数alpha(取0.1) self.alpha = cfg.ALPHA # Bounding Box的中心点(center point)坐标 -- x, y -- 相对于左上角点的偏移量 # (self.B, self.S, self.S)为三维数组的维度，有self.B个array，每个array的维度为(self.S, self.S) # (1,2,0)改变了数组的构造，将会有self.S个array，每个array的维度为(self.S, self.B) self.offset = np.transpose(np.reshape(np.array([np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell), (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0)) self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, 3], name=\u0026#39;images\u0026#39;) # 调用函数build_network() self.logits = self.build_network(self.images, num_outputs=self.output_size, alpha=self.alpha, is_training=is_training) if is_training: self.labels = tf.placeholder(tf.float32, [None, self.cell_size, self.cell_size, 5 + self.num_class]) self.loss_layer(self.logits, self.labels) self.total_loss = tf.losses.get_total_loss() tf.summary.scalar(\u0026#39;total_loss\u0026#39;, self.total_loss) def build_network(self, images, num_outputs, alpha, keep_prob=0.5, is_training=True, scope=\u0026#39;yolo\u0026#39;): # 网络结构可对照paper的Figure 3: The Architecture验证 # # 导入tf.contrib.slim为slim (import tf.contrib.slim as slim) # # slim.conv2d(inputs, num_outputs, kernel_size, stride, padding, ..., scope) # inputs指需要做卷积的输入图像 # num_outputs指定卷积核的个数 # kernel_size指定卷积核的维度 # stride为卷积时在图像每一维的步长 # padding可选VALID或SAME # scope为共享变量所指的variable_scope # # slim.max_pool2d(inputs, kernel_size)函数表示最大池化层, 第二个参数表示池化层核的维度 # # slim.flatten(tensor)表示将tensor扁平化 # 假设tensor为四维张量, flatten函数会转化tensor为三维, 三维数组中有多个二维数组, 二维数组均为1*k的数组 # # slim.fully_connected()表示全连接层, 前两个参数分别为网络输入、输出的神经元数量 # slim.fully_connected(net, 512, scope=\u0026#39;fc_33\u0026#39;)中输出的神经元数量为512 # # slim.dropout(inputs, keep_prob, is_training, ...) # inputs: The tensor to pass to the nn.dropout op. # keep_prob: A scalar `Tensor` with the same type as x. The probability that each element is kept. # is_training: A bool `Tensor` indicating whether or not the model is in training mode. # If so, dropout is applied and values scaled. Otherwise, inputs is returned. # dropout函数的使用目的是防止或减轻过拟合, 它一般用在全连接层 # 在不同的训练过程中随机扔掉一部分神经元, 让某个神经元的激活值以一定的概率p, 让其停止工作 # 这次训练过程中不更新权值, 也不参加神经网络的计算 # 但它的权重得保留下来(只是暂时不更新而已), 因为下次样本输入时它可能又得工作了 # # tf.pad(tensor, paddings, mode=\u0026#39;CONSTANT\u0026#39;, name=None)函数: # 第二个参数paddings也是一个张量(tensor) # 代表每一维填充多少行/列，但是有一个要求它的rank一定要和tensor的rank是一样的 # tf.pad(tensor, [[1,2],[3,4]])会将二维数组左边加1个0, 右边加2个0, 上边加3个0, 下边加4个0 # 第三个参数中\u0026#39;CONSTANT\u0026#39;表示填充的元素为0 # 本例中, 对于四维张量中四个维度的不同两个方向进行添加0元素 # pad目的是填充补数,保证最后卷积层输出特征图大小为7*7 # # tf.transpose(inputs, perm, name=None)函数: # 第二个参数perm=[0,1,2]中 # 0代表三维数组的高(即为二维数组的个数), 1代表二维数组的行, 2代表二维数组的列 # 若在四维空间中, 0代表四维空间的高(即为三维数组的个数) # 1代表三维数组的高(即为二维数组的个数), 2代表二维数组的行, 3代表二维数组的列 # tf.transpose(net, [0, 3, 1, 2], name=\u0026#39;trans_31\u0026#39;) # [0,3,1,2]表示每个三维数组中, 三维数组的高变为每个二维数组的行 # 二维数组的行变为二维数组的列, 二维数组的列变为三维数组的高 with tf.variable_scope(scope): with slim.arg_scope([slim.conv2d, slim.fully_connected], activation_fn=leaky_relu(alpha), weights_regularizer=slim.l2_regularizer(0.0005), weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)): net = tf.pad(images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]), name=\u0026#39;pad_1\u0026#39;) net = slim.conv2d(net, 64, 7, 2, padding=\u0026#39;VALID\u0026#39;, scope=\u0026#39;conv_2\u0026#39;) net = slim.max_pool2d(net, 2, padding=\u0026#39;SAME\u0026#39;, scope=\u0026#39;pool_3\u0026#39;) net = slim.conv2d(net, 192, 3, scope=\u0026#39;conv_4\u0026#39;) net = slim.max_pool2d(net, 2, padding=\u0026#39;SAME\u0026#39;, scope=\u0026#39;pool_5\u0026#39;) net = slim.conv2d(net, 128, 1, scope=\u0026#39;conv_6\u0026#39;) net = slim.conv2d(net, 256, 3, scope=\u0026#39;conv_7\u0026#39;) net = slim.conv2d(net, 256, 1, scope=\u0026#39;conv_8\u0026#39;) net = slim.conv2d(net, 512, 3, scope=\u0026#39;conv_9\u0026#39;) net = slim.max_pool2d(net, 2, padding=\u0026#39;SAME\u0026#39;, scope=\u0026#39;pool_10\u0026#39;) net = slim.conv2d(net, 256, 1, scope=\u0026#39;conv_11\u0026#39;) net = slim.conv2d(net, 512, 3, scope=\u0026#39;conv_12\u0026#39;) net = slim.conv2d(net, 256, 1, scope=\u0026#39;conv_13\u0026#39;) net = slim.conv2d(net, 512, 3, scope=\u0026#39;conv_14\u0026#39;) net = slim.conv2d(net, 256, 1, scope=\u0026#39;conv_15\u0026#39;) net = slim.conv2d(net, 512, 3, scope=\u0026#39;conv_16\u0026#39;) net = slim.conv2d(net, 256, 1, scope=\u0026#39;conv_17\u0026#39;) net = slim.conv2d(net, 512, 3, scope=\u0026#39;conv_18\u0026#39;) net = slim.conv2d(net, 512, 1, scope=\u0026#39;conv_19\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_20\u0026#39;) net = slim.max_pool2d(net, 2, padding=\u0026#39;SAME\u0026#39;, scope=\u0026#39;pool_21\u0026#39;) net = slim.conv2d(net, 512, 1, scope=\u0026#39;conv_22\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_23\u0026#39;) net = slim.conv2d(net, 512, 1, scope=\u0026#39;conv_24\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_25\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_26\u0026#39;) net = tf.pad(net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]), name=\u0026#39;pad_27\u0026#39;) net = slim.conv2d(net, 1024, 3, 2, padding=\u0026#39;VALID\u0026#39;, scope=\u0026#39;conv_28\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_29\u0026#39;) net = slim.conv2d(net, 1024, 3, scope=\u0026#39;conv_30\u0026#39;) net = tf.transpose(net, [0, 3, 1, 2], name=\u0026#39;trans_31\u0026#39;) net = slim.flatten(net, scope=\u0026#39;flat_32\u0026#39;) # First fully connected layer net = slim.fully_connected(net, 512, scope=\u0026#39;fc_33\u0026#39;) net = slim.fully_connected(net, 4096, scope=\u0026#39;fc_34\u0026#39;) # From section 2.2 in paper, \u0026quot;After first fully connected layer # A dropout layer with rate = .5 after the first connected layer prevents co-adaptation between layers\u0026quot; net = slim.dropout(net, keep_prob=keep_prob, is_training=is_training, scope=\u0026#39;dropout_35\u0026#39;) net = slim.fully_connected(net, num_outputs, activation_fn=None, scope=\u0026#39;fc_36\u0026#39;) return net def calc_iou(self, boxes1, boxes2, scope=\u0026#39;iou\u0026#39;): # Calculate IOUs # Args: # boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ====\u0026gt; (x_center, y_center, w, h) # boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===\u0026gt; (x_center, y_center, w, h) # Return: # iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL] with tf.variable_scope(scope): # Transform (x_center, y_center, w, h) to (x1, y1, x2, y2) # 将(x_center, y_center, w, h)转换为Bounding Box的左上角和右下角坐标(x1, y1, x2, y2) # Bounding Box左上角坐标: (x_center - w / 2, y_center - h / 2) # Bounding Box右下角坐标: (x_center + w / 2, y_center + h / 2) boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0, boxes1[..., 1] - boxes1[..., 3] / 2.0, boxes1[..., 0] + boxes1[..., 2] / 2.0, boxes1[..., 1] + boxes1[..., 3] / 2.0], axis=-1) boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0, boxes2[..., 1] - boxes2[..., 3] / 2.0, boxes2[..., 0] + boxes2[..., 2] / 2.0, boxes2[..., 1] + boxes2[..., 3] / 2.0], axis=-1) # 计算两个Bounding Boxes的相交点坐标 # Calculate the left up point \u0026amp; right down point # 相交框(intersection)左上角坐标(lu)为两个Bounding Boxes的左上角较大点坐标 # 相交框(intersection)右下角坐标(rd)为两个Bounding Boxes的右下角较小点坐标 lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2]) rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:]) # Intersection # rd-lu可以得到相交部分框的长和宽 # 与0取最大是为了删除不合理的框，比如两个框无交集 # inter_square为面积(长*宽) intersection = tf.maximum(0.0, rd - lu) inter_square = intersection[..., 0] * intersection[..., 1] # 计算两个Bounding Boxes的面积 # Calculate the boxs1 square and boxs2 square square1 = boxes1[..., 2] * boxes1[..., 3] square2 = boxes2[..., 2] * boxes2[..., 3] # union_square为两个Bounding Boxes的总面积减去相交面积 # tf.maximum保证相交面积不为0,由于下一步计算作为分母 union_square = tf.maximum(square1 + square2 - inter_square, 1e-10) # tf.clip_by_value()函数: 若交并比大于1则为1; 若交并比小于0则为0 return tf.clip_by_value(inter_square / union_square, 0.0, 1.0) def loss_layer(self, predicts, labels, scope=\u0026#39;loss_layer\u0026#39;): # tf.reshape(tensor, shape)函数: # 将张量tensor重塑为shape设定的维度下的张量 # # tf.tile(inputs, multiples, name=None)函数: # tf.tile(boxes, [1, 1, 1, self.boxes_per_cell, 1]) # 第二个参数表示每个维度复制的次数，这个地方只是对轴3复制两次，因为我们知道一个cell_size负责两个框的预测 # # tf.stack(tensor, axis)函数: # 在新的维度上拼接, 拼接后维度加1; 若axis=0, 指第一个维度; 若axis=-1, 指最后一个维度 # t1 = [[1, 2, 3], [4, 5, 6]] # t2 = [[7, 8, 9], [10, 11, 12]] # t3 = tf.stack([t1,t2],axis=0) # t4 = tf.stack([t1,t2],axis=1) # t5 = tf.stack([t1,t2],axis=-1) # with tf.Session() as sess: print(sess.run(t3)) # [[[ 1 2 3] # [ 4 5 6]] # # [[ 7 8 9] # [10 11 12]]] # with tf.Session() as sess: print(sess.run(t4)) # [[[ 1 2 3] # [ 7 8 9]] # # [[ 4 5 6] # [10 11 12]]] # with tf.Session() as sess: print(sess.run(t5)) # [[[ 1 7] # [ 2 8] # [ 3 9]] # # [[ 4 10] # [ 5 11] # [ 6 12]]] # # tf.ones_like(tensor, dtype, ...)函数：生成一个和tensor相同形状的, 数据类型为dtype, 所有元素都被设置为1 # # tf.cast(x, dtype, name=None)函数: 将x转换为dtype # tensor a is [1.8, 2.2], dtype = tf.float # tf.cast(a, tf.int32) ==\u0026gt; [1, 2], where dtype = tf.int32 # # tf.reduce_mean(tensor, axis=None, keep_dims=False, name=None)函数: 求tensor中平均值, axis参数指定轴方向 # # tf.reduce_max(tensor, axis=None, keep_dims=False, name=None)函数: 求tensor中最大值, axis参数指定轴方向 # # tf.reduce_sum(tensor, axis=None, keep_dims=False, name=None)函数:求tensor中元素和, axis参数指定轴方向 # # tf.square(x, name=None)函数: 计算平方x^2 # # tf.sqrt(x, name=None)函数: 计算开根号x^{1/2} # # tf.expand_dims(tensor, dim, name=None)函数: tensor维度加1; 第二个参数dim表示维度扩增的方向 # t6 = tf.expand_dims(t1,0) # t7 = tf.expand_dims(t1,1) # t8 = tf.expand_dims(t1,2) 和 tf.expand_dims(t1,-1) 相同; -1指最后一个维度 # # with tf.Session() as sess: print(sess.run(t6)) # [[[1 2 3] # [4 5 6]]] # with tf.Session() as sess: print(sess.run(t7)) # [[[1 2 3]] # # [[4 5 6]]] # with tf.Session() as sess: print(sess.run(t8)) # [[[1] # [2] # [3]] # # [[4] # [5] # [6]]] # # tf.losses.add_loss()函数: 将外部定义的loss添加到losses的集合中 # # tf.summary.scalar()函数: 查看learning rate和目标函数如何变化 # # tf.summary.histogram()函数: 查看activations, gradients或者weights的分布 # with tf.variable_scope(scope): # 预测类别 predict_classes = tf.reshape(predicts[:, :self.boundary1], [self.batch_size, self.cell_size, self.cell_size, self.num_class]) # 预测置信度 predict_scales = tf.reshape(predicts[:, self.boundary1:self.boundary2], [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell]) # 预测Bounding Box predict_boxes = tf.reshape(predicts[:, self.boundary2:], [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4]) # response是提取label中的置信度，表示这个地方是否有框 response = tf.reshape(labels[..., 0], [self.batch_size, self.cell_size, self.cell_size, 1]) # 提取框 boxes = tf.reshape(labels[..., 1:5],[self.batch_size, self.cell_size, self.cell_size, 1, 4]) boxes = tf.tile(boxes, [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size # 提取类(one-hot编码) classes = labels[..., 5:] offset = tf.reshape(tf.constant(self.offset, dtype=tf.float32), [1, self.cell_size, self.cell_size, self.boxes_per_cell]) offset = tf.tile(offset, [self.batch_size, 1, 1, 1]) offset_tran = tf.transpose(offset, (0, 2, 1, 3)) predict_boxes_tran = tf.stack([(predict_boxes[..., 0] + offset) / self.cell_size, (predict_boxes[..., 1] + offset_tran) / self.cell_size, tf.square(predict_boxes[..., 2]), tf.square(predict_boxes[..., 3])], axis=-1) iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes) # Calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL] object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True) object_mask = tf.cast((iou_predict_truth \u0026gt;= object_mask), tf.float32) * response # Calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL] noobject_mask = tf.ones_like(object_mask, dtype=tf.float32) - object_mask boxes_tran = tf.stack([boxes[..., 0] * self.cell_size - offset, boxes[..., 1] * self.cell_size - offset_tran, tf.sqrt(boxes[..., 2]), tf.sqrt(boxes[..., 3])], axis=-1) # Calculate each part in loss function # class_loss class_delta = response * (predict_classes - classes) class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]), name=\u0026#39;class_loss\u0026#39;) * self.class_scale # object_loss object_delta = object_mask * (predict_scales - iou_predict_truth) object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]), name=\u0026#39;object_loss\u0026#39;) * self.object_scale # noobject_loss noobject_delta = noobject_mask * predict_scales noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]), name=\u0026#39;noobject_loss\u0026#39;) * self.noobject_scale # coord_loss coord_mask = tf.expand_dims(object_mask, 4) boxes_delta = coord_mask * (predict_boxes - boxes_tran) coord_loss = tf.reduce_mean(tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]), name=\u0026#39;coord_loss\u0026#39;) * self.coord_scale # Add each part of loss function together tf.losses.add_loss(class_loss) tf.losses.add_loss(object_loss) tf.losses.add_loss(noobject_loss) tf.losses.add_loss(coord_loss) tf.summary.scalar(\u0026#39;class_loss\u0026#39;, class_loss) tf.summary.scalar(\u0026#39;object_loss\u0026#39;, object_loss) tf.summary.scalar(\u0026#39;noobject_loss\u0026#39;, noobject_loss) tf.summary.scalar(\u0026#39;coord_loss\u0026#39;, coord_loss) tf.summary.histogram(\u0026#39;boxes_delta_x\u0026#39;, boxes_delta[..., 0]) tf.summary.histogram(\u0026#39;boxes_delta_y\u0026#39;, boxes_delta[..., 1]) tf.summary.histogram(\u0026#39;boxes_delta_w\u0026#39;, boxes_delta[..., 2]) tf.summary.histogram(\u0026#39;boxes_delta_h\u0026#39;, boxes_delta[..., 3]) tf.summary.histogram(\u0026#39;iou\u0026#39;, iou_predict_truth) def leaky_relu(alpha): # 激活函数leaky_relu # if(x\u0026gt;0) then \\phi(x)=x # otherwise \\phi(x)=alpha*x # In this case,alpha=0.1 def op(inputs): return tf.nn.leaky_relu(inputs, alpha=alpha, name=\u0026#39;leaky_relu\u0026#39;) return op  网络搭建后用train.py文件进行训练 import os import argparse import datetime import tensorflow as tf import yolo.config as cfg from yolo.yolo_net import YOLONet from utils.timer import Timer from utils.pascal_voc import pascal_voc os.environ[\u0026#39;TF_CPP_MIN_LOG_LEVEL\u0026#39;] = \u0026#39;2\u0026#39; import tensorflow.contrib.slim as slim # slim = tf.contrib.slim class Solver(object): def __init__(self, net, data): # tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate, staircase)函数: # initial_learning_rate表示初始设定学习率; global_step表示当前的学习步数; decay_rate表示衰减速率; # staircase若为True表明每decay_steps次计算学习率变化并更新原始学习率; False则每一步都更新 # learning_rate = initial_learning_rate * (decay_rate) ^ (global_step / decay_steps) # # tf.train.GradientDescentOptimizer(learning_rate)函数: 梯度下降优化器 # # slim.learning.create_train_op(loss, optimizer, ...)通过loss, optimizer等创建train_op, 用于训练 # # tf.GPUOptions(per_process_gpu_memory_fraction)作为可选配置参数的一部分来显示地指定需要分配的显存比例 # per_process_gpu_memory_fraction指定了每个GPU进程中使用显存的上限, 但它只能均匀地作用于所有GPU, 无法对不同GPU设置不同的上限 # # sess.run(a)函数: 找到与a有数据依赖的节点, 然后顺序执行 # # 参数初始化 self.net = net self.data = data self.weights_file = cfg.WEIGHTS_FILE self.max_iter = cfg.MAX_ITER self.initial_learning_rate = cfg.LEARNING_RATE self.decay_steps = cfg.DECAY_STEPS self.decay_rate = cfg.DECAY_RATE self.staircase = cfg.STAIRCASE self.summary_iter = cfg.SUMMARY_ITER self.save_iter = cfg.SAVE_ITER self.output_dir = os.path.join(cfg.OUTPUT_DIR, datetime.datetime.now().strftime(\u0026#39;%Y_%m_%d_%H_%M\u0026#39;)) if not os.path.exists(self.output_dir): os.makedirs(self.output_dir) self.save_cfg() # tf.global_variables表示获取程序中的变量, 返回的值是变量的一个列表 self.variable_to_restore = tf.global_variables() # tf.train.Saver表示Save and restore all the variables self.saver = tf.train.Saver(self.variable_to_restore, max_to_keep=None) self.ckpt_file = os.path.join(self.output_dir, \u0026#39;yolo\u0026#39;) # merge_all可以将所有summary全部保存到磁盘, 以便tensorboard显示 self.summary_op = tf.summary.merge_all() # 定义一个写入summary的目标文件，dir为写入文件地址 self.writer = tf.summary.FileWriter(self.output_dir, flush_secs=60) # tf.train.create_global_step()表示在图中创建全局步长张量 self.global_step = tf.train.create_global_step() # 学习率的设定: 一开始使用较大学习率以快速得到较优解; 再通过较小学习率使模型训练后期更稳定 self.learning_rate = tf.train.exponential_decay(self.initial_learning_rate, self.global_step, self.decay_steps, self.decay_rate, self.staircase, name=\u0026#39;learning_rate\u0026#39;) # 梯度下降 self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate) # 创建训练 self.train_op = slim.learning.create_train_op(self.net.total_loss, self.optimizer, global_step=self.global_step) # 显存GPU设置 gpu_options = tf.GPUOptions() config = tf.ConfigProto(gpu_options=gpu_options) # tf.Session()创建一个会话 self.sess = tf.Session(config=config) self.sess.run(tf.global_variables_initializer()) # 导入weights文件 if self.weights_file is not None: print(\u0026#39;Restoring weights from: \u0026#39; + self.weights_file) # saver.restore(sess, ckpt.model_checkpoint_path)恢复变量 self.saver.restore(self.sess, self.weights_file) self.writer.add_graph(self.sess.graph) def train(self): train_timer = Timer() load_timer = Timer() for step in range(1, self.max_iter + 1): # 记录加载数据时间 \u0026amp; 加载数据 load_timer.tic() images, labels = self.data.get() load_timer.toc() feed_dict = {self.net.images: images, self.net.labels: labels} if step % self.summary_iter == 0: if step % (self.summary_iter * 10) == 0: # 记录训练时间 train_timer.tic() summary_str, loss, _ = self.sess.run([self.summary_op, self.net.total_loss, self.train_op], feed_dict=feed_dict) train_timer.toc() # 打印输出相关数据 log_str = \u0026quot;{} Epoch: {}, Step: {}, Learning rate: {}, Loss: {:5.3f}\\nSpeed: {:.3f}s/iter, Load: {:.3f}s/iter, Remain: {}\u0026quot;.format( datetime.datetime.now().strftime(\u0026#39;%m-%d %H:%M:%S\u0026#39;), self.data.epoch, int(step), round(self.learning_rate.eval(session=self.sess), 6), loss, train_timer.average_time, load_timer.average_time, train_timer.remain(step, self.max_iter)) print(log_str) else: train_timer.tic() summary_str, _ = self.sess.run([self.summary_op, self.train_op], feed_dict=feed_dict) train_timer.toc() self.writer.add_summary(summary_str, step) else: train_timer.tic() self.sess.run(self.train_op, feed_dict=feed_dict) train_timer.toc() if step % self.save_iter == 0: print(\u0026#39;{} Saving checkpoint file to: {}\u0026#39;.format(datetime.datetime.now().strftime(\u0026#39;%m-%d %H:%M:%S\u0026#39;), self.output_dir)) # 保存ckpt模型文件 self.saver.save(self.sess, self.ckpt_file, global_step=self.global_step) def save_cfg(self): with open(os.path.join(self.output_dir, \u0026#39;config.txt\u0026#39;), \u0026#39;w\u0026#39;) as f: cfg_dict = cfg.__dict__ for key in sorted(cfg_dict.keys()): if key[0].isupper(): cfg_str = \u0026#39;{}: {}\\n\u0026#39;.format(key, cfg_dict[key]) f.write(cfg_str) def update_config_paths(data_dir, weights_file): cfg.DATA_PATH = data_dir cfg.PASCAL_PATH = os.path.join(data_dir, \u0026#39;pascal_voc\u0026#39;) cfg.CACHE_PATH = os.path.join(cfg.PASCAL_PATH, \u0026#39;cache\u0026#39;) cfg.OUTPUT_DIR = os.path.join(cfg.PASCAL_PATH, \u0026#39;output\u0026#39;) cfg.WEIGHTS_DIR = os.path.join(cfg.PASCAL_PATH, \u0026#39;weights\u0026#39;) cfg.WEIGHTS_FILE = os.path.join(cfg.WEIGHTS_DIR, weights_file) def main(): parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;--weights\u0026#39;, default=\u0026quot;YOLO_small.ckpt\u0026quot;, type=str) parser.add_argument(\u0026#39;--data_dir\u0026#39;, default=\u0026quot;data\u0026quot;, type=str) parser.add_argument(\u0026#39;--threshold\u0026#39;, default=0.2, type=float) parser.add_argument(\u0026#39;--iou_threshold\u0026#39;, default=0.5, type=float) parser.add_argument(\u0026#39;--gpu\u0026#39;, default=\u0026#39;\u0026#39;, type=str) args = parser.parse_args() if args.gpu is not None: cfg.GPU = args.gpu if args.data_dir != cfg.DATA_PATH: update_config_paths(args.data_dir, args.weights) os.environ[\u0026#39;CUDA_VISIBLE_DEVICES\u0026#39;] = cfg.GPU yolo = YOLONet() pascal = pascal_voc(\u0026#39;train\u0026#39;) solver = Solver(yolo, pascal) print(\u0026#39;Start training ...\u0026#39;) solver.train() print(\u0026#39;Done training.\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: # python train.py --weights YOLO_small.ckpt --gpu 0 main() 参照hizhangp的指引就可以完成训练操作~\n  检测 通过cmd或Anaconda Prompt运行python test.py可以检测test文件夹里面的图片，这里我们直接用到了hizhangp训练完成的模型文件ckpt。假设我们对test文件中的cat进行检测，检测结果如图18所示。\n 图18. cat图像检测结果  检测阶段的test.py文件 import os import cv2 import argparse import numpy as np import tensorflow as tf import yolo.config as cfg from yolo.yolo_net import YOLONet from utils.timer import Timer os.environ[\u0026#39;TF_CPP_MIN_LOG_LEVEL\u0026#39;] = \u0026#39;2\u0026#39; class Detector(object): def __init__(self, net, weight_file): # 参数初始化 self.net = net self.weights_file = weight_file self.classes = cfg.CLASSES self.num_class = len(self.classes) self.image_size = cfg.IMAGE_SIZE self.cell_size = cfg.CELL_SIZE self.boxes_per_cell = cfg.BOXES_PER_CELL self.threshold = cfg.THRESHOLD self.iou_threshold = cfg.IOU_THRESHOLD self.boundary1 = self.cell_size * self.cell_size * self.num_class self.boundary2 = self.boundary1 + self.cell_size * self.cell_size * self.boxes_per_cell # 创建一个会话 self.sess = tf.Session() self.sess.run(tf.global_variables_initializer()) print(\u0026#39;Restoring weights from: \u0026#39; + self.weights_file) self.saver = tf.train.Saver() self.saver.restore(self.sess, self.weights_file) def draw_result(self, img, result): # 将框和原图放在一起并绘制出来 for i in range(len(result)): x = int(result[i][1]) y = int(result[i][2]) w = int(result[i][3] / 2) h = int(result[i][4] / 2) # cv2.rectangle是矩形框左上角和右下角的坐标 # cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)绘制矩形 # img表示原图; 第二个参数(x,y)表示矩形左上点坐标; 第三个参数(x+w,y+h)表示矩形右下点坐标; # (0,255,0)表示画线对应的rgb颜色(0 255 0 为青色); 2表示画线的宽度 # (125,125,125)为灰色; -1表示填充图形 cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2) cv2.rectangle(img, (x - w, y - h - 20), (x + w, y - h), (125, 125, 125), -1) lineType = cv2.LINE_AA if cv2.__version__ \u0026gt; \u0026#39;3\u0026#39; else cv2.CV_AA cv2.putText(img, result[i][0] + \u0026#39; : %.2f\u0026#39; % result[i][5], (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, lineType) def detect(self, img): img_h, img_w, _ = img.shape inputs = cv2.resize(img, (self.image_size, self.image_size)) inputs = cv2.cvtColor(inputs, cv2.COLOR_BGR2RGB).astype(np.float32) inputs = (inputs / 255.0) * 2.0 - 1.0 inputs = np.reshape(inputs, (1, self.image_size, self.image_size, 3)) # 预测测试集 result = self.detect_from_cvmat(inputs)[0] # 预测结果转换变换回原始图像中 for i in range(len(result)): result[i][1] *= (1.0 * img_w / self.image_size) result[i][2] *= (1.0 * img_h / self.image_size) result[i][3] *= (1.0 * img_w / self.image_size) result[i][4] *= (1.0 * img_h / self.image_size) return result def detect_from_cvmat(self, inputs): # 预测测试集的结果 net_output = self.sess.run(self.net.logits, feed_dict={self.net.images: inputs}) results = [] for i in range(net_output.shape[0]): results.append(self.interpret_output(net_output[i])) return results def interpret_output(self, output): probs = np.zeros((self.cell_size, self.cell_size, self.boxes_per_cell, self.num_class)) class_probs = np.reshape(output[0:self.boundary1], (self.cell_size, self.cell_size, self.num_class)) scales = np.reshape(output[self.boundary1:self.boundary2], (self.cell_size, self.cell_size, self.boxes_per_cell)) boxes = np.reshape(output[self.boundary2:], (self.cell_size, self.cell_size, self.boxes_per_cell, 4)) offset = np.array([np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell) offset = np.transpose(np.reshape(offset, [self.boxes_per_cell, self.cell_size, self.cell_size]), (1, 2, 0)) boxes[:, :, :, 0] += offset boxes[:, :, :, 1] += np.transpose(offset, (1, 0, 2)) boxes[:, :, :, :2] = 1.0 * boxes[:, :, :, 0:2] / self.cell_size boxes[:, :, :, 2:] = np.square(boxes[:, :, :, 2:]) boxes *= self.image_size for i in range(self.boxes_per_cell): for j in range(self.num_class): probs[:, :, i, j] = np.multiply(class_probs[:, :, j], scales[:, :, i]) filter_mat_probs = np.array(probs \u0026gt;= self.threshold, dtype=\u0026#39;bool\u0026#39;) filter_mat_boxes = np.nonzero(filter_mat_probs) boxes_filtered = boxes[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]] probs_filtered = probs[filter_mat_probs] classes_num_filtered = np.argmax(filter_mat_probs, axis=3)[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]] argsort = np.array(np.argsort(probs_filtered))[::-1] boxes_filtered = boxes_filtered[argsort] probs_filtered = probs_filtered[argsort] classes_num_filtered = classes_num_filtered[argsort] for i in range(len(boxes_filtered)): if probs_filtered[i] == 0: continue # 通过iou阈值去除多余Bounding Boxes for j in range(i + 1, len(boxes_filtered)): if self.iou(boxes_filtered[i], boxes_filtered[j]) \u0026gt; self.iou_threshold: probs_filtered[j] = 0.0 filter_iou = np.array(probs_filtered \u0026gt; 0.0, dtype=\u0026#39;bool\u0026#39;) boxes_filtered = boxes_filtered[filter_iou] probs_filtered = probs_filtered[filter_iou] classes_num_filtered = classes_num_filtered[filter_iou] result = [] for i in range(len(boxes_filtered)): result.append([self.classes[classes_num_filtered[i]], boxes_filtered[i][0], boxes_filtered[i][1], boxes_filtered[i][2], boxes_filtered[i][3], probs_filtered[i]]) return result def iou(self, box1, box2): tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2]) lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3]) inter = 0 if tb \u0026lt; 0 or lr \u0026lt; 0 else tb * lr return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter) def camera_detector(self, cap, wait=10): # 摄像机检测器 detect_timer = Timer() ret, _ = cap.read() while ret: ret, frame = cap.read() detect_timer.tic() result = self.detect(frame) detect_timer.toc() print(\u0026#39;Average detecting time: {:.3f}s\u0026#39;.format(detect_timer.average_time)) self.draw_result(frame, result) cv2.imshow(\u0026#39;Camera\u0026#39;, frame) cv2.waitKey(wait) ret, frame = cap.read() def image_detector(self, imname, wait=0): # test文件夹中图像检测 detect_timer = Timer() image = cv2.imread(imname) detect_timer.tic() result = self.detect(image) detect_timer.toc() print(\u0026#39;Average detecting time: {:.3f}s\u0026#39;.format(detect_timer.average_time)) self.draw_result(image, result) cv2.imshow(\u0026#39;Image\u0026#39;, image) cv2.waitKey(wait) def main(): parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;--weights\u0026#39;, default=\u0026quot;YOLO_small.ckpt\u0026quot;, type=str) parser.add_argument(\u0026#39;--weight_dir\u0026#39;, default=\u0026#39;weights\u0026#39;, type=str) parser.add_argument(\u0026#39;--data_dir\u0026#39;, default=\u0026quot;data\u0026quot;, type=str) parser.add_argument(\u0026#39;--gpu\u0026#39;, default=\u0026#39;\u0026#39;, type=str) args = parser.parse_args() os.environ[\u0026#39;CUDA_VISIBLE_DEVICES\u0026#39;] = args.gpu # Detection yolo = YOLONet(False) weight_file = os.path.join(args.data_dir, args.weight_dir, args.weights) detector = Detector(yolo, weight_file) # Detect from camera # cap = cv2.VideoCapture(-1) # detector.camera_detector(cap) # # Detect from image file imname = \u0026#39;test/person.jpg\u0026#39; detector.image_detector(imname) if __name__ == \u0026#39;__main__\u0026#39;: main()    Reference J. Redmon, S. Divvala, R. Girshick, A. Farhadi, “You Only Look Once: Unified Real-Time Object Detection”, IEEE Conference on Computer Vision and Pattern Recognition, pp. 779-788, 2016.\n 尤鱼哥. Yolo v1全面深度解读 目标检测论文\n hizhangp. Github yolo_tensorflow\n   ","date":1551830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551830400,"objectID":"f3c923ccf2952119ec03f78e9b86001f","permalink":"/post/tensorflow%E5%AE%9E%E7%8E%B0yolov1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","publishdate":"2019-03-06T00:00:00Z","relpermalink":"/post/tensorflow%E5%AE%9E%E7%8E%B0yolov1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","section":"post","summary":"目标检测是计算机视觉一个重要的领域，希望让计算机可以自己自动找出某张图片（某个视频的某一帧画面）中的物体，并认出它们是什么，这是一个具有挑战又有趣的任务。本文主要对YOLO(You Only Look Once)模型进行探讨并在TensorFlow上实现，YOLOv1是YOLO的第一个版本（YOLO version1），虽然它的目标检测效果不咋滴，但是现在YOLO进化到了第三个版本了，是一个极其强大的工具。为了更好的学习YOLOV3，那也需要领会它前辈YOLOv1的精髓所在。YOLOv1的作者有四个大佬，Joseph Redmon大佬喜欢用C语言，他们也用C语言搭建Darknet并实现了YOLOv1，这也让众多YOLO信徒不知如何用TensorFlow来领悟其中的奥妙。github找到零零散散几个有关于YOLOv1的，但是大多数只有检测过程，而没有训练过程。几番周折，找到了既有训练又能检测的代码。本文参照hizhangp的Github仓库代码，对模型进行介绍和探讨，同时对代码进行解读并实际完成目标检测。\nYou Only Look Once, 你不要看我第二次（//▽//） YOLOv1采用一个单独的CNN模型实现end-to-end的目标检测，它的思想正如它paper的标题一般，你只看一次，就能看出图片中有什么东西，达到跟人类基本一样的探索功能。就像你看到下面这只可爱的黄色电气鼠，一瞄就知道是皮卡丘！\n 图1. 我是谁？皮卡丘！  YOLO(本文指YOLO version1)的大体检测框架是：首先通过转换图像为\\(448\\times 448\\)大小的输入，在图像输入之后YOLO会将其分为\\(S\\times S\\)的grid cell（小格子）。每一个grid cell会产生B个边界框（Bounding Box），每个Bounding Box会附带一个置信度值。原文中设定了每张图像分为\\(7\\times 7\\)的grid cell，每个grid cell产生2个Bounding Boxes，那所有的grid cell总共会生成98($772)个边界框；另外原文设定了检测物体的类别数为20。需要注意的是，在原文中多次出现exist和appear的词，表示grid cell中包含了object，但其实更准确的是表示object的中心点出现在这个grid cell中。在完成训练阶段之后，通过非极大值抑制来去除多余的边界框并完成检测（后面会补充介绍非极大值抑制的内容）~\n 图2. YOLO检测系统细节图  YOLO模型训练阶段（Traning）解析 YOLO检测网络包含了24个卷积层和2个全连接层，其中也运用了最大池化层，如图3所示：\n 图3. YOLO检测网络图  其中激活函数使用了leaky relu函数： \\[ \\phi(x) = \\left\\{ \\begin{array}{l} x,\\quad\\ \\ \\text{if}\\ \\ x\u0026gt;0\\\\ 0.1x,\\ \\text{otherwise} \\end{array} \\right. \\]\n最终模型网络输出的是一个\\(7\\times 7\\times 30\\)的张量（Tensor），这里我们可以看作49(\\(7\\times 7\\))个grid cells，其中每个grid cell中涉及30个通道（channel）。这30个channels中有2组对应2个Bounding Boxes的信息（总共占用10(\\(2\\times 5\\))个channels），剩下的20个channels对应的是20个检测类的概率。\n前5个channels（张量的第1-5d的位置）中的参数分别是第一个Bounding Box（黄色边界框）的四个坐标值以及相应的置信度。这四个坐标(\\(x,y,w,h\\))中(\\(x,y\\))是物体中心点相对于左上角的坐标值，(\\(w,h\\))是Bounding Box的宽和高，以中心点坐标就可以确定Bounding Box的大小。","tags":["ObjectDetection","Deep Learning","TensorFlow"],"title":"TensorFlow实现YOLOv1目标检测","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":" 用Git下载keras-yolo3库 首先你电脑如果安装了Git，那在你希望存储的文件夹目录中打开Git Bash，接着输入一行命令就可以了~\n$ git clone https://github.com/qqwweee/keras-yolo3.git Git会很快帮你下载整个仓库(Repository)~\n那如果你没有安装Git也没关系，打开Github的keras-yolo3仓库，点击Clone or download后再点击Download ZIP，也是一样的。\n 用pip下Python库 Github上作者qqwweee已经把代码都完成了，所以我们只需要确保所需的库也安装了，就万事俱备，只欠东风！\n TensorFlow\n Keras\n h5py\n OpenCV  通常安装库的方法会选用pip来下载安装，打开Anaconda prompt之后输入命令：\nactivate python35 # 激活python3.5环境 pip install tensorflow pip install keras pip install h5py pip install opencv-python 完成安装后就开始正题了！\n YOLO的实现 下载yolov3.weight和格式变换 我们可以直接从YOLO官网可以下载预训练的权重yolov3.weight，也可以通过命令行进行下载；\n先打开Anaconda Prompt（或者cmd）并路径更新到当前keras-yolo3所在文件夹路径，通过下面命令行可完成对yolov3.weight的下载，并转成TensorFlow所支持的h5文件。\nwget https://pjreddie.com/media/files/yolov3.weights python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5  测试demo图像文件 如果想对某张图片进行检测，可以将这张图片放在当前keras-yolo3所在文件夹，再通过Anaconda Prompt运行下面命令\npython yolo_vedio.py --image 命令行运行后会弹出“Input image filename:”，输入指定图片文件即可。\n举个栗子~\n 大家一起放风筝~  YOLOv3的Output效果不错！！\n Enjoy your YOLO now !!!\n  ","date":1550620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550620800,"objectID":"67494f22c5a8a49c4eaf4319ab58f065","permalink":"/post/tensorflow-keras%E5%AE%9E%E7%8E%B0yolov3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","publishdate":"2019-02-20T00:00:00Z","relpermalink":"/post/tensorflow-keras%E5%AE%9E%E7%8E%B0yolov3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","section":"post","summary":"用Git下载keras-yolo3库 首先你电脑如果安装了Git，那在你希望存储的文件夹目录中打开Git Bash，接着输入一行命令就可以了~\n$ git clone https://github.com/qqwweee/keras-yolo3.git Git会很快帮你下载整个仓库(Repository)~\n那如果你没有安装Git也没关系，打开Github的keras-yolo3仓库，点击Clone or download后再点击Download ZIP，也是一样的。\n 用pip下Python库 Github上作者qqwweee已经把代码都完成了，所以我们只需要确保所需的库也安装了，就万事俱备，只欠东风！\n TensorFlow\n Keras\n h5py\n OpenCV  通常安装库的方法会选用pip来下载安装，打开Anaconda prompt之后输入命令：\nactivate python35 # 激活python3.5环境 pip install tensorflow pip install keras pip install h5py pip install opencv-python 完成安装后就开始正题了！\n YOLO的实现 下载yolov3.weight和格式变换 我们可以直接从YOLO官网可以下载预训练的权重yolov3.weight，也可以通过命令行进行下载；\n先打开Anaconda Prompt（或者cmd）并路径更新到当前keras-yolo3所在文件夹路径，通过下面命令行可完成对yolov3.weight的下载，并转成TensorFlow所支持的h5文件。\nwget https://pjreddie.com/media/files/yolov3.weights python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5  测试demo图像文件 如果想对某张图片进行检测，可以将这张图片放在当前keras-yolo3所在文件夹，再通过Anaconda Prompt运行下面命令\npython yolo_vedio.py --image 命令行运行后会弹出“Input image filename:”，输入指定图片文件即可。\n举个栗子~\n 大家一起放风筝~  YOLOv3的Output效果不错！！","tags":["TensorFlow","Deep Learning"],"title":"TensorFlow+Keras实现YOLOv3目标检测","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":" 前言 循环神经网络（Recurrent Nerual Network, RNN）在Deep Learning领域中是一个经典有很重要的神经网络模型。RNN是在自然语言处理（Natural Language Processing, NLP）领域最先被使用发展起来的。在NLP中通常会处理一些文字句子，比如我们想做一个机器翻译，把中文转换成英文。初中生可能在翻译的时候只会逐个中文词翻译成英文，但高中生就可能会对翻译中的词进行调整，结合前后的词汇，那我们也希望机器这样做。\n假设有一段对话：\nA：你好吗？\nB：我很好。\n我们想让机器翻译成英文，对于A而言，机器可能在一些训练后很容易翻译成“How are you?”，但对于B可能就翻译成了“I’m ok.”。那就相当尴尬了~（想起某军的Are you ok?╭(●｀∀´●)╯）机器其实需要参考A问了什么，再来对B的回答进行翻译，才能获得比较好的回答翻译“I’m fine.”\nRNN就是专门解决了处理序列化数据的问题，像上面这样的小例子。\n 简单循环神经网络 对于简单RNN，它由输入层，一个隐藏层和一个输出层构成的，像这样子：  图1. 简单RNN示意图  先看左边的图时会觉得不能理解，但是如果将其展开得到右边的图，就比较好理解了。在\\(t\\)时刻，\\(x_t\\)作为输入的同时，还有上一个时刻隐藏层的\\(h_{t-1}\\)，以\\(V\\)为权重作为第\\(t\\)时刻的输入。我们用计算公式来表示，可以表示为： \\[ h_t = f (U x_t + V h_{t-1})\\\\ o_t = \\sigma (W h_t) \\] 其中\\(f\\)和\\(\\sigma\\)是激活函数（Activation function）。\n如果将上面两个式子联合可以得到： \\[ \\begin{align} o_t \u0026amp;= \\sigma (W h_t)\\\\ \u0026amp;= \\sigma (W f (U x_t + V h_{t-1}))\\\\ \u0026amp;= \\sigma (W f (U x_t + V f (U x_{t-1} + V h_{t-2})))\\\\ \u0026amp;=\\ ... \\end{align} \\] 可以看到我们会得到一个循环向前的公式，循环神经网络的输出值\\(o_t\\)是受到前面历次输入值\\(x_t, x_{t-1}, x_{t-2}, \\dots\\)的影响的。\n 深度RNN \u0026amp; 梯度消失与爆炸 在介绍完简单RNN后，我们会考虑添加更多的隐藏层，那就可以得到深度RNN（如图2）；在这样多个隐藏层的神经网络结构中，我们通过反向传播就可以计算更新网络的参数。  图2. 深度RNN示意图  当神经网络中层数太多的话，可能就会出现梯度消失。举个例子：\n假设我们用了激活函数sigmoid函数 \\[ f(x) = \\frac{1}{1+e^{-x}} \\]\n它的导数为 \\[ f\u0026#39;(x) = f(x)(1-f(x)) \\]\n我们知道\\(1 + e^{-x} \u0026gt; 1\\)，所以可以得到\\(0 \u0026lt; f(x) \u0026lt; 1\\)。\n对于导数\\(f\u0026#39;(x)\\)，我们可以通过\\(-\\frac{b}{2a}\\)计算得到，当\\(f(x) = 0.5\\)时，\\(f\u0026#39;(x)\\)取得最大值为\\(0.25\\)。 在反向传播计算过程中，每经过一个sigmoid函数，便需要乘以一个sigmoid函数的导数值，那残差就至少会被削减变为原来的0.25倍；如果整个循环神经网络的时间长度很长，那么可能残差传递到前面的某一时刻就基本为0了；这样会导致在往前的时刻中无法更新参数，这就是梯度消失。\n同理，如果导数的最小值是不小于1的，那么残差在传递中就会一次比一次大，如果整个循环神经网络的时间长度很长，那每次参数的更新就会非常剧烈，这就是梯度爆炸。下面用数学推导表示梯度消失与梯度爆炸。\n数学推导下的梯度消失与梯度爆炸 我们在前面的时候用计算公式表达了简单RNN： \\[ h_t = f (U x_t + V h_{t-1})\\\\ o_t = \\sigma (W h_t) \\]\n如果将公式写的更明细的话，可以表达为： \\[ \\begin{bmatrix} h_1^t\\\\ h_2^t\\\\ .\\\\ .\\\\ h_n^t \\end{bmatrix} = f\\bigg( \\begin{bmatrix} u_{11} \u0026amp; u_{12} \u0026amp; \\cdots \u0026amp; u_{1m}\\\\ u_{21} \u0026amp; u_{22} \u0026amp; \\cdots \u0026amp; u_{2m}\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ u_{n1} \u0026amp; u_{n2} \u0026amp; \\cdots \u0026amp; u_{nm}\\\\ \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ .\\\\ .\\\\ x_m \\end{bmatrix} + \\begin{bmatrix} v_{11} \u0026amp; v_{12} \u0026amp; \\cdots \u0026amp; v_{1n}\\\\ v_{21} \u0026amp; v_{22} \u0026amp; \\cdots \u0026amp; v_{2n}\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ v_{n1} \u0026amp; v_{n2} \u0026amp; \\cdots \u0026amp; v_{nn}\\\\ \\end{bmatrix} \\begin{bmatrix} h_1^{t-1}\\\\ h_2^{t-1}\\\\ .\\\\ .\\\\ h_n^{t-1} \\end{bmatrix} \\bigg) \\]\n其中，\\(h_j^t\\)表示向量\\(h\\)的第\\(j\\)个元素在\\(t\\)时刻的值；\\(u_ji\\)表示输入层第\\(i\\)个神经元到循环层第\\(j\\)个神经元的权重；\\(w_ij\\)表示循环层第\\(t-1\\)时刻的第\\(i\\)个神经元到循环层第\\(t\\)个时刻的第\\(j\\)个神经元的权重。\n我们用向量\\(net_t\\)来表示神经元在\\(t\\)时刻的加权输入： \\[ net_t = Ux_t + Vh_{t-1}\\\\ h_t = f(net_t) \\] 同样有： \\[ h_{t-1} = f(net_{t-1}) \\] 因此： \\[ \\frac{\\partial net_t}{\\partial net_{t-1}} = \\frac{\\partial net_t}{\\partial h_{t-1}}\\frac{\\partial h_{t-1}}{\\partial net_{t-1}} \\] 由\\(net_t = Ux_t + Vh_{t-1}\\)式子，右边等式的第一部分可以推导得到： \\[ \\begin{align} \\frac{\\partial net_t}{\\partial h_{t-1}} \u0026amp; = \\begin{bmatrix} \\frac{\\partial net_1^t}{\\partial h_1^{t-1}} \u0026amp; \\frac{\\partial net_1^t}{\\partial h_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial net_1^t}{\\partial h_n^{t-1}}\\\\ \\frac{\\partial net_2^t}{\\partial h_1^{t-1}} \u0026amp; \\frac{\\partial net_2^t}{\\partial h_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial net_2^t}{\\partial h_n^{t-1}}\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ \\frac{\\partial net_n^t}{\\partial h_1^{t-1}} \u0026amp; \\frac{\\partial net_n^t}{\\partial h_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial net_n^t}{\\partial h_n^{t-1}}\\\\ \\end{bmatrix}\\\\ \u0026amp;= \\begin{bmatrix} v_{11} \u0026amp; v_{12} \u0026amp; \\cdots \u0026amp; v_{1n}\\\\ v_{21} \u0026amp; v_{22} \u0026amp; \\cdots \u0026amp; v_{2n}\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ v_{n1} \u0026amp; v_{n2} \u0026amp; \\cdots \u0026amp; v_{nn}\\\\ \\end{bmatrix}\\\\ \u0026amp;= V \\end{align} \\] 同理由\\(h_{t-1} = f(net_{t-1})\\)式子，右边等式的第二部分可以推导得到： \\[ \\begin{align} \\frac{\\partial h_{t-1}}{\\partial net_{t-1}} \u0026amp;= \\begin{bmatrix} \\frac{\\partial h_1^{t-1}}{\\partial net_1^{t-1}} \u0026amp; \\frac{\\partial h_1^{t-1}}{\\partial net_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial h_1^{t-1}}{\\partial net_n^{t-1}}\\\\ \\frac{\\partial h_2^{t-1}}{\\partial net_1^{t-1}} \u0026amp; \\frac{\\partial h_2^{t-1}}{\\partial net_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial h_2^{t-1}}{\\partial net_n^{t-1}}\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ \\frac{\\partial h_n^{t-1}}{\\partial net_1^{t-1}} \u0026amp; \\frac{\\partial h_n^{t-1}}{\\partial net_2^{t-1}} \u0026amp; \\cdots \u0026amp; \\frac{\\partial h_n^{t-1}}{\\partial net_n^{t-1}}\\\\ \\end{bmatrix}\\\\ \u0026amp;= \\begin{bmatrix} f\u0026#39;(net_1^{t-1}) \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0\\\\ 0 \u0026amp; f\u0026#39;(net_2^{t-1}) \u0026amp; \\cdots \u0026amp; 0\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; f\u0026#39;(net_n^{t-1})\\\\ \\end{bmatrix}\\\\ \u0026amp;= diag[f\u0026#39;(net_{t-1})] \\end{align} \\] 因此我们可以得到： \\[ \\begin{align} \\frac{\\partial net_t}{\\partial net_{t-1}} \u0026amp;= \\frac{\\partial net_t}{\\partial h_{t-1}}\\frac{\\partial h_{t-1}}{\\partial net_{t-1}}\\\\ \u0026amp;= V diag[f\u0026#39;(net_{t-1})]\\\\ \u0026amp;= \\begin{bmatrix} v_{11}f\u0026#39;(net_1^{t-1}) \u0026amp; v_{12}f\u0026#39;(net_2^{t-1}) \u0026amp; \\cdots \u0026amp; v_{1n}f\u0026#39;(net_n^{t-1})\\\\ v_{21}f\u0026#39;(net_1^{t-1}) \u0026amp; v_{22}f\u0026#39;(net_2^{t-1}) \u0026amp; \\cdots \u0026amp; v_{2n}f\u0026#39;(net_n^{t-1})\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ . \u0026amp; . \u0026amp; . \u0026amp; .\\\\ v_{n1}f\u0026#39;(net_1^{t-1}) \u0026amp; v_{n2}f\u0026#39;(net_2^{t-1}) \u0026amp; \\cdots \u0026amp; v_{nn}f\u0026#39;(net_n^{t-1})\\\\ \\end{bmatrix}\\\\ \\end{align} \\]\n我们可以求得任意时刻\\(k\\)的残差值\\(\\delta_k\\)： \\[ \\begin{align} \\delta_k \u0026amp;= \\frac{\\partial E}{\\partial net_k}\\\\ \u0026amp;= \\frac{\\partial E}{\\partial net_t}\\frac{\\partial net_t}{\\partial net_k}\\\\ \u0026amp;= \\frac{\\partial E}{\\partial net_t}\\frac{\\partial net_t}{\\partial net_{t-1}}\\frac{\\partial net_{t-1}}{\\partial net_{t-2}}\\cdots\\frac{\\partial net_{k+1}}{\\partial net_k}\\\\ \u0026amp;= \\delta_t V diag[f\u0026#39;(net_{t-1})]V diag[f\u0026#39;(net_{t-2})]\\cdots V diag[f\u0026#39;(net_k)]\\\\ \u0026amp;= \\delta_t \\prod_{i=k}^{t-1}V diag[f\u0026#39;(net_i)] \\end{align} \\] 从上面式子我们可以得到： \\[ \\begin{align} \u0026amp; \\delta_k = \\delta_t \\prod_{i=k}^{t-1}V diag[f\u0026#39;(net_i)]\\\\ \\Rightarrow\\ \\ \u0026amp; ||\\delta_k|| \\leq ||\\delta_t|| \\prod_{i=k}^{t-1} ||V|| \\cdot ||diag[f\u0026#39;(net_i)]||\\\\ \\end{align} \\] 其中模可以看作对\\(\\delta_k\\)中每一项值得大小的度量，假定\\(\\beta_f\\)和\\(\\beta_W\\)分别是\\(||diag[f\u0026#39;(net_i)]||\\)和\\(||V||\\)的上界，那么 \\[ ||\\delta_k|| \\leq ||\\delta_t|| (\\beta_f \\beta_W)^{t-k} \\] 显然，如果\\(\\beta_f \\beta_W\\)的乘积比1小或者比1大时，由于指数的缘故，那么残差就可能会变得很小几乎为0或者变得很大。前者就是梯度消失，后者就是梯度爆炸。所以，普通的RNN是无法处理长距离依赖的原因。经过科学家们的努力，终于在1997年，由Sepp Hochreiter和Jürgen Schmidhuber两位科学家提出了长短时间记忆（LSTM），解决了RNN这样的问题。\n  长短时间记忆（Long Short Term Memory, LSTM） 长短时间记忆网络在原来普通RNN的基础上再加了一个状态\\(c\\)，用来保存长期的状态，这个状态也称为单元状态（cell state）。  图3. 普通RNN和LSTM  LSTM中输入有三个：\\(x_t\\)，\\(h_{t-1}\\)和\\(c_{t-1}\\)；而输出有两个：\\(h_t\\)和\\(c_t\\)；另外，LSTM引入了“门”或者“开关”这样的概念，用来控制不同阶段的数据输入和输出，分别是：\n 遗忘门（Forget gate）：控制单元状态\\(c_{t-1}\\)保留多少到\\(c_t\\)；它的计算公式为： \\[ f_t = \\sigma(U^{(f)}x_t + V^{(f)}h_{t-1}) \\] 其中，\\(\\sigma\\)是激活函数（一般sigmoid函数）。  图4. 遗忘门示意图  结合上一时刻单元状态\\(c_{t-1}\\)，\\(f_t\\)决定了保留多少上一时刻单元状态，所以用乘积计算，计算公式为： \\[ c_t = f_t\\circ c_{t-1} \\]  图5. 遗忘门结合上一时刻单元状态示意图  这里的\\(c_t\\)只是计算过程中一个值，还不是输出时的单元状态。\n 输入门（Input gate）：控制输入\\(x_t\\)保存多少到\\(c_t\\)；它的计算公式为： \\[ i_t = \\sigma(U^{(i)}x_t + V^{(i)}h_{t-1})\\\\ \\tilde{c}_t = \\tanh (U^{(c)}x_t + V^{(c)}h_{t-1}) \\]  图6. 输入门示意图   其中，我们把\\(\\tilde{c}_t\\)称为“候选状态”，结合从遗忘门出来的\\(c_t\\)，我们将三者结合，计算公式为： \\[ \\begin{align} c_t \u0026amp;= c_t + i_t\\circ \\tilde{c}_t\\\\ \\Rightarrow c_t \u0026amp;= f_t\\circ c_{t-1} + i_t\\circ \\tilde{c}_t \\end{align} \\]  图7. 输入门结合候选状态和单元状态示意图   输出门（Output gate）：控制单元状态\\(c_t\\)输出多少到\\(h_t\\)；它的计算公式为： \\[ e_t = \\sigma(U^{(e)}x_t + V^{(e)}h_{t-1})\\\\ h_t = \\tanh (c_t)\\circ e_t \\]  图8. 输出门结合单元状态示意图   上面提及的参数在初始化设置为接近0的较小值，对于长短时间记忆网络的训练，让我们慢慢叙述~\nLSTM的训练 残差值沿时间的反向传播计算\n在推导之前，我们先假定每个gate的激活函数为sigmoid函数，而其中我们还涉及到了tanh函数，它们的公式及导数分别为： \\[ \\sigma(x) = \\frac{1}{1+e^{-x}}\\\\ \\sigma\u0026#39;(x) = \\sigma(x)(1-\\sigma(x))\\\\ \\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\\\\ \\tanh\u0026#39;(x) = 1-\\tanh(x)^2 \\] 显然，它们的导数均可以用它们本身进行表示，在计算过程中，我们只需要计算它们各自的值，就可以计算得到对应导数的值。\n另外，对于符号\\(\\circ\\)，当作用于向量时，它的运算时对应元素的相乘，即： \\[ \\text{a}\\circ \\text{b} = \\begin{bmatrix} a_1\\\\ a_2\\\\ a_3\\\\ \\cdots\\\\ a_n \\end{bmatrix} \\circ \\begin{bmatrix} b_1\\\\ b_2\\\\ b_3\\\\ \\cdots\\\\ b_n \\end{bmatrix} = \\begin{bmatrix} a_1b_1\\\\ a_2b_2\\\\ a_3b_3\\\\ \\cdots\\\\ a_nb_n \\end{bmatrix} \\] 当作用于向量和矩阵时，它的计算为： \\[ \\begin{align} \\text{a}\\ \\circ \\text{X} \u0026amp;= \\begin{bmatrix} a_1\\\\ a_2\\\\ a_3\\\\ \\cdots\\\\ a_n \\end{bmatrix} \\circ \\begin{bmatrix} x_{11} \u0026amp; x_{12} \u0026amp; x_{13} \u0026amp; \\cdots \u0026amp; x_{1n}\\\\ x_{21} \u0026amp; x_{22} \u0026amp; x_{23} \u0026amp; \\cdots \u0026amp; x_{2n}\\\\ x_{31} \u0026amp; x_{32} \u0026amp; x_{33} \u0026amp; \\cdots \u0026amp; x_{3n}\\\\ \u0026amp; \u0026amp; \\cdots\\\\ x_{n1} \u0026amp; x_{n2} \u0026amp; x_{n3} \u0026amp; \\cdots \u0026amp; x_{nn} \\end{bmatrix}\\\\ \u0026amp;= \\begin{bmatrix} a_1x_{11} \u0026amp; a_1x_{12} \u0026amp; a_1x_{13} \u0026amp; \\cdots \u0026amp; a_1x_{1n}\\\\ a_2x_{21} \u0026amp; a_2x_{22} \u0026amp; a_2x_{23} \u0026amp; \\cdots \u0026amp; a_2x_{2n}\\\\ a_3x_{31} \u0026amp; a_3x_{32} \u0026amp; a_3x_{33} \u0026amp; \\cdots \u0026amp; a_3x_{3n}\\\\ \u0026amp; \u0026amp; \\cdots\\\\ a_nx_{n1} \u0026amp; a_nx_{n2} \u0026amp; a_nx_{n3} \u0026amp; \\cdots \u0026amp; a_nx_{nn} \\end{bmatrix} \\end{align} \\] 当作用于矩阵和矩阵时，两个矩阵的对应位置的元素相乘。\n同时，我们定义在\\(t\\)时刻，LSTM中的输出值为\\(h_t\\)，残差值\\(\\delta_t\\)为\\(\\delta_t = \\frac{\\partial E}{\\partial h_t}\\)。\n利用反向传播算法，我们需要得到的是前面时刻的残差值，假定现在我们先求上一时刻\\(t-1\\)时刻的残差值\\(\\delta_{t-1}\\)。 \\[ \\begin{align} \\delta_{t-1} \u0026amp;= \\frac{\\partial E}{\\partial h_{t-1}}\\\\ \u0026amp;= \\frac{\\partial E}{\\partial h_t}\\frac{\\partial h_t}{\\partial h_{t-1}}\\\\ \u0026amp;= \\delta_t\\frac{\\partial h_t}{\\partial h_{t-1}} \\end{align} \\] 由前面的推导，我们知道 \\[ h_t = \\tanh(c_t)\\circ e_t\\\\ c_t = f_t\\circ c_{t-1} + i_t\\circ \\tilde{c}_t\\\\ f_t = \\sigma(U^{(f)}x_t + V^{(f)}h_{t-1})\\\\ i_t = \\sigma(U^{(i)}x_t + V^{(i)}h_{t-1})\\\\ \\tilde{c}_t = \\tanh (U^{(c)}x_t + V^{(c)}h_{t-1})\\\\ e_t = \\sigma(U^{(e)}x_t + V^{(e)}h_{t-1}) \\] 对于导数\\(\\frac{\\partial h_t}{\\partial h_{t-1}}\\)，我们得到： \\[ \\frac{\\partial h_t}{\\partial h_{t-1}} = \\frac{\\partial h_t}{\\partial e_t}\\frac{\\partial e_t}{\\partial h_{t-1}} + \\frac{\\partial h_t}{\\partial c_t}\\frac{\\partial c_t}{\\partial f_t}\\frac{\\partial f_t}{\\partial h_{t-1}} + \\frac{\\partial h_t}{\\partial c_t}\\frac{\\partial c_t}{\\partial i_t}\\frac{\\partial i_t}{\\partial h_{t-1}} + \\frac{\\partial h_t}{\\partial c_t}\\frac{\\partial c_t}{\\partial \\tilde{c}_t}\\frac{\\partial \\tilde{c}_t}{\\partial h_{t-1}} \\] 由于 \\[ \\begin{align} \\frac{\\partial h_t}{\\partial e_t} \u0026amp;= diag[\\tanh(c_t)]\\\\ \\frac{\\partial e_t}{\\partial h_{t-1}} \u0026amp;= diag[e_t\\circ (1-e_t)]\\ V^{(e)}\\\\ \\frac{\\partial h_t}{\\partial c_t} \u0026amp;= diag[e_t\\circ (1-\\tanh(c_t)^2)]\\\\ \\frac{\\partial c_t}{\\partial f_t} \u0026amp;= diag[c_{t-1}]\\\\ \\frac{\\partial c_t}{\\partial i_t} \u0026amp;= diag[\\tilde{c}_t]\\\\ \\frac{\\partial c_t}{\\partial \\tilde{c}_t} \u0026amp;= diag[i_t]\\\\ \\frac{\\partial f_t}{\\partial h_{t-1}} \u0026amp;= diag[f_t\\circ (1-f_t)]\\ V^{(f)}\\\\ \\frac{\\partial i_t}{\\partial h_{t-1}} \u0026amp;= diag[i_t\\circ (1-i_t)]\\ V^{(i)}\\\\ \\frac{\\partial \\tilde{c}_t}{\\partial h_{t-1}} \u0026amp;= diag[1-\\tilde{c}_t^2]\\ V^{(c)} \\end{align} \\] 因此， \\[ \\begin{align} \\frac{\\partial h_t}{\\partial h_{t-1}} = \u0026amp;\\ diag[\\tanh(c_t)] diag[e_t\\circ (1-e_t)] V^{(e)}\\\\ \u0026amp;\\ + diag[e_t\\circ (1-\\tanh(c_t)^2)] diag[c_{t-1}] diag[f_t\\circ (1-f_t)] V^{(f)}\\\\ \u0026amp;\\ + diag[e_t\\circ (1-\\tanh(c_t)^2)] diag[\\tilde{c}_t] diag[i_t\\circ (1-i_t)] V^{(i)}\\\\ \u0026amp;\\ + diag[e_t\\circ (1-\\tanh(c_t)^2)] diag[i_t] diag[1-\\tilde{c}_t^2] V^{(c)}\\\\ = \u0026amp;\\ \\tanh(c_t)\\circ e_t\\circ (1-e_t) V^{(e)}\\\\ \u0026amp;\\ + e_t\\circ (1-\\tanh(c_t)^2)\\circ c_{t-1}\\circ f_t\\circ (1-f_t) V^{(f)}\\\\ \u0026amp;\\ + e_t\\circ (1-\\tanh(c_t)^2)\\circ \\tilde{c}_t\\circ i_t\\circ (1-i_t)\\\\ \u0026amp;\\ + e_t\\circ (1-\\tanh(c_t)^2)\\circ i_t\\circ (1-\\tilde{c}_t^2) \\end{align} \\] 可以求得\\(t-1\\)时刻的残差值： \\[ \\begin{align} \\delta_{t-1} \u0026amp;= \\delta_t\\frac{\\partial h_t}{\\partial h_{t-1}}\\\\ \u0026amp;= \\delta_t\\circ \\tanh(c_t)\\circ e_t\\circ (1-e_t) V^{(e)}\\\\ \u0026amp;\\ + \\delta_t\\circ e_t\\circ (1-\\tanh(c_t)^2)\\circ c_{t-1}\\circ f_t\\circ (1-f_t) V^{(f)}\\\\ \u0026amp;\\ + \\delta_t\\circ e_t\\circ (1-\\tanh(c_t)^2)\\circ \\tilde{c}_t\\circ i_t\\circ (1-i_t)\\\\ \u0026amp;\\ + \\delta_t\\circ e_t\\circ (1-\\tanh(c_t)^2)\\circ i_t\\circ (1-\\tilde{c}_t^2) \\end{align} \\] 同理，利用 \\[ \\begin{align} \\delta_k \u0026amp;= \\delta_t\\frac{\\partial h_t}{\\partial h_k}\\\\ \u0026amp;= \\delta_t\\frac{\\partial h_t}{\\partial h_{t-1}}\\frac{\\partial h_{t-1}}{\\partial h_k}\\\\ \u0026amp;= \\delta_t\\frac{\\partial h_t}{\\partial h_{t-1}}\\frac{\\partial h_{t-1}}{\\partial h_{t-2}} \\cdots \\frac{\\partial h_{k+1}}{\\partial h_k}\\\\ \\end{align} \\] 可以求得任意时刻\\(k\\)的残差值。\n对于残差值沿隐藏层的反向传播，其计算方法与之前提及的反向传播基本一致。\n  实践出真知 import tensorflow as tf import pandas as pd from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(\u0026quot;mnist/\u0026quot;) # 训练参数 n_epoches = 100 batch_size = 150 Learning_rate = 0.001 # 网络参数，把28x28的图片数据拆成28行的时序数据喂进RNN n_inputs = 28 n_steps = 28 n_hiddens = 150 n_outputs = 10 # 10分类 # 输入tensors X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) y = tf.placeholder(tf.int32, [None]) # 构建RNN结构 basic_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_hiddens, state_is_tuple=True) # basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_hiddens) # basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_hiddens) # 另一种创建基本单元的方式 outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32) # 前向传播，定义损失函数、优化器 logits = tf.layers.dense(states[-1], n_outputs) # 与states tensor连接的全连接层，LSTM时为states[-1]，即h张量 cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) loss = tf.reduce_mean(cross_entropy) optimizer = tf.train.AdamOptimizer(learning_rate=Learning_rate) train_op = optimizer.minimize(loss) prediction = tf.nn.in_top_k(logits, y, 1) accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32)) # cast函数将tensor转换为指定类型 # 从MNIST中读取数据 X_test = mnist.test.images.reshape([-1, n_steps, n_inputs]) y_test = mnist.test.labels # 训练阶段 init = tf.global_variables_initializer() loss_list = [] accuracy_list = [] with tf.Session() as sess: sess.run(init) n_batches = mnist.train.num_examples // batch_size # 整除返回整数部分 # print(\u0026quot;Batch_number: {}\u0026quot;.format(n_batches)) for epoch in range(n_epoches): for iteration in range(n_batches): X_batch, y_batch = mnist.train.next_batch(batch_size) X_batch = X_batch.reshape([-1, n_steps, n_inputs]) sess.run(train_op, feed_dict={X: X_batch, y: y_batch}) loss_train = loss.eval(feed_dict={X: X_batch, y: y_batch}) loss_list.append(loss_train) acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch}) acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test}) accuracy_list.append(acc_test) print(epoch, \u0026quot;Train accuracy: {:.3f}\u0026quot;.format(acc_train), \u0026quot;Test accuracy: {:.3f}\u0026quot;.format(acc_test)) # 导出损失和准确率，方便绘图 loss_readout = pd.DataFrame(loss_list) loss_readout.to_csv(\u0026#39;csv/RNN_LSTM_loss.csv\u0026#39;) acc_readout = pd.DataFrame(accuracy_list) acc_readout.to_csv(\u0026#39;csv/RNN_LSTM_accuracy.csv\u0026#39;) 运行结果可以绘制出loss和accuracy两图：  Reference 1.hanbingtao. 零基础入门深度学习(5) - 循环神经网络\n2.hanbingtao. 零基础入门深度学习(6) - 长短时记忆网络(LSTM)\n3.罗冬日. TensorFlow入门与实战\n4.郑思座. 循环神经网络（RNN）以及简单TensorFlow实例\n ","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"bd748b358e6d62ce13c670ea4d186d3c","permalink":"/post/recurrent-nerual-network-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/post/recurrent-nerual-network-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","section":"post","summary":"前言 循环神经网络（Recurrent Nerual Network, RNN）在Deep Learning领域中是一个经典有很重要的神经网络模型。RNN是在自然语言处理（Natural Language Processing, NLP）领域最先被使用发展起来的。在NLP中通常会处理一些文字句子，比如我们想做一个机器翻译，把中文转换成英文。初中生可能在翻译的时候只会逐个中文词翻译成英文，但高中生就可能会对翻译中的词进行调整，结合前后的词汇，那我们也希望机器这样做。\n假设有一段对话：\nA：你好吗？\nB：我很好。\n我们想让机器翻译成英文，对于A而言，机器可能在一些训练后很容易翻译成“How are you?”，但对于B可能就翻译成了“I’m ok.”。那就相当尴尬了~（想起某军的Are you ok?╭(●｀∀´●)╯）机器其实需要参考A问了什么，再来对B的回答进行翻译，才能获得比较好的回答翻译“I’m fine.”\nRNN就是专门解决了处理序列化数据的问题，像上面这样的小例子。\n 简单循环神经网络 对于简单RNN，它由输入层，一个隐藏层和一个输出层构成的，像这样子：  图1. 简单RNN示意图  先看左边的图时会觉得不能理解，但是如果将其展开得到右边的图，就比较好理解了。在\\(t\\)时刻，\\(x_t\\)作为输入的同时，还有上一个时刻隐藏层的\\(h_{t-1}\\)，以\\(V\\)为权重作为第\\(t\\)时刻的输入。我们用计算公式来表示，可以表示为： \\[ h_t = f (U x_t + V h_{t-1})\\\\ o_t = \\sigma (W h_t) \\] 其中\\(f\\)和\\(\\sigma\\)是激活函数（Activation function）。\n如果将上面两个式子联合可以得到： \\[ \\begin{align} o_t \u0026amp;= \\sigma (W h_t)\\\\ \u0026amp;= \\sigma (W f (U x_t + V h_{t-1}))\\\\ \u0026amp;= \\sigma (W f (U x_t + V f (U x_{t-1} + V h_{t-2})))\\\\ \u0026amp;=\\ .","tags":["Deep Learning"],"title":"Recurrent Nerual Network 循环神经网络","type":"post"},{"authors":null,"categories":["LaTeX"],"content":" Liam Huang曾说过：\n 选择TeX Live，选择简单的人生；\n选择MiKTeX，选择麻烦的人生；\n选择CTeX套装，选择崩溃的人生。\n 意外重新接触LaTeX之后，发现CTeX确实是个麻烦事。最开始接触LaTeX，就不断被LaTeX各种问题绊倒，可以说相当厌恶了╮(๑•́ ₃•̀๑)╭还好有友好的Markdown语法~\n删掉自己电脑中的CTeX套装，实践记录下如何开始TexLive+TexStudio的完美生活(*•̀ㅂ•́)و\n安装TeXLive 2018 TeXLive的官网是https://tug.org/texlive/，按指引也可以完成下载；但我觉得用中国科技大学的镜像站会比较方便高效~所以从中科大这边下载： https://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/texlive2018.iso\n整个文件3.2GB还是相当大~完成下载后，以管理员身份运行install-tl-advanced.bat，然后点击continue（如图1所示），随后点击安装TeXLive即可。  图1. 安装TeXLive页面   安装TexStudio 安装完TexLive后，可以说完成百分之80的工作了，TexStudio的安装相比前面的快很多（因为只有74.1MB(..•˘_˘•..)）。\nTexStudio的官网网址是： http://texstudio.sourceforge.net/\n点击网址打开后，对于Windows平台的，点击Download now下载即可。\n两个安装后，就完成啦！ฅ(๑˙o˙๑)ฅ\n ","date":1548288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548288000,"objectID":"4c42bd88aeb9a69a425aa296392bc46d","permalink":"/post/%E5%85%A5%E9%97%A8texlive-texstudio/","publishdate":"2019-01-24T00:00:00Z","relpermalink":"/post/%E5%85%A5%E9%97%A8texlive-texstudio/","section":"post","summary":" Liam Huang曾说过：\n 选择TeX Live，选择简单的人生；\n选择MiKTeX，选择麻烦的人生；\n选择CTeX套装，选择崩溃的人生。\n 意外重新接触LaTeX之后，发现CTeX确实是个麻烦事。最开始接触LaTeX，就不断被LaTeX各种问题绊倒，可以说相当厌恶了╮(๑•́ ₃•̀๑)╭还好有友好的Markdown语法~\n删掉自己电脑中的CTeX套装，实践记录下如何开始TexLive+TexStudio的完美生活(*•̀ㅂ•́)و\n安装TeXLive 2018 TeXLive的官网是https://tug.org/texlive/，按指引也可以完成下载；但我觉得用中国科技大学的镜像站会比较方便高效~所以从中科大这边下载： https://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/texlive2018.iso\n整个文件3.2GB还是相当大~完成下载后，以管理员身份运行install-tl-advanced.bat，然后点击continue（如图1所示），随后点击安装TeXLive即可。  图1. 安装TeXLive页面   安装TexStudio 安装完TexLive后，可以说完成百分之80的工作了，TexStudio的安装相比前面的快很多（因为只有74.1MB(..•˘_˘•..)）。\nTexStudio的官网网址是： http://texstudio.sourceforge.net/\n点击网址打开后，对于Windows平台的，点击Download now下载即可。\n两个安装后，就完成啦！ฅ(๑˙o˙๑)ฅ\n ","tags":["LaTeX"],"title":"入门TeXLive+TeXStudio","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":"\r简介\rConvolutional Neural Networks的中文名叫卷积神经网络，当然英文简称直接为CNN，它的创始人是著名的计算机科学家Yann LeCun，CNN和RNN（Recurrent Neural Networks）可以说是深度学习领域最常提及的两种网络模型。本篇博客参照知乎上问题“CNN(卷积神经网络)是什么？有入门简介或文章吗？”的回答来进行介绍~\n\rConvolutional Neural Networks开始正文！\rCNN的“卷积”介绍\r我们假设神经网络的输入是一张彩色的图像，那通常我们输入的是\\(n\\times m\\times 3\\)的RGB图像，下面图中是\\(4\\times 4\\times 3\\)RGB图像的示例；其中的数字代表着图片的原始像素值。\n\r图1. \\(4\\times 4\\times 3\\)RGB图像\r\r卷积核是CNN的一个重要部分，卷积则是CNN的一个重要步骤。\n\r首先，假设我们选取的卷积核为： \\[\r\\begin{vmatrix}\r1 \u0026amp; 0 \u0026amp; 1\\\\\r0 \u0026amp; 1 \u0026amp; 0\\\\\r1 \u0026amp; 0 \u0026amp; 1\r\\end{vmatrix}\r\\]\r\r我们会从原始图像的左上角开始，选取和卷积核大小相同的区域。\n\r通过水平和垂直移动不断获得新的区域，我们假设移动的步长为1，重复上面的步骤，我们可以一个新的矩阵 \\[\r\\begin{vmatrix}\r4 \u0026amp; 3 \u0026amp; 4\\\\\r2 \u0026amp; 4 \u0026amp; 3\\\\\r2 \u0026amp; 3 \u0026amp; 4\r\\end{vmatrix}\r\\]\r\r\r图2. 卷积过程示例\r\r由此，一个\\(5\\times 5\\)的图像矩阵经过卷积得到了一个\\(3\\times 3\\)的矩阵，生成的这个矩阵我们称为Convolved Feature或Feature Map。\n\r有时候为了不让新生成的图片缩小，可以给原始的图像进行0元素的填充（padding）。\r\r\r图3. 填充（padding）示意图\r\r如图所示，原来的\\(4\\times 4\\)矩阵如果通过\\(3\\times 3\\)的卷积核处理会得到\\(2\\times 2\\)的Convolved Feature，但是在周围加一圈0元素，从\\(4\\times 4\\)矩阵扩充到\\(5\\times 5\\)的矩阵的话，经过\\(3\\times 3\\)的卷积核处理会得到\\(4\\times 4\\)的Convolved Feature。\n\rCNN的“池化”介绍\r池化（pooling）实际上是对上个操作（卷积）得到的Convolved Feature进行降维，池化有很多方法（比如取最大值，求平均，求和等等），但常用的方法有“最大池化”（池化区域内所有值的平均值作为池化结果）和“平均池化”（池化区域内所有值的最大值作为池化结果）这两种。\n池化的具体操作是让一个池化窗口在图片上移动，每次取窗口内的平均值或者最大值；窗口的水平和垂直移动，它移动步长取窗口本身的大小；下图是最大池化的示意图。\n\r图4. 最大池化示意图\r\r为什么要池化层？\n假设输入了一张\\(1000\\times 1000\\)的图像，我们采用100个卷积核进行提取不同的特征，其中卷积核大小为\\(3\\times 3\\)，卷积核在原图像上移动的步长为1；若不考虑填充（padding），那么我们会得到一个\\(998\\times 998=996004\\)的Convolved feature，那100个卷积核便会得到100个996004大小的Convolved feature；所以，一张图片最终会得到一个\\(996004\\times 100\\)的卷积特征向量。这样上千万个特征进行图片的分类，很容易造成过拟合（overfitting）。\n由于图像具有空间相关性，即一个像素点和它周围的像素点在很大概率上是相似的。通过相邻的像素点进行合并（即池化），可以缩小最后得到的特征数量。\n\r反向传播和参数更新\rCNN的训练过程和全连接网络的训练过程比较类似，都是先将参数随机初始化，再进行前向计算；得到最后的输出结果之后，再计算最后一层每个神经元的残差；通过反向传播方法，可以得到所有节点的残差和损失函数对所有参数的偏导数；最后对参数进行更新。两者的架构区别主要在于卷积层和池化层。\n卷积层的反向传播\r我们先定义，\n卷积之前的矩阵： \\[\r\\begin{vmatrix}\rx_{00} \u0026amp; x_{01} \u0026amp; x_{02}\\\\\rx_{10} \u0026amp; x_{11} \u0026amp; x_{12}\\\\\rx_{20} \u0026amp; x_{21} \u0026amp; x_{22}\r\\end{vmatrix}\r\\] 卷积核的矩阵： \\[\r\\begin{vmatrix}\rk_{00} \u0026amp; k_{01}\\\\\rk_{10} \u0026amp; k_{11}\r\\end{vmatrix}\r\\] 卷积之后的矩阵： \\[\r\\begin{vmatrix}\ry_{00} \u0026amp; y_{01}\\\\\ry_{10} \u0026amp; y_{11}\r\\end{vmatrix}\r\\] 卷积之后的残差矩阵： \\[\r\\begin{vmatrix}\r\\delta^{l+1}_{00} \u0026amp; \\delta^{l+1}_{01}\\\\\r\\delta^{l+1}_{10} \u0026amp; \\delta^{l+1}_{11}\r\\end{vmatrix}\r\\] 卷积之前的残差矩阵： \\[\r\\begin{vmatrix}\r\\delta^l_{00} \u0026amp; \\delta^l_{01} \u0026amp; \\delta^l_{02}\\\\\r\\delta^l_{10} \u0026amp; \\delta^l_{11} \u0026amp; \\delta^l_{12}\\\\\r\\delta^l_{20} \u0026amp; \\delta^l_{21} \u0026amp; \\delta^l_{22}\r\\end{vmatrix}\r\\]\n我们在前向计算中，卷积操作的计算过程如下： \\[\ry_{00} = x_{00}\\times k_{00} + x_{01}\\times k_{01} + x_{10}\\times k_{10} + x_{11}\\times k_{11}\\\\\ry_{01} = x_{01}\\times k_{00} + x_{02}\\times k_{01} + x_{11}\\times k_{10} + x_{12}\\times k_{11}\\\\\ry_{10} = x_{10}\\times k_{00} + x_{11}\\times k_{01} + x_{20}\\times k_{10} + x_{21}\\times k_{11}\\\\\ry_{11} = x_{11}\\times k_{00} + x_{12}\\times k_{01} + x_{21}\\times k_{10} + x_{22}\\times k_{11}\\\\\r\\]\n又卷积之后的残差可以由反向传播计算得到，我们可以得到： \\[\r\\begin{align}\r\\delta^l_{00} \u0026amp;= \\frac{\\partial L}{\\partial x_{00}} = \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial x_{00}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times k_{00}\\\\\r\\delta^l_{01} \u0026amp;= \\frac{\\partial L}{\\partial x_{01}} = \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial x_{01}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial x_{01}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times k_{01} + \\delta^{l+1}_{01}\\times k_{00}\\\\\r\\delta^l_{02} \u0026amp;= \\frac{\\partial L}{\\partial x_{02}} = \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial x_{02}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{01}\\times k_{01}\\\\\r\\delta^l_{10} \u0026amp;= \\frac{\\partial L}{\\partial x_{10}} = \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial x_{10}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial x_{10}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times k_{10} + \\delta^{l+1}_{10}\\times k_{00}\\\\\r\\delta^l_{11} \u0026amp;= \\frac{\\partial L}{\\partial x_{11}} = \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial x_{11}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial x_{11}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial x_{11}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial x_{11}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times k_{11} + \\delta^{l+1}_{01}\\times k_{10} + \\delta^{l+1}_{10}\\times k_{01} + \\delta^{l+1}_{11}\\times k_{00}\\\\\r\\delta^l_{12} \u0026amp;= \\frac{\\partial L}{\\partial x_{12}} = \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial x_{12}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial x_{12}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{01}\\times k_{11} + \\delta^{l+1}_{11}\\times k_{01}\\\\\r\\delta^l_{20} \u0026amp;= \\frac{\\partial L}{\\partial x_{20}} = \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial x_{20}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{10}\\times k_{10}\\\\\r\\delta^l_{21} \u0026amp;= \\frac{\\partial L}{\\partial x_{21}} = \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial x_{21}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial x_{21}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{10}\\times k_{11} + \\delta^{l+1}_{11}\\times k_{10}\\\\\r\\delta^l_{22} \u0026amp;= \\frac{\\partial L}{\\partial x_{22}} = \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial x_{22}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{11}\\times k_{11}\r\\end{align}\r\\] 通过上述等式，我们可以将残差通过卷积层反向得到上一层的残差，接下来通过残差推导损失函数对卷积核中参数的偏导数。 \\[\r\\begin{align}\r\\frac{\\partial L}{\\partial k_{00}} \u0026amp;= \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial k_{00}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial k_{00}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial k_{00}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial k_{00}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times x_{00} + \\delta^{l+1}_{01}\\times x_{01} + \\delta^{l+1}_{10}\\times x_{10} + \\delta^{l+1}_{11}\\times x_{11}\\\\\r\\frac{\\partial L}{\\partial k_{01}} \u0026amp;= \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial k_{01}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial k_{01}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial k_{01}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial k_{01}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times x_{01} + \\delta^{l+1}_{02}\\times x_{01} + \\delta^{l+1}_{10}\\times x_{11} + \\delta^{l+1}_{11}\\times x_{12}\\\\\r\\frac{\\partial L}{\\partial k_{10}} \u0026amp;= \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial k_{10}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial k_{10}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial k_{10}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial k_{10}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times x_{010} + \\delta^{l+1}_{01}\\times x_{11} + \\delta^{l+1}_{10}\\times x_{20} + \\delta^{l+1}_{11}\\times x_{21}\\\\\r\\frac{\\partial L}{\\partial k_{11}} \u0026amp;= \\frac{\\partial L}{\\partial y_{00}}\\times \\frac{\\partial y_{00}}{\\partial k_{11}} + \\frac{\\partial L}{\\partial y_{01}}\\times \\frac{\\partial y_{01}}{\\partial k_{11}} + \\frac{\\partial L}{\\partial y_{10}}\\times \\frac{\\partial y_{10}}{\\partial k_{11}} + \\frac{\\partial L}{\\partial y_{11}}\\times \\frac{\\partial y_{11}}{\\partial k_{11}}\\\\\r\u0026amp;=\\ \\delta^{l+1}_{00}\\times x_{11} + \\delta^{l+1}_{01}\\times x_{12} + \\delta^{l+1}_{10}\\times x_{21} + \\delta^{l+1}_{11}\\times x_{22}\\\\\r\\end{align}\r\\]\n举个实例体会下！\n输入的数据是\\(3\\times 3\\)的矩阵： \\[\r\\begin{vmatrix}\r1 \u0026amp; 2 \u0026amp; 1\\\\\r3 \u0026amp; 2 \u0026amp; 1\\\\\r2 \u0026amp; 1 \u0026amp; 1\r\\end{vmatrix}\r\\]\n假设有两个卷积核分别为： \\[\r\\begin{vmatrix}\r0.1 \u0026amp; 0.2\\\\\r0.2 \u0026amp; 0.4\r\\end{vmatrix}\r和\r\\begin{vmatrix}\r-0.3 \u0026amp; 0.1\\\\\r0.1 \u0026amp; 0.2\r\\end{vmatrix}\r\\]\n假设经过两个卷积核卷积之后的残差值分别为： \\[\r\\begin{vmatrix}\r1 \u0026amp; 3\\\\\r2 \u0026amp; 2\r\\end{vmatrix}\r和\r\\begin{vmatrix}\r2 \u0026amp; 1\\\\\r1 \u0026amp; 1\r\\end{vmatrix}\r\\]\n那么，第一个卷积核卷积之前各个节点的残差为： \\[\r\\begin{align}\r\\delta^l_{00} \u0026amp;= \\delta^{l+1}_{00}\\times k_{00}\\\\\r\u0026amp;=\\ 1\\times 0.1 = 0.1\\\\\r\\delta^l_{01} \u0026amp;= \\delta^{l+1}_{00}\\times k_{01} + \\delta^{l+1}_{01}\\times k_{00}\\\\\r\u0026amp;=\\ 1\\times 0.2 + 3\\times 0.1 = 0.5\\\\\r\\delta^l_{02} \u0026amp;= \\delta^{l+1}_{01}\\times k_{01}\\\\\r\u0026amp;=\\ 3\\times 0.2 = 0.6\\\\\r\\delta^l_{10} \u0026amp;= \\delta^{l+1}_{00}\\times k_{10} + \\delta^{l+1}_{10}\\times k_{00}\\\\\r\u0026amp;=\\ 1\\times 0.2 + 2\\times 0.1 = 0.4\\\\\r\\delta^l_{11} \u0026amp;= \\delta^{l+1}_{00}\\times k_{11} + \\delta^{l+1}_{01}\\times k_{10} + \\delta^{l+1}_{10}\\times k_{01} + \\delta^{l+1}_{11}\\times k_{00}\\\\\r\u0026amp;=\\ 1\\times 0.4 + 3\\times 0.2 + 2\\times 0.2 + 2\\times 0.1 = 1.6\\\\\r\\delta^l_{12} \u0026amp;= \\delta^{l+1}_{01}\\times k_{11} + \\delta^{l+1}_{11}\\times k_{01}\\\\\r\u0026amp;=\\ 3\\times 0.4 + 2\\times 0.2 = 1.6\\\\\r\\delta^l_{20} \u0026amp;= \\delta^{l+1}_{10}\\times k_{10}\\\\\r\u0026amp;=\\ 2\\times 0.2 = 0.4\\\\\r\\delta^l_{21} \u0026amp;= \\delta^{l+1}_{10}\\times k_{11} + \\delta^{l+1}_{11}\\times k_{10}\\\\\r\u0026amp;=\\ 2\\times 0.4 + 2\\times 0.2 = 1.2\\\\\r\\delta^l_{22} \u0026amp;= \\delta^{l+1}_{11}\\times k_{11}\\\\\r\u0026amp;=\\ 2\\times 0.4 = 0.8\r\\end{align}\r\\]\n即第一个卷积核反向传播计算过程中卷积之前的残差为： \\[\r\\begin{vmatrix}\r0.1 \u0026amp; 0.5 \u0026amp; 0.6\\\\\r0.4 \u0026amp; 1.6 \u0026amp; 1.6\\\\\r0.4 \u0026amp; 1.2 \u0026amp; 0.8\r\\end{vmatrix}\r\\]\n同理可以得到第二个卷积核反向传播计算过程中卷积之前的残差为： \\[\r\\begin{vmatrix}\r-0.6 \u0026amp; -0.1 \u0026amp; 0.1\\\\\r-0.1 \u0026amp; 0.3 \u0026amp; 0.3\\\\\r0.1 \u0026amp; 0.3 \u0026amp; 0.2\r\\end{vmatrix}\r\\]\n对于第一个卷积核，通过上面推导的公式可以计算： \\[\r\\begin{align}\r\\frac{\\partial L}{\\partial k_{00}} \u0026amp;= \\delta^{l+1}_{00}\\times x_{00} + \\delta^{l+1}_{01}\\times x_{01} + \\delta^{l+1}_{10}\\times x_{10} + \\delta^{l+1}_{11}\\times x_{11}\\\\\r\u0026amp;=\\ 1\\times 1 + 3\\times 2 + 2\\times 3 + 2\\times 2 = 17\\\\\r\\frac{\\partial L}{\\partial k_{01}} \u0026amp;= \\delta^{l+1}_{00}\\times x_{01} + \\delta^{l+1}_{02}\\times x_{01} + \\delta^{l+1}_{10}\\times x_{11} + \\delta^{l+1}_{11}\\times x_{12}\\\\\r\u0026amp;=\\ 1\\times 2 + 3\\times 1 + 2\\times 2 + 2\\times 1 = 11\\\\\r\\frac{\\partial L}{\\partial k_{10}} \u0026amp;= \\delta^{l+1}_{00}\\times x_{010} + \\delta^{l+1}_{01}\\times x_{11} + \\delta^{l+1}_{10}\\times x_{20} + \\delta^{l+1}_{11}\\times x_{21}\\\\\r\u0026amp;=\\ 1\\times 3 + 3\\times 2 + 2\\times 2 + 2\\times 1 = 15\\\\\r\\frac{\\partial L}{\\partial k_{11}} \u0026amp;= \\delta^{l+1}_{00}\\times x_{11} + \\delta^{l+1}_{01}\\times x_{12} + \\delta^{l+1}_{10}\\times x_{21} + \\delta^{l+1}_{11}\\times x_{22}\\\\\r\u0026amp;=\\ 1\\times 2 + 3\\times 1 + 2\\times 1 + 2\\times 1 = 9\r\\end{align}\r\\]\n则第一个卷积核的更新计算为： \\[\r\\begin{vmatrix}\rk\u0026#39;_{00} \u0026amp; k\u0026#39;_{01}\\\\\rk\u0026#39;_{10} \u0026amp; k\u0026#39;_{11}\r\\end{vmatrix}\r=\r\\begin{vmatrix}\r0.1 \u0026amp; 0.2\\\\\r0.2 \u0026amp; 0.4\r\\end{vmatrix}\r-\\alpha\\times \\begin{vmatrix}\r17 \u0026amp; 11\\\\\r15 \u0026amp; 9\r\\end{vmatrix}\r\\] 其中\\(\\alpha\\)为学习率，\\(k\u0026#39;_{ij}\\)为更新之后的第一个卷积核的参数。同理，可更新第二个卷积核的参数\n\r池化层的反向传播\r平均池化\n假设输入的是一个\\(4\\times 4\\)的矩阵，池化区域是\\(2\\times 2\\)的矩阵，经过池化后得到的是\\(2\\times 2\\)的矩阵。我们假设在反向传播计算过程中，最后一层4个节点的残差值为： \\[\r\\begin{vmatrix}\r1 \u0026amp; 3\\\\\r2 \u0026amp; 4\r\\end{vmatrix}\r\\] 那么由于一个节点对应池化之前的4个节点，同时需要满足反向传播过程中各层的残差总和不变，所以池化之前的神经元的残差值是池化之后的残差值得平均；在这个例子中，池化之前\\(4\\times 4\\)的神经元的残差值为： \\[\r\\begin{vmatrix}\r0.25 \u0026amp; 0.25 \u0026amp; 0.75 \u0026amp; 0.75\\\\\r0.25 \u0026amp; 0.25 \u0026amp; 0.75 \u0026amp; 0.75\\\\\r0.5 \u0026amp; 0.5 \u0026amp; 1 \u0026amp; 1\\\\\r0.5 \u0026amp; 0.5 \u0026amp; 1 \u0026amp; 1\r\\end{vmatrix}\r\\]\n最大池化\n在这里也用和平均池化一样的例子，我们假设在反向传播计算过程中，最后一层4个节点的残差值为： \\[\r\\begin{vmatrix}\r1 \u0026amp; 3\\\\\r2 \u0026amp; 4\r\\end{vmatrix}\r\\]\n最大池化在前向计算的过程中，需要记录被池化的\\(2\\times 2\\)区域中哪个位置被选取（即最大值），我们假设被选中的最大值所在的位置就是下面星星所在位置： \\[\r\\begin{vmatrix}\r* \u0026amp; - \u0026amp; - \u0026amp; -\\\\\r- \u0026amp; - \u0026amp; * \u0026amp; -\\\\\r- \u0026amp; - \u0026amp; - \u0026amp; *\\\\\r- \u0026amp; * \u0026amp; - \u0026amp; -\r\\end{vmatrix}\r\\] 在反向传播中，将残差直接给上述星星位置，其他位置则赋为0，即 \\[\r\\begin{vmatrix}\r1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\\\\r0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 0\\\\\r0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 4\\\\\r0 \u0026amp; 3 \u0026amp; 0 \u0026amp; 0\r\\end{vmatrix}\r\\]\n\r\r代码与实现\r在知乎“CNN(卷积神经网络)是什么？有入门简介或文章吗？”这个问题上，“阿里云云栖社区”在它的答案中给出了CNN实现的代码ヾ(´▽‘)ﾉ\n# Import the deep learning library\rimport tensorflow as tf\rimport time\r# Import the MNIST dataset\rfrom tensorflow.examples.tutorials.mnist import input_data\rmnist = input_data.read_data_sets(\u0026quot;./mnist\u0026quot;, one_hot=True)\r# Network inputs and outputs\r# The network\u0026#39;s input is a 28×28 dimensional input\rn = 28\rm = 28\rnum_input = n * m # MNIST data input num_classes = 10 # MNIST total classes (0-9 digits)\r# tf Graph input\rX = tf.placeholder(tf.float32, [None, num_input])\rY = tf.placeholder(tf.float32, [None, num_classes])\r# Storing the parameters of our LeNET-5 inspired Convolutional Neural Network\rweights = {\r\u0026quot;W_ij\u0026quot;: tf.Variable(tf.random_normal([5, 5, 1, 32])),\r\u0026quot;W_jk\u0026quot;: tf.Variable(tf.random_normal([5, 5, 32, 64])),\r\u0026quot;W_kl\u0026quot;: tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\r\u0026quot;W_lm\u0026quot;: tf.Variable(tf.random_normal([1024, num_classes]))\r}\rbiases = {\r\u0026quot;b_ij\u0026quot;: tf.Variable(tf.random_normal([32])),\r\u0026quot;b_jk\u0026quot;: tf.Variable(tf.random_normal([64])),\r\u0026quot;b_kl\u0026quot;: tf.Variable(tf.random_normal([1024])),\r\u0026quot;b_lm\u0026quot;: tf.Variable(tf.random_normal([num_classes]))\r}\r# The hyper-parameters of our Convolutional Neural Network\rlearning_rate = 1e-3\rnum_steps = 500\rbatch_size = 128\rdisplay_step = 10\rdef ConvolutionLayer(x, W, b, strides=1):\r# Convolution Layer\r# \u0026#39;SAME\u0026#39; in padding parameter represents that the size of pics will not change\rx = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\u0026#39;SAME\u0026#39;)\rx = tf.nn.bias_add(x, b)\rreturn x\rdef ReLU(x):\r# ReLU activation function\rreturn tf.nn.relu(x)\rdef PoolingLayer(x, k=2, strides=2):\r# Max Pooling layer\rreturn tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1],\rpadding=\u0026#39;SAME\u0026#39;)\rdef Softmax(x):\r# Softmax activation function for the CNN\u0026#39;s final output\rreturn tf.nn.softmax(x)\r# Create model\rdef ConvolutionalNeuralNetwork(x, weights, biases):\r# MNIST data input is a 1-D row vector of 784 features (28×28 pixels)\r# Reshape to match picture format [Height x Width x Channel]\r# Tensor input become 4-D: [Batch Size, Height, Width, Channel]\rx = tf.reshape(x, shape=[-1, 28, 28, 1])\r# Convolution Layer\rConv1 = ConvolutionLayer(x, weights[\u0026quot;W_ij\u0026quot;], biases[\u0026quot;b_ij\u0026quot;])\r# Non-Linearity\rReLU1 = ReLU(Conv1)\r# Max Pooling (down-sampling)\rPool1 = PoolingLayer(ReLU1, k=2)\r# Convolution Layer\rConv2 = ConvolutionLayer(Pool1, weights[\u0026quot;W_jk\u0026quot;], biases[\u0026quot;b_jk\u0026quot;])\r# Non-Linearity\rReLU2 = ReLU(Conv2)\r# Max Pooling (down-sampling)\rPool2 = PoolingLayer(ReLU2, k=2)\r# Fully connected layer\r# Reshape conv2 output to fit fully connected layer input\rFC = tf.reshape(Pool2, [-1, weights[\u0026quot;W_kl\u0026quot;].get_shape().as_list()[0]])\rFC = tf.add(tf.matmul(FC, weights[\u0026quot;W_kl\u0026quot;]), biases[\u0026quot;b_kl\u0026quot;])\rFC = ReLU(FC)\r# Output, class prediction\routput = tf.add(tf.matmul(FC, weights[\u0026quot;W_lm\u0026quot;]), biases[\u0026quot;b_lm\u0026quot;])\rreturn output\r# Construct model\rlogits = ConvolutionalNeuralNetwork(X, weights, biases)\rprediction = Softmax(logits)\r# Softamx cross entropy loss function\rloss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\rlogits=logits, labels=Y))\r# Optimization using the Adam Gradient Descent optimizer\roptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\rtraining_process = optimizer.minimize(loss_function)\r# Evaluate model\rcorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\raccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r# recording how the loss functio varies over time during training\rcost = tf.summary.scalar(\u0026quot;cost\u0026quot;, loss_function)\rtraining_accuracy = tf.summary.scalar(\u0026quot;accuracy\u0026quot;, accuracy)\rtrain_summary_op = tf.summary.merge([cost,training_accuracy])\rtrain_writer = tf.summary.FileWriter(\u0026quot;./logs\u0026quot;, graph=tf.get_default_graph())\r# Initialize the variables (i.e. assign their default value)\rinit = tf.global_variables_initializer()\r# Start training\rwith tf.Session() as sess:\r# Run the initializer\rsess.run(init)\rstart_time = time.time()\rfor step in range(1, num_steps+1):\rbatch_x, batch_y = mnist.train.next_batch(batch_size)\r# Run optimization op (backprop)\rsess.run(training_process, feed_dict={X: batch_x, Y: batch_y})\rif step % display_step == 0 or step == 1:\r# Calculate batch loss and accuracy\rloss, acc, summary = sess.run([loss_function, accuracy, train_summary_op], feed_dict={X: batch_x,\rY: batch_y})\rtrain_writer.add_summary(summary, step)\rprint(\u0026quot;Step \u0026quot; + str(step) + \u0026quot;, Minibatch Loss= \u0026quot; + \\\r\u0026quot;{:.4f}\u0026quot;.format(loss) + \u0026quot;, Training Accuracy= \u0026quot; + \\\r\u0026quot;{:.3f}\u0026quot;.format(acc))\rend_time = time.time() print(\u0026quot;Time duration: \u0026quot; + str(int(end_time-start_time)) + \u0026quot; seconds\u0026quot;)\rprint(\u0026quot;Optimization Finished!\u0026quot;)\r# Calculate accuracy for 256 MNIST test images\rprint(\u0026quot;Testing Accuracy:\u0026quot;, \\\rsess.run(accuracy, feed_dict={X: mnist.test.images[:256],\rY: mnist.test.labels[:256]}))\r计算结果中可以得到Testing accuracy为94.53125%\n计算输出如下：\nStep 1, Minibatch Loss= 48469.1758, Training Accuracy= 0.125\nStep 10, Minibatch Loss= 20853.4180, Training Accuracy= 0.273\nStep 20, Minibatch Loss= 7270.9775, Training Accuracy= 0.539\nStep 30, Minibatch Loss= 6032.3340, Training Accuracy= 0.625\nStep 40, Minibatch Loss= 3758.7192, Training Accuracy= 0.727\nStep 50, Minibatch Loss= 2683.9473, Training Accuracy= 0.805\nStep 60, Minibatch Loss= 2468.1599, Training Accuracy= 0.836\nStep 70, Minibatch Loss= 1618.9688, Training Accuracy= 0.852\nStep 80, Minibatch Loss= 1811.2744, Training Accuracy= 0.836\nStep 90, Minibatch Loss= 2332.1758, Training Accuracy= 0.836\nStep 100, Minibatch Loss= 2061.6094, Training Accuracy= 0.875\nStep 110, Minibatch Loss= 1141.6943, Training Accuracy= 0.914\nStep 120, Minibatch Loss= 1826.9503, Training Accuracy= 0.867\nStep 130, Minibatch Loss= 2125.6672, Training Accuracy= 0.875\nStep 140, Minibatch Loss= 1881.3708, Training Accuracy= 0.867\nStep 150, Minibatch Loss= 1131.6064, Training Accuracy= 0.867\nStep 160, Minibatch Loss= 691.9032, Training Accuracy= 0.938\nStep 170, Minibatch Loss= 1885.9514, Training Accuracy= 0.844\nStep 180, Minibatch Loss= 1068.9915, Training Accuracy= 0.914\nStep 190, Minibatch Loss= 1600.2179, Training Accuracy= 0.906\nStep 200, Minibatch Loss= 618.6491, Training Accuracy= 0.930\nStep 210, Minibatch Loss= 1556.0098, Training Accuracy= 0.836\nStep 220, Minibatch Loss= 894.7733, Training Accuracy= 0.922\nStep 230, Minibatch Loss= 1324.5962, Training Accuracy= 0.930\nStep 240, Minibatch Loss= 906.6990, Training Accuracy= 0.914\nStep 250, Minibatch Loss= 997.3357, Training Accuracy= 0.906\nStep 260, Minibatch Loss= 411.8199, Training Accuracy= 0.953\nStep 270, Minibatch Loss= 1174.1459, Training Accuracy= 0.938\nStep 280, Minibatch Loss= 1530.4811, Training Accuracy= 0.930\nStep 290, Minibatch Loss= 1549.0024, Training Accuracy= 0.883\nStep 300, Minibatch Loss= 871.0544, Training Accuracy= 0.945\nStep 310, Minibatch Loss= 596.3419, Training Accuracy= 0.953\nStep 320, Minibatch Loss= 760.7213, Training Accuracy= 0.922\nStep 330, Minibatch Loss= 1059.3221, Training Accuracy= 0.891\nStep 340, Minibatch Loss= 918.7598, Training Accuracy= 0.922\nStep 350, Minibatch Loss= 1347.2892, Training Accuracy= 0.914\nStep 360, Minibatch Loss= 854.8413, Training Accuracy= 0.922\nStep 370, Minibatch Loss= 938.9316, Training Accuracy= 0.930\nStep 380, Minibatch Loss= 963.6599, Training Accuracy= 0.914\nStep 390, Minibatch Loss= 443.7957, Training Accuracy= 0.922\nStep 400, Minibatch Loss= 899.7906, Training Accuracy= 0.922\nStep 410, Minibatch Loss= 754.6378, Training Accuracy= 0.906\nStep 420, Minibatch Loss= 25.4618, Training Accuracy= 0.992\nStep 430, Minibatch Loss= 1071.7233, Training Accuracy= 0.914\nStep 440, Minibatch Loss= 67.5639, Training Accuracy= 0.961\nStep 450, Minibatch Loss= 805.5145, Training Accuracy= 0.906\nStep 460, Minibatch Loss= 555.4743, Training Accuracy= 0.930\nStep 470, Minibatch Loss= 505.9941, Training Accuracy= 0.930\nStep 480, Minibatch Loss= 358.9708, Training Accuracy= 0.961\nStep 490, Minibatch Loss= 633.9738, Training Accuracy= 0.930\nStep 500, Minibatch Loss= 259.1246, Training Accuracy= 0.969\nTime duration: 148 seconds\nOptimization Finished!\nTesting Accuracy: 0.9453125\n利用TensorBoard查看过程\r上述代码\ntrain_writer = tf.summary.FileWriter(\u0026quot;./logs\u0026quot;,graph=tf.get_default_graph())\n中会在文件夹目录下新建文件夹logs，并在里面生成名为events.out.tfevents.{time}.{machine-name}的文件。通过打开Anaconda prompt并启动python3.5，打开TensorBoard，如图所示：\r\r图5. 通过Anaconda prompt打开TensorBoard\r\r打开浏览器，地址栏输入 http://localhost:6006 即可打开TensorBoard。\n在TensorBoard中可以查看cost和accuracy的变化\r\r图6. TensorBoard中cost和accuracy的变化图\r\r同时可以查看Graphs\r\r图7. TensorFlow定义的计算图\r\r\r\r\rReference\r知乎. CNN(卷积神经网络)是什么？有入门简介或文章吗？\r罗冬日. Tensorflow入门与实战\r\r\r","date":1548028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548028800,"objectID":"33789fc0fc400ffd48ce91452ebf7f51","permalink":"/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/","publishdate":"2019-01-21T00:00:00Z","relpermalink":"/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/","section":"post","summary":"简介\rConvolutional Neural Networks的中文名叫卷积神经网络，当然英文简称直接为CNN，它的创始人是著名的计算机科学家Yann LeCun，CNN和RNN（Recurrent Neural Networks）可以说是深度学习领域最常提及的两种网络模型。本篇博客参照知乎上问题“CNN(卷积神经网络)是什么？有入门简介或文章吗？”的回答来进行介绍~\n\rConvolutional Neural Networks开始正文！\rCNN的“卷积”介绍\r我们假设神经网络的输入是一张彩色的图像，那通常我们输入的是\\(n\\times m\\times 3\\)的RGB图像，下面图中是\\(4\\times 4\\times 3\\)RGB图像的示例；其中的数字代表着图片的原始像素值。\n\r图1. \\(4\\times 4\\times 3\\)RGB图像\r\r卷积核是CNN的一个重要部分，卷积则是CNN的一个重要步骤。\n\r首先，假设我们选取的卷积核为： \\[\r\\begin{vmatrix}\r1 \u0026amp; 0 \u0026amp; 1\\\\\r0 \u0026amp; 1 \u0026amp; 0\\\\\r1 \u0026amp; 0 \u0026amp; 1\r\\end{vmatrix}\r\\]\r\r我们会从原始图像的左上角开始，选取和卷积核大小相同的区域。\n\r通过水平和垂直移动不断获得新的区域，我们假设移动的步长为1，重复上面的步骤，我们可以一个新的矩阵 \\[\r\\begin{vmatrix}\r4 \u0026amp; 3 \u0026amp; 4\\\\\r2 \u0026amp; 4 \u0026amp; 3\\\\\r2 \u0026amp; 3 \u0026amp; 4\r\\end{vmatrix}\r\\]\r\r\r图2.","tags":["Deep Learning","TensorFlow"],"title":"卷积神经网络 Convolutional Neural Networks","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":"\r我们认为每张图片对应的是一个高维向量，我们希望能找出这一类图片所在的图像空间的分布\\(P\\)，GAN的目的其实就是在寻找这个分布\\(P\\)。\n传统的方法我们会想到用最大似然估计：\n\r首先给定一些样本数据，可以得到它的分布\\(P_{data}(x)\\)；接着我们假定有一个由参数\\(\\theta\\)决定的分布\\(P_G(x;\\theta)\\)；我们希望能够找到\\(\\theta\\)，满足分布\\(P_G(x;\\theta)\\)尽可能靠近分布\\(P_{data}(x)\\)；假设\\(P_G(x;\\theta)\\)是高斯分布（正态分布），那\\(\\theta\\)就是均值和方差。\n\r从分布\\(P_{data}(x)\\)中进行抽样获得一组样本数据\\(\\{x_1,x_2,\\dots,x_m\\}\\)，我们可以得到似然值的表达式 \\[L = \\prod_{i=1}^{m} P_G(x^i;\\theta)\\]我们希望能够找到\\(\\theta^*\\)能够使得似然值\\(L\\)最大。\n\r\r最大似然估计与最小KL散度的等价性\r通过对\\(L\\)取对数，我们可以得到对数似然值，同时\\(\\theta^*\\)可以通过下式得到： \\[\r\\begin{align}\r\\theta^* \u0026amp;=\\ \\arg \\max_{\\theta} \\log L\\\\ \u0026amp;=\\ \\arg \\max_{\\theta} \\log \\prod_{i=1}^{m} P_G(x^i;\\theta)\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\sum_{i=1}^m \\log P_G(x^i;\\theta)\r\\end{align}\r\\]\n由于样本\\(\\{x^1,x^2,\\dots,x^m\\}\\)是随机抽取来自于分布\\(P_{data}(x)\\)，上式可以近似求\\(\\log P_G(x;\\theta)\\)的期望的最大点，可以表示为 \\[\r\\begin{align}\r\\theta^* \u0026amp;\\approx\\ \\arg \\max_{\\theta} E_{x\\sim P_{data}}[\\log P_G(x;\\theta)]\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\log P_G(x;\\theta) dx\r\\end{align}\r\\]\n从式子中知道，我们所求的\\(\\theta^*\\)只跟分布\\(P_G(x;\\theta)\\)相关，我们可以在后面加上一项\\(-\\int\\limits_x P_{data}(x) \\log P_{data}(x)dx\\)，这不影响求最大化下对应得\\(\\theta^*\\)，那么由上式就可以得到 \\[\r\\begin{align}\r\\theta^* \u0026amp;\\approx\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\log P_G(x;\\theta) dx - \\int\\limits_x P_{data}(x) \\log P_{data}(x)dx\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\Big[\\log P_G(x;\\theta) - \\log P_{data}(x)\\Big] dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} \\int\\limits_x P_{data}(x) \\Big[\\log P_{data}(x) - \\log P_G(x;\\theta)\\Big] dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} \\int\\limits_x P_{data}(x) \\log \\frac{P_{data}(x)}{P_G(x;\\theta)} dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} KL(P_{data}||P_G)\r\\end{align}\r\\]\n从上述推导可以发现最大似然估计实际上等价于最小化KL散度。\n\r用生成器Generator定义概率分布\\(P_G\\)\r如果\\(P_G\\)是很复杂的形式，那我们很难去直接计算我们的目标值。虽然我们可以假定一些简单的已知的分布来确定\\(P_G\\)，比如高斯分布；但是很多情况下，高斯分布的实验结果并不是很好；所以，我们希望用一个更generalized的函数来定义\\(P_G\\)。\n我们用生成器Generator（一个网络结构）来定义概率分布\\(P_G\\)，我们希望输入某个已知分布（比如高斯分布）随机产生的一个数\\(z\\)，通过Generator之后可以得到\\(x=G(z)\\)，那么这些\\(x\\)可以构成某个复杂的分布，也可以说这个复杂的分布是我们希望得到的分布\\(P_G\\)，我们希望这个分布\\(P_G\\)能够和分布\\(P_{data}\\)越接近越好；从散度（Divergence）的角度来说，我们希望分布\\(P_G\\)和分布\\(P_{data}\\)的散度能够越小越好，即 \\[\rG^* = \\arg \\min_G \\text{Div}(P_G,P_{data})\r\\tag{1}\r\\]\n如果是最大似然估计的话，我们会希望KL散度越小越好，即 \\[G^* = \\arg \\min_G KL(P_G,P_{data})\\]\n\r图1. 生成器Generator流程示意图\r\r\r如何获得我们需要的散度Divergence？\r由于我们无法确定\\(P_{data}(x)\\)和\\(P_G(x)\\)的分布，所以我们也无法直接计算得到他们的Divergence，当然就没办法直接用梯度下降去找到最小的Divergence小对应的Generator。\n虽然我们无法知道\\(P_{data}(x)\\)和\\(P_G(x)\\)的分布，但是利用重抽样（Resample）的想法，我们可以对它们这两个分布进行抽样；对于\\(P_{data}(x)\\)而言，我们从原数据抽取样本；对于\\(P_G(x)\\)而言，我们从高斯分布抽样再通过前面确定的Generator得到样本。\n我们引入上一Part讲到的监督器Discriminator（我们说到Discriminator也是一个network），对于训练Discriminator的时候，假设我们的目标函数是 \\[\rV(G,D) = E_{x\\sim P_{data}}[\\log D(x)] + E_{x\\sim P_{G}}[\\log (1-D(x))]\r\\tag{2}\r\\]\n其中\\(G\\)代表Generator，它在这一步是固定不变的；我们希望最大化\\(V(G,D)\\)，式（2）第一项\\(E_{x\\sim P_{data}}[\\log D(x)]\\)表示从\\(P_{data}(x)\\)得到的\\(x\\)，我们希望\\(D(x)\\)能够尽可能大；而对于第二项\\(E_{x\\sim P_{G}}[\\log (1-D(x))]\\)，表示从\\(P_G(x)\\)得到的\\(x\\)，我们希望\\(D(x)\\)能够尽可能小，因为这样\\(1-D(x)\\)才能尽可能大；整体两部分加起来才能够做到尽可能大，实现\\(V(G,D)\\)的最大化。由于抽取的样本\\(x\\)在这个环节是固定的，相当于我们需要找到一个Discriminator满足最大化\\(V(G,D)\\)，即 \\[\rD^* = \\arg \\max_D V(G,D)\r\\]\n【注：使用式（2）作为目标函数相当于训练一个二分类器】\n当抽取的样本分散的很开的时候，即它们的散度很大的时候，我们很容易训练得到一个Discriminator能够容易区分来自两个不同分布的样本（很容易使我们的目标函数变大）；但如果抽取的样本分散的不开的时候，即它们的散度比较小时，我们训练得到的Discriminator是很难区分来自两个不同分布的样本的（很难使我们的目标函数变大）。\n\r图2. 生成器Discriminator流程示意图\r\r最大化目标函数\\(V(D,G)\\)与散度Divergence的联系\r在给定Generator情况下，我们想要找到一个Discriminator使得我们的目标函数\\(V(G,D)\\)最大，依据上面式（2），我们可以得到： \\[\r\\begin{align}\rV(G,D) \u0026amp;=\\ E_{x\\sim P_{data}}[\\log D(x)] + E_{x\\sim P_G}[\\log (1-D(x))]\\\\\r\u0026amp;=\\ \\int\\limits_x P_{data}(x) \\log D(x) dx + \\int\\limits_x P_G(x) \\log (1-D(x)) dx\\\\\r\u0026amp;=\\ \\int\\limits_x \\Big[P_{data}(x) \\log D(x) + P_G(x) \\log (1-D(x))\\Big] dx\r\\end{align}\r\\tag{3}\r\\]\n给定\\(x\\)的情况下，最大化式（3）等价于最大化 \\[\rP_{data}(x) \\log D(x) + P_G(x) \\log (1-D(x))\r\\tag{4}\r\\]\n那么，原优化问题等价于找一个最优Discriminator使得式（4）最大。由于\\(x\\)固定了，那么\\(P_{data}(x)\\)和\\(P_G(x)\\)是确定的；我们将\\(P_{data}(x)\\)记作\\(a\\)，\\(P_G(x)\\)记作\\(b\\)，\\(D(x)\\)记作\\(D\\)，那式（4）可以变化为： \\[\rf(D) = a\\log(D) + b\\log (1-D)\r\\tag{5}\r\\]\n对式（5）求导并赋值为0，可以得到： \\[\r\\begin{align}\r\u0026amp; \\ \\frac{df(D)}{dD} = \\frac{a}{D} - \\frac{b}{1-D} = 0\\\\\r\\Rightarrow\u0026amp; \\ \\frac{a}{D} = \\frac{b}{1-D}\\\\\r\\Rightarrow\u0026amp; \\ a\\times (1-D) = b\\times D\\\\\r\\Rightarrow\u0026amp; \\ D = \\frac{a}{a+b}\r\\end{align}\r\\]\n将符号复原，我们知道满足式（4）最大的\\(D^*\\)满足 \\[\rD^* = \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}\r\\]\n由二阶导数我们可以知道该点为极大值点： \\[\r\\begin{align}\r\\frac{d^2f(D)}{dD^2} \u0026amp;=\\ -\\frac{a}{D^2} - \\frac{b}{1-D^2}\\\\\r\u0026amp;=\\ -\\frac{a}{(\\frac{a}{a+b})^2}-\\frac{b}{1-(\\frac{a}{a+b})^2}\\\\\r\u0026amp;=\\ -\\frac{(a+b)^2}{a}-\\frac{(a+b)^2}{b}\\\\\r\u0026amp;\u0026lt;\\ 0\r\\end{align}\r\\]\n将\\(D^*\\)带入\\(V(G,D) = E_{x\\sim P_{data}}[\\log D(x)] + E_{x\\sim P_{G}}[\\log (1-D(x))]\\)，我们可以得到 \\[\r\\begin{align}\r\\max_D V(G,D) \u0026amp;=\\ V(G,D^*)\\\\\r\u0026amp;=\\ E_{x\\sim P_{data}}[\\log D(x)] + E_{x\\sim P_G}[\\log (1-D(x))]\\\\\r\u0026amp;=\\ E_{x\\sim P_{data}}[\\log \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] + E_{x\\sim P_G}[\\log (1-\\frac{P_{data}(x)}{P_{data}(x)+P_G(x)})]\\\\\r\u0026amp;=\\ E_{x\\sim P_{data}}[\\log \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] + E_{x\\sim P_G}[\\log \\frac{P_G(x)}{P_{data}(x)+P_G(x)}]\\\\\r\u0026amp;=\\ \\int\\limits_x P_{data}(x)\\log \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}dx + \\int\\limits_x P_G(x)\\log \\frac{P_G(x)}{P_{data}(x)+P_G(x)}dx\\\\\r\u0026amp;=\\ \\int\\limits_x P_{data}(x)\\log \\frac{\\frac{1}{2}P_{data}(x)}{\\frac{1}{2} [P_{data}(x)+P_G(x)]}dx + \\int\\limits_x P_G(x)\\log \\frac{\\frac{1}{2}P_G(x)}{\\frac{1}{2} [P_{data}(x)+P_G(x)]}dx\\\\\r\u0026amp;=\\ \\int\\limits_x P_{data}(x)\\log \\frac{P_{data}(x)}{\\frac{1}{2} [P_{data}(x)+P_G(x)]}dx + \\int\\limits_x P_G(x)\\log \\frac{P_G(x)}{\\frac{1}{2} [P_{data}(x)+P_G(x)]}dx - 2\\log2\\\\\r\u0026amp;=\\ KL(P_{data} || \\frac{P_{data}+P_G}{2}) + KL(P_G || \\frac{P_{data}+P_G}{2}) - 2\\log2\r\\end{align}\r\\]\nJS散度（Jensen-Shannon Divergence）是这样定义的： \\[\rJS(P_1||P_2)=\\frac{1}{2}KL(P_1||\\frac{P_1+P_2}{2})+\\frac{1}{2}KL(P_2||\\frac{P_1+P_2}{2})\r\\]\n因此，我们可以推得 \\[\r\\max_D V(G,D) = V(G,D^*) = -2\\log 2 + 2JS(P_{data}||P_G)\r\\]\n从上面可以看出，我们在固定Generator之后，对\\(V(G,D)\\)的最大化相当于计算\\(P_{data}\\)和\\(P_G\\)之间的JS散度再减去2倍\\(\\log2\\)。\n在式（1）中散度Divergence是无法直接计算的，但是从刚刚的推导中，我们知道最大化目标函数\\(V(G,D)\\)可以得到散度的值，我们进一步用最大化\\(V(G,D)\\)替代\\(P_{data}\\)和\\(P_G\\)之间的散度，可以得到一个Min-Max的优化问题。 \\[\r\\begin{align}\rG^* \u0026amp;=\\ \\arg \\min_G \\text{Div}(P_G,P_{data})\\\\\r\u0026amp;=\\ \\arg \\min_G \\max_D V(G,D)\r\\end{align}\r\\]\n\r求解Min-Max问题\r上面我们最终得到了一个Min-Max最优化问题 \\[G^* = \\arg \\min_G \\max_D V(G,D)\\]\n如果我们手中没有Generator的话，我们无法得到\\(V(G,D)\\)的最大值，在解决这个优化问题之时，我们可以按一下步骤进行：\n\r初始化一个带随机参数的Generator \\(G_0\\)；\r\r对于\\(i = 0,1,\\dots,n\\)，重复进行下列步骤：\n\r通过梯度上升（Gradient Ascent）方法找到满足最大化\\(V(G_i,D)\\)的\\(D_i\\)；（这一步等价于获得了\\(P_{data}\\)和\\(P_{G_i}\\)之间的JS散度）\n\r通过梯度下降（Gradient Descent）方法得到\\(G_{i+1}\\)：\n\r\r\\[\\theta_{G_{i+1}} = \\theta_{G_i} - \\eta\\frac{\\partial V(G,D_i)}{\\partial \\theta_G}\\]\n算法的大致框架得到了，但是对于细节\\(V(G,D)\\)的形式我们只有式（2）；对于式（2）中的期望，实际上我们是很难得到的，在实践中，我们用样本均值来代替期望值；因此最大化\\(V(G,D)\\)可以转换为最大化 \\[ \\tilde{V} = \\frac{1}{m}\\sum_{i=1}^m\\log D(x^i) + \\frac{1}{m}\\sum_{i=1}^m\\log (1-D(\\tilde{x}^i)) \\] 其中样本\\(\\{x^1,x^2,\\dots,x^m\\}\\)来自分布\\(P_{data}(x)\\)，样本\\(\\{\\tilde{x}^1,\\tilde{x}^2,\\dots,\\tilde{x}^m\\}\\)来自分布\\(P_G(x)\\)。\n\rGAN的算法\r通过上面的推导介绍，我们可以总结出GAN的算法框架出来：\r\r图3. GAN的算法框架\r\r可以注意到，在训练Generator的时候，其中\\(\\tilde{V}\\)的第一项实际上是与Generator是无关的，去掉第一项不影响我们最小化目标函数\\(\\tilde{V}\\)。显然，整个GAN算法分为两部分，我们可以这么理解：第一步训练Discriminator实际上是度量两个分布间JS散度，而训练Generator是在最小化JS散度。\n从数学推导可以帮助我们更好理解GAN，这一Part就结束啦๑乛◡乛๑\n\r\rReference\r李宏毅个人主页\r\r\r","date":1547510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547510400,"objectID":"d03491a09024157e17f22f6dd9546953","permalink":"/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%BA%8Cpart/","publishdate":"2019-01-15T00:00:00Z","relpermalink":"/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%BA%8Cpart/","section":"post","summary":"我们认为每张图片对应的是一个高维向量，我们希望能找出这一类图片所在的图像空间的分布\\(P\\)，GAN的目的其实就是在寻找这个分布\\(P\\)。\n传统的方法我们会想到用最大似然估计：\n\r首先给定一些样本数据，可以得到它的分布\\(P_{data}(x)\\)；接着我们假定有一个由参数\\(\\theta\\)决定的分布\\(P_G(x;\\theta)\\)；我们希望能够找到\\(\\theta\\)，满足分布\\(P_G(x;\\theta)\\)尽可能靠近分布\\(P_{data}(x)\\)；假设\\(P_G(x;\\theta)\\)是高斯分布（正态分布），那\\(\\theta\\)就是均值和方差。\n\r从分布\\(P_{data}(x)\\)中进行抽样获得一组样本数据\\(\\{x_1,x_2,\\dots,x_m\\}\\)，我们可以得到似然值的表达式 \\[L = \\prod_{i=1}^{m} P_G(x^i;\\theta)\\]我们希望能够找到\\(\\theta^*\\)能够使得似然值\\(L\\)最大。\n\r\r最大似然估计与最小KL散度的等价性\r通过对\\(L\\)取对数，我们可以得到对数似然值，同时\\(\\theta^*\\)可以通过下式得到： \\[\r\\begin{align}\r\\theta^* \u0026amp;=\\ \\arg \\max_{\\theta} \\log L\\\\ \u0026amp;=\\ \\arg \\max_{\\theta} \\log \\prod_{i=1}^{m} P_G(x^i;\\theta)\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\sum_{i=1}^m \\log P_G(x^i;\\theta)\r\\end{align}\r\\]\n由于样本\\(\\{x^1,x^2,\\dots,x^m\\}\\)是随机抽取来自于分布\\(P_{data}(x)\\)，上式可以近似求\\(\\log P_G(x;\\theta)\\)的期望的最大点，可以表示为 \\[\r\\begin{align}\r\\theta^* \u0026amp;\\approx\\ \\arg \\max_{\\theta} E_{x\\sim P_{data}}[\\log P_G(x;\\theta)]\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\log P_G(x;\\theta) dx\r\\end{align}\r\\]\n从式子中知道，我们所求的\\(\\theta^*\\)只跟分布\\(P_G(x;\\theta)\\)相关，我们可以在后面加上一项\\(-\\int\\limits_x P_{data}(x) \\log P_{data}(x)dx\\)，这不影响求最大化下对应得\\(\\theta^*\\)，那么由上式就可以得到 \\[\r\\begin{align}\r\\theta^* \u0026amp;\\approx\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\log P_G(x;\\theta) dx - \\int\\limits_x P_{data}(x) \\log P_{data}(x)dx\\\\\r\u0026amp;=\\ \\arg \\max_{\\theta} \\int\\limits_x P_{data}(x) \\Big[\\log P_G(x;\\theta) - \\log P_{data}(x)\\Big] dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} \\int\\limits_x P_{data}(x) \\Big[\\log P_{data}(x) - \\log P_G(x;\\theta)\\Big] dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} \\int\\limits_x P_{data}(x) \\log \\frac{P_{data}(x)}{P_G(x;\\theta)} dx\\\\\r\u0026amp;=\\ \\arg \\min_{\\theta} KL(P_{data}||P_G)\r\\end{align}\r\\]","tags":["Deep Learning","Algorithm"],"title":"生成对抗网络的第二Part","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":"\r从知乎上了解到台大有位著名的教授李宏毅超级会讲Generative Adversarial Networks, GAN技术，所以慕名而到Youtube找到他的上课视频成为他的“课外学生”。李教授真的厉害，形象生动地讲解GAN的各个知识点。那么，我把我学到的整理为一篇博客，尝试作为一名“GAN路上的导游”。\nYann LeCun是Facebook的AI研究部门的Director，同时也是NYU（New York University）的一位教授，维基百科上是这么介绍他：\n\rHe is the Chief Artificial Intelligence Scientist at Facebook AI Research, and he is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNN), and is a founding father of convolutional nets.\n\r做Deep Learning的人多多少少会听过这个名字，他曾经这样回答了Quora论坛上的一个问题（What are some recent and potentially upcoming breakthroughs in unsupervised learning?）：\n\rAdversarial training is the coolest thing since sliced bread.\n\r这里sliced bread的中文意思是切片面包，但其实这里是表示了有一个好东西问世，给某个领域带来了巨大发展，维基百科这么说：\n\rThe phrase “the greatest thing since sliced bread” is a common hyperbole used to praise an invention or development.\n\r这也说明了GAN推进了整个领域的发展。Yann LeCun对GAN也有过这样极高的评价：\n\rThis, and the variations that are now being proposed is the most interesting idea in the last 10 years in ML, in my opinion.\n\r李教授统计了ICASSP（International Conference on Acoustics, Speech and Signal Processing）的文章题目涵盖关键词的数量：\r\r图1. ICASSP文章题目涵盖关键词的数量变化图\r\r很明显，从17年的2篇Adversarial到18年的42篇Adversarial，同年增长了21倍！相当惊人！既然GAN这么Popular又是这么酷炫，那么我们就开始正文吧！(๑•̀ㅂ•́)و✧\n什么是GAN？说GAN就干！\rGAN里面主要分为Generator和Discriminator这两部分，其实原理很简单，Generator是负责训练样本并能生成对的Output，而Discriminator像是一位老师，看看Generator这位学生交的作业质量怎么样，会给Generator的作业一个分数。下面我们更详细地介绍他们这两部分~\n一无所知的Generator生成器\rGenerator其实就是neural network (NN)，它的输入是向量，那我们如果丢一个向量到Generator里面，它就能产生某个Output（可能是一张相片或者一句话等等）\r\r图2. Generator生成器的示例图\r\r李教授酷爱二次元，所以他举了这样的例子，丢一些向量给生成图片的Generator就生成了一些二次元的图片；另外，对应句子生成的例子，丢一些向量给生成句子的Generator就生成了一些句子。简单来说，我们给Generator这个function（NN其实就是一个复杂的function）赋值，它就会产生对应的结果。\n我们以图片为例，输入的向量中的每一个元素，可能对应着图片中不同的特征。假设第一位是改变头发的长短特征，那从下图中可以看到0.1改为3后，图片中的女孩从短头发变为长头发；假设向量倒数第二位是改变头发的颜色特征，那从下图可以看到5.4改为2.4后，图片中的女孩从紫色变为了蓝色；假设向量倒数第一位是改变嘴巴特征，那从下图可以看到0.9改为3.5后，图片中的女孩从小嘴巴变为了张开嘴巴。\r\r图3. 输入向量对结果输出的影响\r\r在实际操作中，如果我们通过大量的样本让Generator训练，使其能够输出与图片尽可能相似的结果，那这样就只是普通的NN（神经网络），但我们想要更高级！想要输出的图片质量更好！而GAN满足了我们的需求，它的idea妙就妙在搞多了一个Discriminator（监督器），审判Generator输出的结果是不是真的“好”。\n\r超严厉的Discriminator监督器\rDiscriminator也是一个NN，但是它的输入是一张图片或是一句话（Generator的输出）。而它的输出是一个数值，这个数值代表了这张图片的质量如何，数值越大，那图片的质量就越好，越像是真实的图片；相反，数值越小，图片质量越差。下面可以看到不同质量的二次元图片对应着不同的得分数值~\r\r图4. 不同二次元图片对应不同的得分\r\r前面大致讲了一下Generator和Discriminator的关系，但是不算很生动详细！下面我来举个栗子！\n我们可以把Generator和Discriminator当做捕食者和被捕食者，那Pokemon里面鸟系对虫系就有着威慑能力，天生虫系会怕鸟系嘛，这很合理╮(๑•́ ₃•̀๑)╭\r\r图5. 小智的比比鸟和绿毛虫的初次相遇\r\r其实一开始绿毛虫（一代Generator）就很怕波波（一代Discriminator）嘛，所以它就会进化成铁甲蛹（二代Generator），那波波个子小就拿它没办法了，吃也吃不了╮(๑•́ ₃•̀๑)╭所以波波也进化了变成了比比鸟（二代Discriminator）。那现在比比鸟翅膀大了，爪子一夹，把铁甲蛹抓到空中再丢下来（极其残忍！），铁甲蛹也会痛！所以铁甲蛹不甘示弱，它接着进化成巴大蝴（三代Generator）！这下比比鸟没办法它也进化成比雕（三代Discriminator），它以为比雕可能会搞得定巴大蝴！奈何巴大蝴也有翅膀了，还有催眠粉！比雕觉得没办法了，就这样吧，两人实力相当了！\n\r图6. Generator和Discriminator的相互关系\r\r回到现实！这里的巴大蝴就是我们的最终Generator（这里以三代为例，实际需要N代），那它所生成的图片可以让最终的Discriminator认为是真实的，这就达到了我们的目的(*•̀ㅂ•́)و\n\rGAN的算法框架\r我们了解了Generator和Discriminator的基本知识后，我们来看看算法~\n首先随机产生了两个NN作为Generator和Discriminator，然后不断循环：固定Generator调Discriminator的参数，再固定Discriminator调Generator的参数。具体过程如下所示：\n在第一步中固定Generator调Discriminator的参数，对于从Database出来的真实案例，我们希望Discriminator给高分；对于Generator生成的案例，我们希望Discriminator给低分。Discriminator通过训练会在这个过程中学会给真实的案例高分，给假的案例低分。\r\r图7. 固定Generator下训练Discriminator\r\r在下一步中我们固定Discriminator调Generator的参数，我们希望调整Generator后，我们给一个向量生成一个案例，这个案例通过Discriminator得到的分数能够尽量高。\r\r图8. 固定Discriminator下训练Generator\r\r如果我们写成Pseudocode（伪代码），就变成下面这样：\r\r图9. 关于GAN算法的伪代码\r\r\r\rUnsupervised Conditional Generation非监督的条件生成器\r通常在普通的神经网络方法下，但是我们需要对应的样本来帮助我们生成我们需要的图片；我们给一个输入，再给一个Label告诉机器，你看到这个输入就需要有这样的Label的输出，但如果对于某些样本我们刚好没有对应Label的话，但我们手中有其他类似的，那我们可以通过非监督的条件生成器来生成我们想要的结果。\n我们希望能够创造一个Generator，输入一个来自Domain X的样本，可以输出一个对应在Domain Y的样本。这相当于一种风格转化的案例。举个例子，现在许多人喜欢拍照用滤镜，通常我们拍的普通相片是没有带滤镜的，那现在我希望能够得到水彩画形式的相片，如下所示：\r\r图10. 变成水彩画形式的相片\r\r样本的直接转化问题（Direct Transformation）\r像上面叙述的例子，其实普通相片到油画形式的相片，只是色彩质地有所区别，但是总体的框架基本不变，相当于说只是小部分修改了我们输入的相片，那Direct Transformation就足够帮我们处理这个问题了。\n通常我们会用GAN的技术来实现，GAN其实也是可以解决这个问题，如果Generator的层数很少，不是那么复杂，在Discrimiantor的监督下生成油画型的图片跟输入的图片差距不会太大。但是如果Generator很复杂的情况下，Generator是存在可能会生成在Domain Y的相片与在Domain X的相片差距很大。即使在Discriminator中拿到了很高的分数，但是与原始输入的样本差距甚远，如下图所示：\r\r图11. 普通GAN的弱点\r\r在Domain X的河道图输入之后，尽管训练得到的Generator产生了艺术型的油画图，但是明显上图中的梵高自画像不是我们希望得到的输出，但它确实是属于Domain Y类型的图片。\nCycle GAN\r存在上述的问题，那么我们想在生成Domain Y的图片之后，我们可以做一个逆函数（NN）来返回去检验这个图片，看看能否恢复成我们输入图片的样子；当然，我们需要Discriminator帮助我们将输入的图片训练生成在Domain Y的图片。\r\r图12. Cycle GAN处理过程示意图\r\r\rStarGAN\r如果现在我们不仅仅希望普通相片可以变成一张油画照，我们还希望可以变成黑白照或者素描照，那我们的案例就变得更复杂，需要多个Domain，而且我们希望能够在多个Domain里面互转。假设我们有普通照片，油画照，黑白照和素描照这四种类型照片，那其实我们需要创建\\(C_4^2\\)个Cycle GAN来解决这样一个大问题，使得在这四个Domain之间实现互转（如下图(a)所示）。\n2017年arXiv上Yunjey Choi等人发表了文章StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation，StarGAN的方便之处是在于只学习了一个Generator，就可以在多个Domain之间实现互转（如下图(b)所示）。\n\r图13. Cross-domain models和StarGAN的示意图\r\r下面我们通过原文提供的案例来进一步了解StarGAN：\n\r首先，我们先训练Discriminator。这个Discriminator的输入有真实的照片和假的照片，我们希望Discriminator可以输出判断输入的照片是真的还是假的；同时希望可以输出判断真实的照片属于哪一个Domain。在下图案例可以看到，我们真实判断的Domain是\\(0\\ 0\\ 1\\ 0\\ 1\\)相当于真实照片是一个棕色头发年轻的女性角色。在这个地方可以注意到，我们只在考虑CelebA label，但是没有考虑RaFD label，而这个是由Mask vector所控制的（先设定为\\(1\\ 0\\)）。\n\r接着我们以真实照片（棕色头发年轻的女性角色）和我们希望得到的Domain（\\(1\\ 0\\ 0\\ 1\\ 1\\)）作为我们训练Generator的输入，我们希望输出得到目标Domain的照片（转化案例是希望得到一个黑色头发年轻的男性角色）。\n\r利用Cycle GAN的想法，我们用输出的照片（黑色头发年轻的男性角色）和我们原始的Domain（\\(0\\ 0\\ 1\\ 0\\ 1\\)）作为另外一个Generator的输入，希望得到和原始一模一样的照片（棕色头发年轻的女性角色）。\n\r最后呢~将第二步训练得到的照片作为Discriminator的输入，训练Discriminator判断能不能认为输入的照片是真实的照片，并且是属于我们希望得到的Domain（\\(1\\ 0\\ 0\\ 1\\ 1\\)）。\n\r循环前面第二到第四步，直到第四步中Discriminator认为第二步所输出的照片是真实的且属于Domain（\\(1\\ 0\\ 0\\ 1\\ 1\\)）。\n\r\r同理，我们可以让Mask vector为\\(0\\ 1\\)，不考虑CelebA label了而是考虑RaFD label，即考虑情绪的变换。\r\r图14. 来自原Paper的案例\r\r\r\r投影到共有的空间（Projection to Common Space）\r那如果想要转化的结果跟你原来输入的样本结果差别很大，对于图片而言，可能画风突变！比如从真人头像到二次元的漫画头像，这时没办法简单地进行Direct Transformation了，需要利用Projection这样的技术。如果我们先通过编码器获得latent variables，再通过解码器获得我们想要的输出，这样就有可能做到比较大的变换。\n问题\n对于两个Domain的大变化的互转，我们希望可以先分别对两个不同Domain的样本做Auto-Encoder，同时最小化重建的误差（Minimizing reconstruction error）。我们假设Domain X是漫画版本闪电侠，我们希望直接通过图片转化成真人版本的闪电侠（Domain Y），我们按刚刚说的流程，实现的流程如下图所示。\r\r图15. 漫画闪电侠与真人版的互换\r\r但是这样做存在问题就是Domain X做好的Auto-Encoder跟Domain Y做好的Auto-Encoder是完全没有联系的，这种情况下可能我输入一张闪电侠的漫画图片，通过Y的解码器（Decoder）之后，没办法得到闪电侠的真人图片，而是得到了绿箭侠的真人图片(๑•́ ₃ •̀)\r\r图16. 漫画闪电侠的变换结果出错的可能性\r\r【注：美剧闪电侠第五季的第九集和美剧绿箭第七季的第九集中，Oliver Queen变成了闪电侠。。。Barry Allen变成了绿箭侠。。。源自异世界的剧情_(:з」∠)_ 】\r\r回到正题！！！\n方法1\n那有一种方法呢，就是在获得中间的latent variables之前时，两个encoder最后有几层是共享相同参数的；同样在进入decoder部分时，前面几层也是共享相同参数的。这样在获得latent variables的时候，能够尽可能落在相同的latent space。这样的方法出现在文章Coupled Generative Adversarial Networks和文章Unsupervised Image-to-Image Translation Networks。\r\r图17. 共享参数的方法示意图\r\r方法2\n另外一种方法就是我们加一个Domain Discriminator，对中间产生的latent variables进行判定，判定产生的latent variables是来自\\(EN_X\\)还是来自\\(EN_Y\\)，那么两个Encoder就会训练使得产生的latent variables能够骗过Discriminator。这样相当于这个Domain Discriminator促使两个Encoder产生的latent variables来自相同的分布。\r\r图18. 加入Domain Discriminator的示意图\r\r方法3\n利用Cycle GAN的想法，我们还可以输入一张我们想要转换的图片（比如输入是漫画闪电侠），通过Domain X的encoder和Domain Y的decoder得到目标输出结果；然后，将这个结果作为Domain Y的encoder的输入，再通过Domain X的decoder得到我们想要转换的图片，当然我们会希望重建误差尽可能小。\n另外，我们可以加入两个Discriminator来判断两个decoder生成的图片是否属于各自相对应的Domain，这样的想法就有用在ComboGAN上，ComboGAN的文章全名叫做ComboGAN: Unrestrained Scalability for Image Domain Translation。\r\r图19. Cycle GAN想法下的流程示意图\r\r方法4\n除了最小化重建误差，我们也可以最小化从Domain X和Domain Y分别编码得到的latent variables。跟方法3有点相似，先输入一张我们想要转换的图片（比如输入是漫画闪电侠），通过Domain X的encoder得到latent variables，再通过Domain Y的decoder得到目标输出结果；然后，将这个结果作为Domain Y的encoder的输入，可以再次得到latent variables。其中这两次获得的latent variables，我们希望它们能够越接近越好。那这样的方法就有用在DTN和XGAN上，它们的文章全名分别为Unsupervised Cross-Domain Image Generation和XGAN: Unsupervised Image-to-Image Translation for Many-to-Many Mappings。\n更多的应用！语音变换！\r其实这项技术还可以用在语音变换上，可能生活中我们希望做一个变声器，我们说一句话但是扬声器出来的是另外一个人的声音。其实阿笠博士在20年前就已经给柯南一个变声器了，每次柯南都用来假装毛利小五郎的声音(..•˘_˘•..)\r\r图20. 柯南的蝴蝶结变声器\r\r结束基础普及知识的第一Part！！！第二Part再从基础理论来看GAN！\n\r\r\rReference\r李宏毅个人主页\r李宏毅，Youtube：GAN Lecture 1 (2018): Introduction\rI. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial networks,” in Advances in Neural Information Processing Systems (NIPS), 2014. 1, 3\rY. Choi, M. Choi, M. Kim, J.-W. Ha, S. Kim, and J. Choo, “Stargan: Unified generative adversarial networks for multi-domain image-toimage translation,” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. 1, 3, 6, 7, 8, 9, 10\r\r\r","date":1547424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547424000,"objectID":"fe7467601e4b4a7a071f5b06deb13dc2","permalink":"/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%B8%80part/","publishdate":"2019-01-14T00:00:00Z","relpermalink":"/post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%B8%80part/","section":"post","summary":"从知乎上了解到台大有位著名的教授李宏毅超级会讲Generative Adversarial Networks, GAN技术，所以慕名而到Youtube找到他的上课视频成为他的“课外学生”。李教授真的厉害，形象生动地讲解GAN的各个知识点。那么，我把我学到的整理为一篇博客，尝试作为一名“GAN路上的导游”。\nYann LeCun是Facebook的AI研究部门的Director，同时也是NYU（New York University）的一位教授，维基百科上是这么介绍他：\n\rHe is the Chief Artificial Intelligence Scientist at Facebook AI Research, and he is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNN), and is a founding father of convolutional nets.\n\r做Deep Learning的人多多少少会听过这个名字，他曾经这样回答了Quora论坛上的一个问题（What are some recent and potentially upcoming breakthroughs in unsupervised learning?）：\n\rAdversarial training is the coolest thing since sliced bread.","tags":["Deep Learning"],"title":"生成对抗网络的第一Part","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":" 神经元及神经网络基础结构  图1. 神经元的组成（源自维基百科）  神经元这个图大多数理科生在高中生物课本都学过~神经网络则由许许多多的神经元所组成，通常一个神经元具有多个树突，主要用来接收消息；轴突只有一条，相当于我们定义的一个计算过程；而轴突尾部的许许多多轴突末梢，将传递信息给其他神经元。\n 图2. 神经网络基础结构  通常这里的非线性函数会用上各式各样的激活函数，比如Sigmoid函数，tanh函数和ReLu函数。\nSigmoid函数\n\\[f(z) = \\frac{1}{1+e^{-z}}\\] tanh函数\n\\[f(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}\\] ReLu函数\n\\[f(z) = \\max(0,z)\\]\n 神经网络基础认知 我们把许多神经元组合起来就可以得到一个神经网络，由于有输入的数据和我们想得到的输出数据，便会有“输入层”（Input layer）和“输出层”（Output layer）；中间的神经元则组成了“隐藏层”（Hidden layer）。在下面图3中，输入层有3个神经元，隐藏层有4个神经元，输出层有2个神经元。在实际情况中，输入层和输出层通常是固定的，而隐藏层的层数和节点数则可以自由调节。  图3. 神经网络基础层级结构  我们假设一个全连接的网络结构，其中隐藏层只有一层。另外，假设输入层和隐藏层之间的边的权值构成的矩阵为 \\[ \\left [ \\begin{matrix} w_{11} \u0026amp; w_{12} \u0026amp; w_{13} \\\\ w_{21} \u0026amp; w_{22} \u0026amp; w_{23} \\\\ w_{31} \u0026amp; w_{32} \u0026amp; w_{33} \\end{matrix} \\right ] \\] 其中，第一列的\\(w_{11}, w_{21}, w_{31}\\)代表的是输入层的点\\(x_1\\)分别连接隐藏层的三个节点的边的权值；第二列的\\(w_{12}, w_{22}, w_{32}\\)代表的是输入层的点\\(x_2\\)分别连接隐藏层的三个节点的边的权值；第三列的\\(w_{13}, w_{23}, w_{33}\\)代表的是输入层的点\\(x_3\\)分别连接隐藏层的三个节点的边的权值。\n图中的“+1”点代表我们添加了一个值b，称其为偏置项。那么，隐藏层的节点可以由下计算得到： \\[ \\begin{align} a_1 = w_{11}\\times x_1 + w_{12}\\times x_2 + w_{13}\\times x_3 + b_1\\\\ a_2 = w_{21}\\times x_1 + w_{22}\\times x_2 + w_{23}\\times x_3 + b_2\\\\ a_3 = w_{31}\\times x_1 + w_{32}\\times x_2 + w_{33}\\times x_3 + b_3 \\end{align} \\tag{1} \\] 由于线性计算的表现能力比较差，所以考虑用非线性函数进行计算，即使用激活函数\\(f(\\cdot)\\)（前面已提及）。（1）式可以变换为（2）式： \\[ \\begin{align} a_1 = f(w_{11}\\times x_1 + w_{12}\\times x_2 + w_{13}\\times x_3 + b_1)\\\\ a_2 = f(w_{21}\\times x_1 + w_{22}\\times x_2 + w_{23}\\times x_3 + b_2)\\\\ a_3 = f(w_{31}\\times x_1 + w_{32}\\times x_2 + w_{33}\\times x_3 + b_3) \\end{align} \\tag{2} \\] 将（2）式改写为矩阵运算形式（3）式： \\[ \\begin{align} \\boldsymbol{a} = f \\begin{pmatrix} \\begin{pmatrix} w_{11},w_{12},w_{13}\\\\w_{21},w_{22},w_{23}\\\\w_{31},w_{32},w_{33} \\end{pmatrix} \\begin{pmatrix} x_1\\\\x_2\\\\x_3 \\end{pmatrix} + \\begin{pmatrix} b_1\\\\b_2\\\\b_3 \\end{pmatrix} \\end{pmatrix} = f(\\boldsymbol{W}x+\\boldsymbol{B}) \\end{align} \\tag{3} \\]\n 图4. 简单全连接网络中层之间的计算方式  当我们增加隐藏层的层数，便可以构成更复杂的网络，即深度神经网络。  图5. 深度神经网络示意图   损失函数（Loss Function） 训练数据通常是一系列“输入-输出”数据对组成的集合，我们希望输入一个数据，尽可能与配对的输出数据相同。那么网络的输出结果和实际的真实结果差多少，我们需要一定数学形式进行量化，所以引入了损失函数（Loss Function）。常见的损失函数有以下几种：\n0-1损失函数\n如果预测值和真实值一样，则损失值为0；若不等，则为1；公式表达为： \\[ L(y,f(x)) = \\begin{cases} 1, \u0026amp; y = f(x)\\\\ 0, \u0026amp; y \\neq f(x) \\end{cases} \\]\n绝对值损失函数（1-范数形式）\n通过预测值和真实值之差的绝对值进行衡量，公式表达为： \\[ L(y,f(x)) = |y-f(x)| \\]\n均方误差损失函数（2-范数形式）\n通过计算预测值和真实值之差的平方再求均值，可得到均方误差，公式表达为： \\[ L(y,f(x)) = \\frac{1}{n}\\sum_{i=1}^n(y_i-f(x_i))^2 \\]\n 优化算法 梯度下降法（Gradient Descent Method） 传统的梯度下降法是通过计算损失函数的一阶导数作为方向进行下降计算，计算方法可表示为： \\[ W_{ij} = W_{ij} - \\alpha\\frac{\\partial}{\\partial W_{ij}}L(w,b)\\\\ b_i = b_i - \\alpha\\frac{\\partial}{\\partial b_i}L(w,b) \\] 其中\\(W_{ij}\\)和\\(b_i\\)是需要优化的参数，\\(L(w,b)\\)是损失函数，\\(\\alpha\\)在深度学习中通常称为学习率（learning rate），在机器学习或最优化计算领域中我们通常称为步长（stepsize）。\n传统的梯度下降法需要计算\\(n\\)个梯度，即样本数量的梯度个数，在数据越来越大的时代，这会大大降低我们需要的计算速度，因此也产生了随机梯度下降（Stochastic gradient descent）这一类的方法。随机梯度下降通常随机选取某个样本并计算其相应导数，作为所有样本相同的导数进行计算，这种方法在实践上有不错的效果。当然，我们可以随机选取一小批样本，样本数量记为batch size，将batch size个样本的导数进行累加后求均值作为所有样本相同的导数，再进一步计算；这种方法我们称为小批量随机梯度下降法（mini-batch stochastic gradient descent）。\n虽然梯度下降直接快速，但是也有一定的不足，由于我们需要选取stepsize，若stepsize太大，那可能无法达到优化问题的最优点；若stepsize太小，则收敛速度太慢，大大降低了模型训练速度。同时，不变的stepsize可能会使结果无法收敛到全局最优解，并可能停在局部最小值（局部最优解），当然很容易陷入到“鞍点”。\n 图6. “鞍点”示意图   Momentum优化器（Momentum Optimizer） Momentum优化器也可称为基于动量的优化算法，其中参数的更新会根据梯度的变化而变化：动量再梯度连续指向同一方向上时会增加，而在梯度方向变化时会减小；这样可以更快地收敛并减少震荡。公式表示为： \\[ v_t^{W} = \\gamma \\times v_{t-1}^{W} + \\alpha \\times \\frac{\\partial}{\\partial W_{ij}}L(w,b)\\\\ W_{ij} = W_{ij} - v_t^{W}\\\\ v_t^{b} = \\gamma \\times v_{t-1}^{b} + \\alpha \\times \\frac{\\partial}{\\partial b_i}L(w,b)\\\\ b_i = b_i - v_t^{b} \\] 其中，\\(\\gamma\\)是动量更新值，通常取0.9。这样，基于Momentum的随机梯度下降可以更快地收敛，并减少陷入局部最优点的概率。\n Adagrad优化器（Adaptive Gradient Optimizer） Momentum优化器虽然加速了参数的更新并加速收敛，但存在缺点是没有对不同的参数进行区别对待。Adagrad优化器则基于这样的梯度优化思想：根据参数自适应地更新学习率（也为步长stepsize），对于不频繁更新的参数做较大更新，而对于频繁更新的参数做较小的更新。\nAdagrad对于每个参数\\(\\theta_{t,i}\\)，在每个时间点\\(t\\)使用不同的学习率。首先我们先考虑Adagrad的单参数情况，为了公式形式的整洁，我们记各个时间点\\(t\\)的参数\\(\\theta_{t,i}\\)下的目标函数梯度为\\(g_{t,i}\\)： \\[g_{t,i} = \\frac{\\partial}{\\partial \\theta_{t,i}}L(\\theta_{t,i})\\] 在Adagrad的更新规则中，我们会根据每个时间点\\(t\\)对每个参数\\(\\theta_{t+1,i}\\)基于上次已经计算过的梯度\\(\\theta_{t,i}\\)来修改步长： \\[\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\alpha}{\\sqrt{G_{t,ii}+\\epsilon}}\\times g_{t,i}\\] 其中，\\(G_{t,ii}\\in R^{d\\times d}\\)，\\(G_{t,ii}\\)是一个对角矩阵，其对角元素\\(t\\)时刻参数\\(\\theta_{t,i}\\)的梯度平方和，\\(\\epsilon\\)是一个光滑项，防止分母为0，通常取1e-8级别的数。另外，\\(\\alpha\\)使用默认值0.01。Adagrad有个缺点就是其分母实际上累积了梯度的平方，会使得步长（学习率）越来越小。\n Adadelta优化器 Adadelta是对Adagrad的改进，通过用过去计算的梯度平方的均值代替单纯的累加梯度平方，可以避免一味地降低步长。\n\\(t\\)时刻的梯度平方均值表示为： \\[ E[g^2]_{t,i} = \\gamma\\times E[g^2]_{t-1,i} + (1-\\gamma)\\times g_{t,i}^2 \\] 其中，\\(\\gamma\\)和前面提到的Momentum优化器中的\\(\\gamma\\)类似，通常取0.9。将累积梯度平方更改为梯度平方均值，可得到： \\[\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\alpha}{\\sqrt{E_t+\\epsilon}}\\times g_{t,i}\\] 另外，我们还想要变换分子的\\(\\gamma\\)，将\\(\\gamma\\)改为\\(\\sqrt{E[\\Delta\\theta^2]_t+\\epsilon}\\)，便得到Adadelta的计算形式，以上内容可以总结为： \\[ E[g^2]_{t,i} = \\gamma\\times E[g^2]_{t-1,i} + (1-\\gamma)\\times g_{t,i}^2\\\\ E[\\Delta\\theta^2]_{t,i} = \\gamma\\times E[\\Delta\\theta^2]_{t-1,i} + (1-\\gamma)\\times \\Delta\\theta_{t,i}^2\\\\ \\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\sqrt{E[\\Delta\\theta^2]_{t-1,i}+\\epsilon}}{\\sqrt{E[g^2]_{t,i}+\\epsilon}}\\times g_{t,i} \\] 显然，我们不再需要提前设定步长了。\n Adam优化器（Adaptive Moment Estimation Optimizer, Adam Optimizer） Adam也是个人名，圣经中说他是世上的第一个人类也是第一个男人，接着和夏娃结为夫妻，过上了幸福的生活…跑远了！回正题！其实Adam的全称中文是自适应矩估计，它不仅像Adadelta一样存储过去梯度平方\\(v_t\\)的平均值之外，还保留了像Momentum一样的保留了过去梯度\\(m_t\\)，其计算公式为： \\[ m_t = \\beta_1m_{t-1} + (1-\\beta_1)g_t\\\\ v_t = \\beta_2v_{t-1} + (1-\\beta_2)g_t^2 \\] 由于\\(m_t\\)和\\(v_t\\)在计算上会存在偏差，所以进行了偏差校正： \\[ \\hat{m_t} = \\frac{m_t}{1-\\beta_1^t}\\\\ \\hat{v_t} = \\frac{v_t}{1-\\beta_2^t} \\] Adam的更新规则： \\[\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v_t}+\\epsilon}}\\times \\hat{m_t}\\] 其中，\\(\\beta_1\\)通常取0.9，\\(\\beta_2\\)通常取0.999，\\(\\epsilon\\)通常取1e-8。大多实验表明，Adam比其他自适应学习算法表现更优。\n 算法表现效果  图7. 不同优化器的随机梯度下降法在鞍点处的不同表现  注：动图来源于Sebastian Ruder的文章，由Alec Radford制作。\n 题外话（跳过这段吧~）\n在整理学习优化算法的时候，发现一件有趣的事。我边看着《Tensorflow入门与实战》的第四章边学习优化算法，同时网上边找找资料帮助理解。然而有趣的是我找到了一位业界大神Sebastian Ruder的主页，并看到了他在2016年1月6日写下了An overview of gradient descent optimization algorithms。看着看着我发现手中拿的书竟然是电脑屏幕上显示的文章的中文版，我便好奇地寻找手中这本实战书的出版时间 —— 2018年2月17日。怪哉怪哉~再翻翻书，发现并无任何引用。算了，回归主题！（Reference选了日期比较前的S.R.大佬的文章作为引用）    反向传播算法（Backpropagation） 反向传播算法是目前用来训练人工神经网络（Artificial Neural Network，ANN）的最常用且最有效的算法。首先我们先定义变量：\n \\(v_i^{(l)}\\)：第\\(l\\)层的第\\(i\\)个节点的输入值，\\(v_i^{(l)} = \\sum_{j=0}^n w_{ij}^{(l)}a_j^{(l-1)} + b_i^{(l)}\\)； \\(a_i^{(l)}\\)：第\\(l\\)层的第\\(i\\)个节点的输出值，\\(a_i^{(l)} = f(v_i^{(l)})\\)，其中\\(f(\\cdot)\\)是激活函数； \\(w_{ij}^{(l)}\\)：第\\(l-1\\)层的第\\(j\\)个节点到第\\(l\\)层的第\\(i\\)个节点的权值； \\(b_i^{(l)}\\)：第\\(l\\)层计算第\\(i\\)个节点的输入值时的偏置项的值； \\(K\\)：神经网络的总层数； \\(f(\\cdot)\\)：激活函数，例如sigmoid函数，tanh函数或者ReLu函数； \\(L(w,b)\\)：整体损失函数，常用的损失函数为\\(\\frac{1}{2n}\\sum_{i=1}^n(y_i-f(x_i))^2\\)，其中n是样本的个数。  反向传播计算过程的细节如下所示：\n 参数初始化\n随机初始化网络中的各层的参数\\(w_{ij}^{(l)}\\)和\\(b_i^{(l)}\\)，且满足\\(N(0,\\ 0.01)\\)分布的随机数；\n 前向传播\n  以图3中隐藏层的第一个节点（从上往下数第一个）为例，对于这个节点而言，其输入信号为： \\[v_1^{(2)} = a_1^{(1)}\\times w_{11}^{(2)} + a_2^{(1)}\\times w_{12}^{(2)} + a_3^{(1)}\\times w_{13}^{(2)} + b_1^{(2)}\\]\n同理，我们可以得到该层的其他节点的计算： \\[ v_2^{(2)} = a_1^{(1)}\\times w_{21}^{(2)} + a_2^{(1)}\\times w_{22}^{(2)} + a_3^{(1)}\\times w_{23}^{(2)} + b_2^{(2)}\\\\ v_3^{(2)} = a_1^{(1)}\\times w_{31}^{(2)} + a_2^{(1)}\\times w_{32}^{(2)} + a_3^{(1)}\\times w_{33}^{(2)} + b_3^{(2)}\\\\ v_4^{(2)} = a_1^{(1)}\\times w_{41}^{(2)} + a_2^{(1)}\\times w_{42}^{(2)} + a_3^{(1)}\\times w_{43}^{(2)} + b_4^{(2)}\\\\ \\]\n若用矩阵形式进行表达： \\[V^{(2)} = A^{(1)}\\times W^{(2)} + B^{(2)}\\] 其中， \\[ V^{(2)} = (v_1^{(2)}, v_2^{(2)}, v_3^{(2)}, v_4^{(2)})\\\\ A^{(1)} = (a_1^{(1)}, a_2^{(1)}, a_3^{(1)})\\\\ W^{(2)} = \\begin{pmatrix} w_{11}^{(2)} \u0026amp; w_{21}^{(2)} \u0026amp; w_{31}^{(2)} \u0026amp; w_{41}^{(2)}\\\\ w_{12}^{(2)} \u0026amp; w_{22}^{(2)} \u0026amp; w_{32}^{(2)} \u0026amp; w_{42}^{(2)}\\\\ w_{13}^{(2)} \u0026amp; w_{23}^{(2)} \u0026amp; w_{33}^{(2)} \u0026amp; w_{43}^{(2)} \\end{pmatrix}\\\\ B^{(2)} = (b_1^{(2)}, b_2^{(2)}, b_3^{(2)}, b_4^{(2)}) \\]\n再经过激活函数（非线性函数）变换后得到： \\[A^{(2)} = f(V^{(2)})\\]\n同理，经由 \\[ V^{(3)} = A^{(2)}\\times W^{(3)} + B^{(3)}\\\\ A^{(3)} = f(V^{(3)}) \\] 可以得到最终输出。\n 反向传播\n首先对于最后一层节点的偏导数，其实我们很容易得到，我们定义神经网络总共有\\(K\\)层，对于最后一层即第\\(K\\)层（输出层），根据偏导数的定义：  \\[ \\begin{align} \\delta_i^{(K)} =\u0026amp;\\ \\frac{\\partial}{\\partial v_i^{(K)}}L(w,b)\\\\ =\u0026amp;\\ \\frac{\\partial L(w,b)}{\\partial a_i^{(K)}}\\times \\frac{\\partial a_i^{(K)}}{\\partial v_i^{(K)}}\\\\ =\u0026amp;\\ \\frac{\\partial L(w,b)}{\\partial a_i^{(K)}}\\times f\u0026#39;(v_i^{(K)}) \\end{align} \\tag{4} \\] 明显的是，\\(a_i^{(K)}\\)是最后一层（即输出层）的输出值，\\(f\u0026#39;(v_i^{(K)})\\)则是激活函数对\\(v_i^{(K)}\\)的导数。\n对（4）式进一步推导可以得到： \\[ \\begin{align} \\delta_i^{(K)} =\u0026amp;\\ \\frac{\\partial}{\\partial a_i^{(K)}}\\Big[\\frac{1}{2n_K}\\sum_{j=1}^{n_K}\\Big(y_j-a_j^{(K)}\\Big)^2\\Big]\\times f\u0026#39;(v_i^{(K)})\\\\ =\u0026amp;\\ -\\frac{1}{n_k}(y_i-a_i^{(K)})\\times f\u0026#39;(v_i^{(K)}) \\end{align} \\] 其中，\\(y_i\\)是样本对应的正确值，\\(n_K\\)是第K层节点个数。\n因此，可得到最后一层（第K层）的计算公式： \\[ \\delta_i^{(K)} = -\\frac{1}{n_k}(y_i-a_i^{(K)})\\times f\u0026#39;(v_i^{(K)}) \\tag{5} \\]\n那么对于第\\(K-1\\)层的偏导数，可以根据第\\(K\\)层的计算出来： \\[ \\begin{align} \\delta_i^{(K-1)} =\u0026amp;\\ \\frac{\\partial}{\\partial v_i^{(K-1)}}L(w,b)\\\\ =\u0026amp;\\ \\frac{\\partial}{\\partial v_i^{(K-1)}}\\Big[\\frac{1}{2n_K}\\sum_{j=1}^{n_K}\\Big(y_j-a_j^{(K)}\\Big)^2\\Big]\\\\ =\u0026amp;\\ \\frac{1}{2n_K}\\Big[\\frac{\\partial}{\\partial v_i^{(K-1)}} \\sum_{j=1}^{n_K}\\Big(y_j-f(v_j^{(K)})\\Big)^2\\Big] \\end{align} \\tag{6} \\]\n利用连续函数的求导和求和顺序可互换，（6）式可以推得： \\[ \\begin{align} \\delta_i^{(K-1)} =\u0026amp;\\ -\\frac{1}{n_K} \\sum_{j=1}^{n_K} \\Big[(y_j-f(v_j^{(K)}))\\times \\frac{\\partial}{\\partial v_i^{(K-1)}}f(v_j^{(K)})\\Big]\\\\ =\u0026amp;\\ -\\frac{1}{n_K} \\sum_{j=1}^{n_K} \\Big[(y_j-f(v_j^{(K)}))\\times \\frac{\\partial f(v_j^{(K)})}{\\partial v_i^{(K)}}\\times \\frac{\\partial v_i^{(K)}}{\\partial v_i^{(K-1)}} \\Big]\\\\ =\u0026amp;\\ \\sum_{j=1}^{n_K} \\Big[-\\frac{1}{n_K} (y_j-f(v_j^{(K)}))\\times f\u0026#39;(v_j^{(K)})\\times \\frac{\\partial v_i^{(K)}}{\\partial v_i^{(K-1)}} \\Big] \\end{align} \\]\n联合（5）式，由（6）式可以得到： \\[ \\begin{align} \\delta_i^{(K-1)} =\u0026amp;\\ \\sum_{j=1}^{n_K} \\Big[ \\delta_i^{(K)}\\times \\frac{\\partial v_i^{(K)}}{\\partial v_i^{(K-1)}} \\Big]\\\\ =\u0026amp;\\ \\sum_{j=1}^{n_K}\\Bigg[ \\delta_i^{(K)}\\times \\frac{\\partial }{\\partial v_i^{(K-1)}}\\Big[ \\sum_{m=0}^{n_{K-1}}a_m^{(K-1)}\\times w_{jm}^{(K)}+b_j^{(K)} \\Big]\\Bigg]\\\\ =\u0026amp;\\ \\sum_{j=1}^{n_K}\\Bigg[ \\delta_i^{(K)}\\times \\frac{\\partial }{\\partial v_i^{(K-1)}}\\Big[ \\sum_{m=0}^{n_{K-1}}f(v_m^{(K-1)})\\times w_{jm}^{(K)}+b_j^{(K)} \\Big]\\Bigg]\\\\ =\u0026amp;\\ \\sum_{j=1}^{n_K}\\Bigg[ \\delta_i^{(K)}\\times f\u0026#39;(v_i^{(K-1)})\\times w_{ji}^{(K)} \\Bigg]\\\\ =\u0026amp;\\ \\Bigg[\\sum_{j=1}^{n_K}\\Big[ \\delta_i^{(K)}\\times w_{ji}^{(K)} \\Big]\\Bigg] \\times f\u0026#39;(v_i^{(K-1)}) \\end{align} \\]\n因此，可得到第K-1层的计算公式： \\[ \\delta_i^{(K-1)} = \\Bigg[\\sum_{j=1}^{n_K}\\Big[ \\delta_i^{(K)}\\times w_{ji}^{(K)} \\Big]\\Bigg] \\times f\u0026#39;(v_i^{(K-1)}) \\tag{7} \\]\n同理，用\\(K-2\\)替换\\(K-1\\)，用\\(K-1\\)替换\\(K\\)，则可计算第\\(K-2\\)层的偏导数。 \\[ \\delta_i^{(K-2)} = \\Bigg[\\sum_{j=1}^{n_{K-1}}\\Big[ \\delta_i^{(K-1)}\\times w_{ji}^{(K-1)} \\Big]\\Bigg] \\times f\u0026#39;(v_i^{(K-2)}) \\tag{7} \\]\n同样的，可以根据（7）式计算得到网络中所有节点的偏导数。\n回归我们的参数迭代公式： \\[ \\begin{align} w_{ij}^{(l)} =\u0026amp;\\ w_{ij}^{(l)} - \\alpha\\times \\frac{\\partial}{\\partial w_{ij}^{(l)}}L(w,b)\\\\ b_i^{(l)} =\u0026amp;\\ b_i^{(l)} - \\alpha\\times \\frac{\\partial}{\\partial b_i^{(l)}}L(w,b) \\end{align} \\tag{8} \\]\n对于后面的偏导数部分，我们可以加以处理，对于参数\\(w_{ij}^{(l)}\\)部分： \\[ \\begin{align} \\frac{\\partial L(w,b)}{\\partial w_{ij}^{(l)}} =\u0026amp;\\ \\frac{\\partial L(w,b)}{\\partial v_i^{(l)}}\\times \\frac{\\partial v_i^{(l)}}{\\partial w_{ij}^{(l)}}\\\\ =\u0026amp;\\ \\delta_i^{(l)}\\times \\frac{\\partial v_i^{(l)}}{\\partial w_{ij}^{(l)}}\\\\ =\u0026amp;\\ \\delta_i^{(l)}\\times \\frac{\\partial }{\\partial w_{ij}^{(l)}}\\Big[\\sum_{j=0}^{n_{l-1}}a_j^{(l-1)}\\times w_{ij}^{(l)}+b_i^{(l)}\\Big]\\\\ =\u0026amp;\\ \\delta_i^{(l)}\\times a_j^{(l-1)} \\end{align} \\]\n对于参数\\(b_i^{(l)}\\)部分： \\[ \\begin{align} \\frac{\\partial L(w,b)}{\\partial b_i^{(l)}} =\u0026amp;\\ \\frac{\\partial L(w,b)}{\\partial v_i^{(l)}}\\times \\frac{\\partial v_i^{(l)}}{\\partial b_i^{(l)}}\\\\ =\u0026amp;\\ \\delta_i^{(l)}\\times \\frac{\\partial}{\\partial b_i^{(l)}}\\Big[\\sum_{j=0}^{n_{l-1}}a_j^{(l-1)}\\times w_{ij}^{(l)}+b_i^{(l)}\\Big]\\\\ =\u0026amp;\\ \\delta_i^{(l)} \\end{align} \\]\n因此，由（8）式可以推得 \\[ \\begin{align} w_{ij}^{(l)} =\u0026amp;\\ w_{ij}^{(l)} - \\alpha\\times \\delta_i^{(l)}\\times a_j^{(l-1)}\\\\ b_i^{(l)} =\u0026amp;\\ b_i^{(l)} - \\alpha\\times \\delta_i^{(l)} \\end{align} \\tag{8} \\]\nOver！反向传播算法到此结束！\n Reference Sebastian Ruder. An overview of gradient descent optimization algorithms\n ","date":1546646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546646400,"objectID":"a02ffc69823c43b02495a4e0f043803c","permalink":"/post/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","publishdate":"2019-01-05T00:00:00Z","relpermalink":"/post/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","section":"post","summary":"神经元及神经网络基础结构  图1. 神经元的组成（源自维基百科）  神经元这个图大多数理科生在高中生物课本都学过~神经网络则由许许多多的神经元所组成，通常一个神经元具有多个树突，主要用来接收消息；轴突只有一条，相当于我们定义的一个计算过程；而轴突尾部的许许多多轴突末梢，将传递信息给其他神经元。\n 图2. 神经网络基础结构  通常这里的非线性函数会用上各式各样的激活函数，比如Sigmoid函数，tanh函数和ReLu函数。\nSigmoid函数\n\\[f(z) = \\frac{1}{1+e^{-z}}\\] tanh函数\n\\[f(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}\\] ReLu函数\n\\[f(z) = \\max(0,z)\\]\n 神经网络基础认知 我们把许多神经元组合起来就可以得到一个神经网络，由于有输入的数据和我们想得到的输出数据，便会有“输入层”（Input layer）和“输出层”（Output layer）；中间的神经元则组成了“隐藏层”（Hidden layer）。在下面图3中，输入层有3个神经元，隐藏层有4个神经元，输出层有2个神经元。在实际情况中，输入层和输出层通常是固定的，而隐藏层的层数和节点数则可以自由调节。  图3. 神经网络基础层级结构  我们假设一个全连接的网络结构，其中隐藏层只有一层。另外，假设输入层和隐藏层之间的边的权值构成的矩阵为 \\[ \\left [ \\begin{matrix} w_{11} \u0026amp; w_{12} \u0026amp; w_{13} \\\\ w_{21} \u0026amp; w_{22} \u0026amp; w_{23} \\\\ w_{31} \u0026amp; w_{32} \u0026amp; w_{33} \\end{matrix} \\right ] \\] 其中，第一列的\\(w_{11}, w_{21}, w_{31}\\)代表的是输入层的点\\(x_1\\)分别连接隐藏层的三个节点的边的权值；第二列的\\(w_{12}, w_{22}, w_{32}\\)代表的是输入层的点\\(x_2\\)分别连接隐藏层的三个节点的边的权值；第三列的\\(w_{13}, w_{23}, w_{33}\\)代表的是输入层的点\\(x_3\\)分别连接隐藏层的三个节点的边的权值。\n图中的“+1”点代表我们添加了一个值b，称其为偏置项。那么，隐藏层的节点可以由下计算得到： \\[ \\begin{align} a_1 = w_{11}\\times x_1 + w_{12}\\times x_2 + w_{13}\\times x_3 + b_1\\\\ a_2 = w_{21}\\times x_1 + w_{22}\\times x_2 + w_{23}\\times x_3 + b_2\\\\ a_3 = w_{31}\\times x_1 + w_{32}\\times x_2 + w_{33}\\times x_3 + b_3 \\end{align} \\tag{1} \\] 由于线性计算的表现能力比较差，所以考虑用非线性函数进行计算，即使用激活函数\\(f(\\cdot)\\)（前面已提及）。（1）式可以变换为（2）式： \\[ \\begin{align} a_1 = f(w_{11}\\times x_1 + w_{12}\\times x_2 + w_{13}\\times x_3 + b_1)\\\\ a_2 = f(w_{21}\\times x_1 + w_{22}\\times x_2 + w_{23}\\times x_3 + b_2)\\\\ a_3 = f(w_{31}\\times x_1 + w_{32}\\times x_2 + w_{33}\\times x_3 + b_3) \\end{align} \\tag{2} \\] 将（2）式改写为矩阵运算形式（3）式： \\[ \\begin{align} \\boldsymbol{a} = f \\begin{pmatrix} \\begin{pmatrix} w_{11},w_{12},w_{13}\\\\w_{21},w_{22},w_{23}\\\\w_{31},w_{32},w_{33} \\end{pmatrix} \\begin{pmatrix} x_1\\\\x_2\\\\x_3 \\end{pmatrix} + \\begin{pmatrix} b_1\\\\b_2\\\\b_3 \\end{pmatrix} \\end{pmatrix} = f(\\boldsymbol{W}x+\\boldsymbol{B}) \\end{align} \\tag{3} \\]","tags":["Deep Learning"],"title":"深度神经网络基础","type":"post"},{"authors":null,"categories":["Rmarkdown"],"content":" 缘于某人用Rmarkdown搞不出中文内容的pdf而引发一场激战之下，TT只能忍气吞声继续走上帮人帮到底的道路，于是网上搜出一大堆关于Rmarkdown生成中文pdf的麻烦事。无奈，众里寻它千百度，最终发现解决问题的YAML模板及相关的解决方案，怕在接下来的日子可能遭受同样的折磨，并以扩充Blog文章为前提，书写此文。\n首先，让我们先在RStudio菜单栏选择Tools并点击Global Options。选择Sweaver并按图勾选，最后点OK~  Figure1. 可爱的Global Options窗口  然后.Rmd文件中的YAML模板如下设置：\n--- title: \u0026quot;我是一个Test文档的标题\u0026quot; author: \u0026quot;我是一个Test文档的作者名称\u0026quot; date: \u0026quot;我是一个Test文档的写作日期\u0026quot; CJKmainfont: Microsoft YaHei output: pdf_document: includes: header-includes: - \\usepackage{xeCJK} keep_tex: yes latex_engine: xelatex --- 注：介个模板用上了大微软的雅黑字体，如若想修改，那请继续摸索摸索。（T.T累了不想改了~）\n搞定！Over！愿你的探索之路不与我一样艰辛((٩(//̀Д/́/)۶))\n课外补充：\n 关于Rmarkdown to pdf的美好世界\n如果你也被这样的问题所困扰，那么你会发现R界的大佬谢益辉搞了个包叫rticles，直接提供template给你写中文文档。然而，无奈Tex世界的混乱，还是遇到奇奇怪怪的乱七八糟的问题，但是大佬说大家用TinyTex吧，那将提供Rmarkdown to pdf的一片美好世界。  ","date":1546387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546387200,"objectID":"787c464bca8e3faac12f75c940ece8da","permalink":"/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","publishdate":"2019-01-02T00:00:00Z","relpermalink":"/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","section":"post","summary":" 缘于某人用Rmarkdown搞不出中文内容的pdf而引发一场激战之下，TT只能忍气吞声继续走上帮人帮到底的道路，于是网上搜出一大堆关于Rmarkdown生成中文pdf的麻烦事。无奈，众里寻它千百度，最终发现解决问题的YAML模板及相关的解决方案，怕在接下来的日子可能遭受同样的折磨，并以扩充Blog文章为前提，书写此文。\n首先，让我们先在RStudio菜单栏选择Tools并点击Global Options。选择Sweaver并按图勾选，最后点OK~  Figure1. 可爱的Global Options窗口  然后.Rmd文件中的YAML模板如下设置：\n--- title: \u0026quot;我是一个Test文档的标题\u0026quot; author: \u0026quot;我是一个Test文档的作者名称\u0026quot; date: \u0026quot;我是一个Test文档的写作日期\u0026quot; CJKmainfont: Microsoft YaHei output: pdf_document: includes: header-includes: - \\usepackage{xeCJK} keep_tex: yes latex_engine: xelatex --- 注：介个模板用上了大微软的雅黑字体，如若想修改，那请继续摸索摸索。（T.T累了不想改了~）\n搞定！Over！愿你的探索之路不与我一样艰辛((٩(//̀Д/́/)۶))\n课外补充：\n 关于Rmarkdown to pdf的美好世界\n如果你也被这样的问题所困扰，那么你会发现R界的大佬谢益辉搞了个包叫rticles，直接提供template给你写中文文档。然而，无奈Tex世界的混乱，还是遇到奇奇怪怪的乱七八糟的问题，但是大佬说大家用TinyTex吧，那将提供Rmarkdown to pdf的一片美好世界。  ","tags":["Rmarkdown"],"title":"关于Rmarkdown生成中文内容pdf的那些事","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":"\rIntroduction\rWe assume the observed variable \\(x\\) is a random sample from an unknown underlying process, whose true distribution \\(p^*(x)\\) is unknown. We attempt to approximate this underlying process with a chosen model \\(p_{\\theta}(x)\\), with parameters \\(\\theta\\): \\[x\\sim p_{\\theta}(x)\\] We always talk about learning like Deep Learning, and actually the learning is the process of searching for a value of the parameters \\(\\theta\\) in model \\(p_{\\theta}(x)\\), which can approximate the true distribution of the data, denoted by \\(p^*(x)\\). In other words, \\[p_{\\theta}(x)\\approx p^*(x)\\] Latent variables are variables that are part of the model, but which we don’t observe, and are therefore not part of the dataset. We typically use \\(z\\) to denote such latent variables.\nThe marginal distribution over the observed variables \\(p_{\\theta}(x)\\), is given by: \\[\rp_{\\theta}(x) = \\int p_{\\theta}(x,z) dz = \\int p_{\\theta}(z) p_{\\theta}(x|z) dz\r\\] We use the term deep latent variable model (DLVM) to denote a latent variable model \\(p_{\\theta}(x,z)\\) whose distributions are parameterized by neural networks.\nExample DLVM for multivariate Bernoulli data\rA simple example DLVM for binary data \\(x\\), with a spherical Gaussian latent space, and a factorized Bernoulli obervation model \\[\rp(z) = \\mathcal{N}(0,\\text{I})\\\\\r\\text{p} = \\text{DecoderNeuralNet}_{\\theta}(z)\\\\\r\\begin{align}\r\\log p(x|z) =\u0026amp; \\sum_{j=1}^J \\log p(x_j|z) = \\sum_{j=1}^J \\text{Bernoulli}(x_j,p_j)\\\\\r=\u0026amp; \\sum_{j=1}^Jx_j \\log p_j + (1-x_j)\\log (1-p_j)\r\\end{align}\r\\] where \\(0\\leq p_j\\leq 1\\).\nTherefore, we easily get \\(p(x,z) = p(x|z)\\times p(z)\\) by the term we described above.\n\rSome problem\rNote that \\(p_{\\theta}(x,z)\\) is efficient to compute. Since the intractability of \\(p_{\\theta}(x)\\) (\\(p_{\\theta}(x) = \\int p_{\\theta}(x,z) dz\\)), the posterior distribution \\(p_{\\theta}(z|x)\\) is also intractable, because their densities are related through the basic identity: \\[p_{\\theta}(z|x) = \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)}\\]\nHow can we perform efficient approximate posterior inference and efficient approximate maximum likelihood estimation in deep latent variable models, in the presence of large datasets?\n\rSimilar method like DLVM\rWe introduce a parametric inference model \\(q_{\\phi}(z|x)\\) (also called as encoder)in this part and we try to optimize the variational parameters \\(\\phi\\) such that: \\[q_{\\phi}(z|x) \\approx p_{\\theta}(z|x)\\]\nSimilar to DLVM, the distribution of \\(q_{\\phi}(z|x)\\) also can be parameterized using deep neural networks. In this case, the variational parameters \\(\\phi\\) include the weights and biases of the neural network. For example: \\[\r(\\mu,\\sigma) = \\text{EncoderNeuralNet}_{\\phi}(x)\\\\\rq_{\\phi}(z|x) = \\mathcal{N}(\\mu,\\text{diag}(\\sigma^2))\r\\]\n\r\rEvidence lower bound (ELBO) and KL divergence\rThe optimization objective of the variational autoencoder is the evidence lower bound, abbreviated as ELBO. An alternative term for this objective is variational lower bound. We can obtain the lower bound by: \\[\r\\begin{align}\r\\log p_{\\theta}(x) =\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x)}[\\log p_{\\theta}(x)] = \\mathbb{E}_{q_{\\phi}(z|x)} \\Big[\\log\\Big[ \\frac{p_{\\theta}(x,z)}{p_{\\theta}(z|x)}\\Big]\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x)}\\Big[\\log\\Big[\\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)}\\frac{q_{\\phi}(z|x)}{p_{\\theta}(z|x)}\\Big]\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x)}\\Big[\\log\\Big[\\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)}\\Big]\\Big] + \\mathbb{E}_{q_{\\phi}(z|x)}\\Big[\\log\\Big[\\frac{q_{\\phi}(z|x)}{p_{\\theta}(z|x)}\\Big]\\Big]\\\\\r=\u0026amp;\\ \\mathcal{L}_{\\theta,\\phi}(x) + KL[q_{\\phi}(z|x)||p_{\\theta}(z|x)]\\\\\r\\geq\u0026amp;\\ \\mathcal{L}_{\\theta,\\phi}(x)\r\\end{align}\r\\]\nKL divergence\rWe want to find a good probability distribution \\(q_{\\phi}(z|x)\\) (‘good’ means the efficient computation) to approximate the true posterior probability \\(p_{\\theta}(z|x)\\), where the \\(z\\) is the latent variable. KL divergence can measure the distance well between these two distribution. For the discrete probability situation, the KL divergence can be written as \\[KL(q||p) = \\sum q(x)\\log \\frac{q(x)}{p(x)}\\]\nExample of 1-dimension Guassian distribution\rSupposed that we have two random variables \\(x_1, x_2\\) w.r.t the guassian distribution \\(\\mathcal{N}(\\mu_1,\\sigma_1^2),\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) respectively.\nRecall that the density function of guassian distribution \\[\r\\mathcal{N}(\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\r\\] Then \\[\r\\begin{align}\rKL(p_1,p_2) =\u0026amp;\\ \\int p_1(x)\\log \\frac{p_1(x)}{p_2(x)}dx\\\\\r=\u0026amp;\\ \\int p_1(x)(\\log p_1(x) - \\log p_2(x))dx\\\\\r=\u0026amp;\\ \\int p_1(x)(\\log \\frac{1}{\\sqrt{2\\pi\\sigma_1^2}}e^{-\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}} - \\log \\frac{1}{\\sqrt{2\\pi\\sigma_2^2}}e^{-\\frac{(x-\\mu_2)^2}{2\\sigma_2^2}})dx\\\\\r=\u0026amp;\\ \\int p_1(x)(-\\log \\sqrt{2\\pi \\sigma_1^2} - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2} + \\log \\sqrt{2\\pi \\sigma_2^2} + \\frac{(x-\\mu_2)^2}{2\\sigma_2^2})dx\\\\\r=\u0026amp;\\ \\int p_1(x)(-\\frac{1}{2}\\log2\\pi-\\log\\sigma_1+\\frac{1}{2}\\log2\\pi+\\log\\sigma_2 - (\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}-\\frac{(x-\\mu_2)^2}{2\\sigma_2^2}))dx\\\\\r=\u0026amp;\\ \\int p_1(x)(\\log\\frac{\\sigma_2}{\\sigma_1} - (\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}-\\frac{(x-\\mu_2)^2}{2\\sigma_2^2}))dx\\\\\r=\u0026amp;\\ \\int p_1(x)(\\log\\frac{\\sigma_2}{\\sigma_1})dx + \\int p_1(x)(\\frac{(x-\\mu_2)^2}{2\\sigma_2^2})dx - \\int p_1(x)(\\frac{(x-\\mu_1)^2}{2\\sigma_1^2})dx\\\\\r=\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{1}{2\\sigma_2^2}\\int p_1(x)(x-\\mu_2)^2dx - \\frac{1}{2\\sigma_1^2}\\int p_1(x)(x-\\mu_1)^2dx\r\\end{align}\r\\] Since \\(\\sigma^2 = \\int p_1(x)(x-\\mu_1)^2dx\\), then \\[\r\\begin{align}\rKL(p_1,p_2) =\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{1}{2\\sigma_2^2}\\int p_1(x)(x-\\mu_2)^2dx - \\frac{1}{2}\\\\\r=\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{1}{2\\sigma_2^2}\\int p_1(x)(x - \\mu_1 + \\mu_1 - \\mu_2)^2dx - \\frac{1}{2}\\\\\r=\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{1}{2\\sigma_2^2}[\\int p_1(x)(x-\\mu_1)^2dx+\\int p_1(x)(\\mu_1-\\mu_2)^2dx+2\\int p_1(x)(x-\\mu_1)(\\mu_1-\\mu_2)dx] - \\frac{1}{2}\\\\\r\\end{align}\r\\] We know that \\(\\mu_1 = \\int x p_1(x)dx\\), so \\(2\\int p_1(x)(x-\\mu_1)(\\mu_1-\\mu_2)dx = 2(\\mu_1-\\mu_2)[\\int xp_1(x)dx - \\mu_1] = 0\\), thus \\[\r\\begin{align}\rKL(p_1,p_2) =\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{1}{2\\sigma_2^2}[\\int p_1(x)(x-\\mu_1)^2dx + (\\mu_1-\\mu_2)^2] - \\frac{1}{2}\\\\\r=\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2+(\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}\\\\\r\\end{align}\r\\] If we suppose that the \\(\\mathcal{N}(\\mu_2,\\sigma_2^2)\\) is standard guassian distribution, \\(\\mu_2 = 0, \\sigma_2^2 = 1\\), so \\[\r\\begin{align}\rKL =\u0026amp;\\ \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2+(\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}\\\\\r=\u0026amp;\\ \\log1 - \\log\\sigma_1 + \\frac{\\sigma_1^2+(\\mu_1 - 0)^2}{2} - \\frac{1}{2}\\\\\r=\u0026amp;\\ -\\log\\sigma_1 + \\frac{\\sigma_1^2+\\mu_1^2}{2} - \\frac{1}{2}\\\\\r\\end{align}\r\\] We expect that the KL can be as small as possible, we calculate its derivative, then we get \\[\r\\frac{\\partial KL}{\\partial \\sigma_1} = -\\frac{1}{\\sigma_1} + \\sigma_1\\\\\r\\frac{\\partial KL}{\\partial \\mu_1} = \\mu_1\r\\] We let them equal to zero, then we get \\[\r-\\frac{1}{\\sigma_1} + \\sigma_1 = 0 \\Rightarrow \\sigma_1 = 1\\\\\r\\mu_1 = 0\r\\] which means that the KL becomes the minimum when \\(x_2 \\sim \\mathcal{N}(0,1)\\)\n\rMinimization of KL divergence\rIf we want to use the ELBO to approximate the log-likelihood, then we need to minimize the \\(D_{KL}[q_{\\phi}(z|x)||p_{\\theta}(z|x)]\\).\nFrom \\[\r\\begin{align}\rKL[q_{\\phi}(z|x)||p_{\\theta}(z|x)] =\u0026amp;\\ \\int q_{\\phi}(z|x) \\log \\frac{q_{\\phi}(z|x)}{p_{\\theta}(z|x)} dz\\\\\r=\u0026amp;\\ \\int q_{\\phi}(z|x) [\\log q_{\\phi}(z|x) - \\log p_{\\theta}(z|x)]dz\r\\end{align}\r\\] and Bayesian formula \\[\rp_{\\theta}(z|x) = \\frac{p_{\\theta}(x|z)*p_{\\theta}(z)}{p_{\\theta}(x)}\r\\] We can get \\[\r\\begin{align}\rKL[q_{\\phi}(z|x)||p_{\\theta}(z|x)] =\u0026amp;\\ \\int q_{\\phi}(z|x) [\\log q_{\\phi}(z|x) - \\log \\frac{p_{\\theta}(x|z)*p_{\\theta}(z)}{p_{\\theta}(x)}]dz\\\\\r=\u0026amp;\\ \\int q_{\\phi}(z|x) [\\log q_{\\phi}(z|x) -\\log p_{\\theta}(x|z) - \\log p_{\\theta}(z) + \\log p_{\\theta}(x)]dz\\\\\r=\u0026amp;\\ \\int q_{\\phi}(z|x) [\\log q_{\\phi}(z|x) -\\log p_{\\theta}(x|z) - \\log p_{\\theta}(z)]dz + \\log p_{\\theta}(x)\\\\\r=\u0026amp;\\ KL[q_{\\phi}(z|x)||p_{\\theta}(z)] - \\int q_{\\phi}(z|x) \\log p_{\\theta}(x|z)dz + \\log p_{\\theta}(x)\r\\end{align}\r\\]\nWhen the data \\(x\\) are provided, then last term in the right side \\(\\log p_{\\theta}(x)\\) becomes constant, and we wish the \\(D_{KL}[q_{\\phi}(z|x)||p_{\\theta}(z|x)]\\) can be as small as possible.\nThus, the optimization problem becomes\n\r\\(\\min\\limits_x D_{KL}[q_{\\phi}(z|x)||p_{\\theta}(z)]\\)\n\r\\(\\max\\limits_x \\int q_{\\phi}(z|x) \\log p_{\\theta}(x|z)dz\\)\n\r\rIt also can be written as \\[\\min_x KL[q_{\\phi}(z|x)||p_{\\theta}(z)] - \\mathbb{E}_{q_{\\phi}(z|x)}[\\log p_{\\theta}(x|z)]\\]\nAlthough we can obtain our new optimization problem, the problem actually is difficult to solve, and thus we would like to straightly optimize the ELBO.\n\r\r\rVariational Auto-Encoder\rConnection with EM\rFor standard EM algorithms, the posterior is often known, \\(q_{\\phi}(z|x) = q(z|x) = p_{\\theta}(z|x)\\), then the KL term becomes zero, so \\[\r\\begin{align}\r\\log p_{\\theta}(x) = \\mathcal{L}_{\\theta}(x) =\u0026amp;\\ \\mathbb{E}_{q(z|x)}\\Big[\\log\\Big[\\frac{p_{\\theta}(x,z)}{q(z|x)}\\Big]\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q(z|x)}[\\log p_{\\theta}(x,z)] - \\mathbb{E}_{q(z|x)}[\\log q(z|x)]\r\\end{align}\r\\]\nThe above step is indeed the E-step in the standard EM algorithm. The M-step would be \\[\\theta_{\\text{new}} = \\arg \\max_\\theta L_{\\theta}(x)\\]\n\rStochastic gradient-based optimization of the ELBO\rFrom the Evidence lower bound (ELBO) part, we obtain the inequality fomula as \\(\\log p_{\\theta}(x) \\geq \\mathcal{L}_{\\theta,\\phi}(x)\\). Recall that EM algorithm is one of the special case of Minorize-Maximization (MM) algorithm, and \\(\\mathcal{L}_{\\theta,\\phi}(x)\\) can be considered as the surrogate function in MM algorithm, so we would get the maximum of log-likelihood by maximizing the lower bound.\n\rFigure1. The EM algorithm involves alternatel computing a lower bound on the log likelihood for the current parameter values and then maximizing this bound to obtain the new parameter values.\r\rGiven a dataset with i.i.d. data, the ELBO objective is the sum (or average) of individual-datapoint ELBO’s: \\[\r\\mathcal{L}_{\\theta,\\phi}(\\mathcal{D})=\\sum_{x\\in\\mathcal{D}}\\mathcal{L}_{\\theta,\\phi}(x)\r\\]\nApparantly, the individual-datapoint ELBO and its gradient \\(\\nabla_{\\theta,\\phi}\\mathcal{L}_{\\theta,\\phi}(x)\\) is intractable in general.\nThe SGVB estimator and Auto-Encoding VB (AEVB) algorithm\rReparamterization trick\nLet \\(z\\) be a continuous random variable and \\(z\\sim q_{\\phi}(z|x)\\) be some conditional distribution. It is often possible to express the random variable \\(z\\) as a deterministic variable \\(z=g_{\\phi}(\\epsilon,x)\\), where \\(\\epsilon\\) is an auxiliary variable with independent marginal \\(p(\\epsilon)\\).\nWe suppose that the recognition model \\(q_{\\phi}(z|x)\\) can be written as some differentiable transformation of another randome variable \\(\\epsilon\\), \\(g_{\\phi}(\\epsilon,x)\\), and we can form a simple Monte Carlo estimator \\(\\tilde{\\mathcal{L}}_{\\theta,\\phi}(x)\\) of the individual-datapoint ELBO: \\[\r\\epsilon \\sim p(\\epsilon)\r\\]\nso we can get our generic Stochastic Gradient Variational Bayes (SGVB) estimator from the lower bound \\[\r\\tilde{\\mathcal{L}}_{\\theta,\\phi}^{A}(x^{(i)}) = \\frac{1}{L}\\sum_{l=1}^L[\\log p_{\\theta}(x^{(i)},z^{(i,l)}) - \\log q_{\\phi}(z^{(i,l)}|x^{(i)})]\r\\] where \\(z^{(i,l)} = g_{\\phi}(\\epsilon^{(i,l)},x^{(i)}),\\quad \\epsilon^{(i,l)} \\sim p(\\epsilon)\\).\nWe try to decompose the \\(\\mathcal{L}_{\\theta,\\phi}(x)\\), and we get \\[\r\\begin{align}\r\\mathcal{L}_{\\theta,\\phi}(x^{(i)}) =\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x^{(i)})}\\Big[\\log\\frac{p_{\\theta}(x^{(i)},z)}{q_{\\phi}(z|x^{(i)})}\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x^{(i)})}\\Big[\\log\\frac{p_{\\theta}(x^{(i)}|z)p_{\\theta}(z)}{q_{\\phi}(z|x^{(i)})}\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x^{(i)})}\\Big[\\log p_{\\theta}(x^{(i)}|z)-\\log\\frac{q_{\\phi}(z|x^{(i)})}{p_{\\theta}(z)}\\Big]\\\\\r=\u0026amp;\\ \\mathbb{E}_{q_{\\phi}(z|x^{(i)})}[\\log p_{\\theta}(x^{(i)}|z)]-KL[q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)]\r\\end{align}\r\\] The final equality showed the same object result (In Minimization of KL divergence section).\nWith this equality, we also can obtain another estimator \\[\r\\tilde{\\mathcal{L}}_{\\theta,\\phi}^{B}(x^{(i)}) = \\mathbb{E}_{q_{\\phi}(z|x^{(i)})}[\\log p_{\\theta}(x^{(i)}|z)]-KL[q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)]\\\\\r=\\frac{1}{L}\\sum_{l=1}^L\\log p_{\\theta}(x^{(i)}|z^{(i,l)})-KL[q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)]\r\\] where \\(z^{(i,l)} = g_{\\phi}(\\epsilon^{(i,l)},x^{(i)}),\\quad \\epsilon^{(i,l)} \\sim p(\\epsilon)\\). Given multiple datapoints from a dataset \\(\\text{X}\\) with \\(N\\) datapoints, we can construct an estimator of the marginal likelihood lower bound of the full dataset, based on minibatches: \\[\r\\mathcal{L}_{\\theta,\\phi}(\\text{X})\\simeq\\tilde{\\mathcal{L}}_{\\theta,\\phi}^{M}(\\text{X}^M)=\\frac{N}{M}\\sum_{i=1}^M\\tilde{\\mathcal{L}}_{\\theta,\\phi}(x^{(i)})\r\\] where the minibatch \\(\\text{X}^M=\\{x^{(i)}\\}_{i=1}^M\\) is randomly drawn sample of \\(M\\) datapoints from the full dataset \\(\\text{X}\\) with \\(N\\) datapoints. In the paper Auto-Encoding Variational Bayes, author set \\(M = 100, L = 1\\) in their experiments.\n\r\r\rVariational Auto-Encoder with specific case\rWe know that we can not perform the algorithm that we describe above, because we don’t know the distributions of \\(\\epsilon, p_{\\theta}(x|z), q_{\\phi}(z|x), p_{\\theta}(z)\\) and \\(g_{\\phi}(\\epsilon,x)\\). In reality, like author described in the paper, we firstly let the prior over the latent variables be the centered isotropic multivariate Guassian \\(p_{\\theta}(z) = \\mathcal{N}(0,\\text{I})\\).\nVariational approxiamte posterior \\(q_{\\phi}(z|x^{(i)})\\)\rLet the variational approxiamte posterior be a multivariate Guassian with a diagonal covariance structure: \\[\rq_{\\phi}(z|x^{(i)}) = \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\r\\] where \\(\\mu^{(i)},\\sigma^{(i)}\\) denote the variational mean and s.d. evaluated by datapoint \\(i\\).\nThen a valid reparameterization is \\(z=\\mu+\\sigma\\epsilon\\), where \\(\\epsilon\\) is an auxiliary noise variable \\(\\epsilon\\sim \\mathcal{N}(0,\\text{I})\\).\nLet \\(J\\) be the dimensionality of \\(z\\) and \\(\\mu^{(i)}_j, \\sigma^{(i)}_j\\) denote the \\(j\\)-th element. Recall that \\[\r\\mathbb{E}[z] = \\int z p(z) dz\\\\\r\\mathbb{E}[z^2] = \\int z^2 p(z) dz\\\\\r\\text{Var}[z] = \\mathbb{E}[z^2] - \\mathbb{E}^2[z]\r\\] Then, \\[\r\\begin{align}\r\\int q_{\\phi}(z|x^{(i)})\\log p_{\\theta}(z)dz =\u0026amp;\\ \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\\log \\mathcal{N}(0,\\text{I})dz\\\\\r=\u0026amp;\\ \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})(\\log \\frac{1}{\\sqrt{2\\pi}})dz - \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I}) \\frac{z^2}{2}dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi)\\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})dz - \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I}) \\frac{z^2}{2}dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\int z^2 \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J\\mathbb{E}_{ q_{\\phi}(z_j|x^{(i)})}[z_j^2]\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J\\Big[\\mathbb{E}_{ q_{\\phi}(z_j|x^{(i)})}^2[z_j]+\\text{Var}_{ q_{\\phi}(z_j|x^{(i)})}[z_j]\\Big]\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J(\\mu_j^2+\\sigma_j^2)\r\\end{align}\r\\] and \\[\r\\begin{align}\r\\int q_{\\phi}(z|x^{(i)})\\log q_{\\phi}(z|x^{(i)})dz =\u0026amp;\\ \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\\log \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})dz\\\\\r=\u0026amp;\\ \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\\log \\Big[\\frac{1}{\\sqrt{2\\pi\\sigma^{(i)^2}}}\\exp(\\frac{-(z-\\mu^{(i)})^2}{2\\sigma^{(i)^2}})\\Big]dz\\\\\r=\u0026amp;\\ \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\\Big[-\\frac{1}{2}\\log 2\\pi - \\frac{1}{2}\\log \\sigma^{(i)^2} - \\frac{(z-\\mu^{(i)})^2}{2\\sigma^{(i)^2}}\\Big]dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})\\Big[\\frac{\\log \\sigma^{(i)^2}}{2} - \\frac{(z-\\mu^{(i)})^2}{2\\sigma^{(i)^2}}\\Big]dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\int \\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I}) \\Big[\\frac{1}{2}\\log \\sigma^{(i)^2} - \\frac{z^2-2\\mu^{(i)}z+\\mu^{(i)^2}}{2\\sigma^{(i)^2}}\\Big]dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{J=1}^J\\log \\sigma_j^{(i)^2} + \\int \\frac{1}{2\\sigma^{(i)^2}}\\mathcal{N}(\\mu^{(i)},\\sigma^{(i)^2}\\text{I})(z^2-2\\mu^{(i)}z+\\mu^{(i)^2})dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J\\log \\sigma_j^{(i)^2} + \\frac{1}{2}\\sum_{j=1}^J\\frac{\\mu^{(i)^2}+\\sigma^{(i)^2}-2\\mu^{(i)^2}+\\mu^{(i)^2}}{\\sigma^{(i)^2}}\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J(1+\\log \\sigma_j^{(i)^2})\r\\end{align}\r\\] Therefore, \\[\r\\begin{align}\r-KL[q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)] =\u0026amp; - \\int q_{\\phi}(z|x^{(i)})\\log \\frac{q_{\\phi}(z|x^{(i)})}{p_{\\theta}(z)}dz\\\\\r=\u0026amp;\\ - \\int q_{\\phi}(z|x^{(i)})[\\log q_{\\phi}(z|x^{(i)}) - \\log p_{\\theta}(z)]dz\\\\\r=\u0026amp;\\ \\int q_{\\phi}(z|x^{(i)})[\\log p_{\\theta}(z) - \\log q_{\\phi}(z|x^{(i)})]dz\\\\\r=\u0026amp;\\ -\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J(\\mu_j^2+\\sigma_j^2) - \\Big[-\\frac{J}{2}\\log(2\\pi) - \\frac{1}{2}\\sum_{j=1}^J(1+\\log \\sigma_j^{(i)^2})\\Big]\\\\\r=\u0026amp;\\ \\frac{1}{2}\\sum_{j=1}^J(1+\\log \\sigma_j^{(i)^2}-\\mu_j^2-\\sigma_j^2)\r\\end{align}\r\\]\n\rTrue posterior \\(p_{\\theta}(x|z)\\)\rWe supposed that the true posterior \\(p_{\\theta}(x|z)\\) be a multivariate Gaussian (in case of real-valued data) or Bernoulli (in case of binary data) whose distribution parameters are computed from \\(z\\) with a MLP (Multi-Layer Perceptron).\nBernoulli MLP as decoder\nIf the data are binary data, then we would choose \\[\r\\log p_{\\theta}(x|z) = \\sum_{j=1}^Dx_j \\log y_j + (1-x_j)\\log (1-y_j)\r\\] where \\(y = f_\\sigma(W_2\\tanh(W_1z+b_1)+b_2)\\), \\(f_\\sigma(\\cdot)\\) is the elementwise sigmoid activation function and \\(\\theta=\\{W_1,W_2,b_1,b_2\\}\\) are the weights and biases of the MLP.\nGaussian MLP as decoder\nLet decoder be a mutivariate Guassian with a diagonal covariance structure: \\[\r\\log p_{\\theta}(x|z) = \\log \\mathcal{N}(\\mu,\\sigma^2\\text{I})\r\\] where \\(\\mu = W_4h+b_4,\\ \\log\\sigma^2 = W_5h+b_5,\\ h = \\tanh(W_3Z+b_3)\\) and \\(\\{W_3,W_4,W_5,b_3,b_4,b_5\\}\\) are the weights and biases of the MLP and part of \\(\\theta\\).\nAnalysis in case of binary data\nRecall the second estimator we describe above \\[\r\\begin{align}\r\\mathcal{L}_{\\theta,\\phi}(\\text{X})\\simeq\u0026amp;\\ \\tilde{\\mathcal{L}}_{\\theta,\\phi}^{B}(x^{(i)})\\\\\r=\u0026amp;\\ \\frac{1}{L}\\sum_{l=1}^L\\log p_{\\theta}(x^{(i)}|z^{(i,l)}) - KL[q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)]\\\\\r=\u0026amp;\\ \\frac{1}{L}\\sum_{l=1}^L\\log p_{\\theta}(x^{(i)}|z^{(i,l)}) + \\frac{1}{2}\\sum_{j=1}^J(1+\\log \\sigma_j^{(i)^2}-\\mu_j^2-\\sigma_j^2)\r\\end{align}\r\\] where \\(z^{(i,l)} = \\mu^{(i)} + \\sigma^{(i)}\\epsilon^{(l)}, \\epsilon^{l}\\sim p(\\epsilon)\\) and \\(\\log p_{\\theta}(x|z) = \\sum_{j=1}^Dx_j \\log y_j + (1-x_j)\\log (1-y_j)\\).\n\r\r\rUsing Variational Auto-Encoder in python\rImport packages\rimport numpy as np\rimport matplotlib.pyplot as plt\rimport tensorflow as tf\rfrom tensorflow.examples.tutorials.mnist import input_data\r\rFunction for visualizing batch images\rdef VisConcatImg(batch_images, title):\rbatch_size = np.shape(batch_images)[0]\rsqrt_size = int(batch_size ** 0.5)\rbatch_images = batch_images.reshape(batch_size, 28, 28)\rrow_concatenated = [np.concatenate(batch_images[i*sqrt_size : (i+1)*sqrt_size], axis=1) for i in range(sqrt_size)]\rconcatenated = np.concatenate(row_concatenated, axis=0)\rplt.imshow(concatenated, cmap=\u0026#39;gray\u0026#39;)\rplt.title(title)\rplt.axis(\u0026#39;off\u0026#39;)\rplt.show()\r\rMNIST Dataset\rThe MNIST includes 60000 training samples and 10000 testing samples. Each sample is a 784-dimensional vector (28??28), with pixel values in [0, 1], which can be assumed as multivariate Bernoulli variables.\n# Downloading MNIST dataset\rmnist = input_data.read_data_sets(\u0026#39;./mnist\u0026#39;, one_hot=False)\r# VAE for MNIST\rclass VAE(object):\rdef __init__(self, x_size=28*28, hidden1_size=100, hidden2_size=400, hidden3_size=100, hidden4_size=400, z_size=20, learning_rate=1e-4):\rself.x_size = x_size\rself.hidden1_size = hidden1_size\rself.hidden2_size = hidden2_size\rself.hidden3_size = hidden3_size\rself.hidden4_size = hidden4_size\rself.z_size = z_size\rself.learning_rate = learning_rate\rself.x = tf.placeholder(tf.float32, [None, x_size])\rself.epsilon = tf.placeholder(tf.float32, [None, z_size]) # sample from N(0,1) for every step\rwith tf.variable_scope(\u0026#39;encoder\u0026#39;):\rself.encoder()\rwith tf.variable_scope(\u0026#39;decoder\u0026#39;):\rself.decoder()\rwith tf.variable_scope(\u0026#39;loss\u0026#39;):\rself.compute_loss()\rwith tf.variable_scope(\u0026#39;train\u0026#39;):\rself.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.total_loss)\rdef encoder(self):\rself.hidden1 = tf.layers.dense(self.x, units=self.hidden1_size, activation=tf.nn.relu)\rself.hidden2 = tf.layers.dense(self.hidden1, units=self.hidden2_size, activation=tf.nn.relu)\rself.mu = tf.layers.dense(self.hidden2, units=self.z_size)\rself.sigma = tf.layers.dense(self.hidden2, units=self.z_size, activation=tf.exp)\rself.z = tf.add(self.mu, tf.multiply(self.epsilon, self.sigma))\rdef decoder(self):\rself.hidden3 = tf.layers.dense(self.z, units=self.hidden3_size, activation=tf.nn.relu)\rself.hidden4 = tf.layers.dense(self.hidden3, units=self.hidden4_size, activation=tf.nn.relu)\rself.y = tf.layers.dense(self.hidden4, units=self.x_size, activation=tf.nn.sigmoid)\r# adding 1e-8 before taking the logarithm to avoid numerical instability.\rdef compute_loss(self):\rself.recons_loss = tf.reduce_mean(tf.reduce_sum(-(self.x * tf.log(self.y + 1e-8) + (1 - self.x) * tf.log(1 - self.y + 1e-8)), 1))\rself.KL_loss = tf.reduce_mean(-0.5 * tf.reduce_sum(1 + 2 * tf.log(self.sigma + 1e-8) - tf.square(self.mu) - tf.square(self.sigma), 1))\rself.total_loss = self.recons_loss + self.KL_loss\r# Training VAE\rmodel = VAE()\rBATCH_SIZE = 100\rEPOCHS = 50\rSTEPS = int(60000 / BATCH_SIZE)\rsess = tf.Session()\rsess.run(tf.global_variables_initializer())\rfor e in range(EPOCHS):\rfor i in range(STEPS):\rtrain_data, _ = mnist.train.next_batch(batch_size=BATCH_SIZE)\rep = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=BATCH_SIZE)\rsess.run(model.train_op, feed_dict={model.x: train_data, model.epsilon: ep})\rREloss, KLloss, Tloss = sess.run([model.recons_loss, model.KL_loss, model.total_loss], feed_dict={model.x: train_data, model.epsilon: ep})\rprint(\u0026#39;Epoch: \u0026#39;, e, \u0026#39;| reconstruction loss: \u0026#39;, REloss, \u0026#39;| KL loss:\u0026#39;, KLloss, \u0026#39;| total loss: \u0026#39;, Tloss)\r# Visualizing results\rtest_data, _ = mnist.test.next_batch(batch_size=50)\rVisConcatImg(test_data, \u0026#39;raw images\u0026#39;)\rep = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=50)\rlatent, recons_x = sess.run([model.mu, model.y], feed_dict={model.x: test_data, model.epsilon: ep})\rVisConcatImg(recons_x, \u0026#39;reconstructed images\u0026#39;)\rrandoms = np.random.multivariate_normal(np.zeros(model.z_size), np.eye(model.z_size), size=50)\rgenerated_x = sess.run(model.y, feed_dict={model.z: randoms})\rVisConcatImg(generated_x, \u0026#39;generated images\u0026#39;)\rsess.close()\r\rResult\r\rFigure3. Raw Images\r\r\rFigure4. Reconstructed Images\r\r\rFigure5. Generated Images\r\r\r\rReference\rD. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2014. 5, 1\rYang Can. VAE_demo in python. 2018,12,31\r\r\r","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"364d7cb43b7ce5560d8689197bd08d27","permalink":"/post/variational-auto-encoder/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/post/variational-auto-encoder/","section":"post","summary":"Introduction\rWe assume the observed variable \\(x\\) is a random sample from an unknown underlying process, whose true distribution \\(p^*(x)\\) is unknown. We attempt to approximate this underlying process with a chosen model \\(p_{\\theta}(x)\\), with parameters \\(\\theta\\): \\[x\\sim p_{\\theta}(x)\\] We always talk about learning like Deep Learning, and actually the learning is the process of searching for a value of the parameters \\(\\theta\\) in model \\(p_{\\theta}(x)\\), which can approximate the true distribution of the data, denoted by \\(p^*(x)\\).","tags":["TensorFlow","VAE"],"title":"Variational Auto-Encoder","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":" 迈出TensorFlow世界的第一步 安装TensorFlow 鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议你跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 Anaconda，快捷高效，下载引导详见图1。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！\n 图1. 下载Anaconda  设置水土不服的Anaconda 首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过conda --version看看是否成功安装了Anaconda。一般会得到版本信息，如下所示\nconda 4.5.12 那么，Anaconda安装成功！\n下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes  创建python3.5环境 首先，由于目前TensoFlow官方Only支持python3.5版本，而且在写本文的这个时候，Anaconda官方最新版本中的python是3.7版本，所以我们需要创建一个python3.5的新环境。\n首先在系统菜单栏找到并点击Anaconda Navigator，然后选择Enviroments（如图2所示），然后点击Create创建新环境：\n 图2. Environments界面  我们命名为tensorflow，并选择python3.5的版本：\n 图3. 创建新环境窗口  安装成功后，Environments界面多了一个我们创建的命名为tensorflow的python3.5的环境，并自动预先安装一些基础的库。\n 图4. 安装成功后的python3.5环境  搞定python3.5的环境后，我们顺便在python3.5环境下安装常用的jupyter notebook和spyder。先选择Home界面，然后可以看到jupyter notebook和spyder下方均显示Install，当然就点击Install，就等着Anaconda Navigator帮我们搞定啦！安装成功后，它们下方会变成Launch（如图5所示）。\n 图5. 安装jupyter和spyder成功后的Home界面  如果要在Anaconda prompt界面启动python3.5环境，很简单，一行命令！\nconda activate tensorflow 这里的tensorflow其实是我们的python3.5环境的命名~\n 通过pip安装我们的主角TensorFlow ٩(๑\u0026gt; ₃ \u0026lt;)۶з 搞定一切基础的部分后，接下来就开始用pip安装我们TensorFlow的CPU版本了~我们先激活python3.5的环境并用pip安装tensorflow\nconda activate tensorflow pip install tensorflow 旋转跳跃~闭着眼~睁开眼后就搞定了你要的TensorFlow (●´▽｀●) 下面我们先测试一下，在激活python3.5之后，输入python运行python，然后输入下面的命令。\nimport tensorflow as tf hello = tf.constant(\u0026#39;Hello, TensorFlow!\u0026#39;) sess = tf.Session() print(sess.run(hello)) a = tf.constant(1) b = tf.constant(2) c = sess.run(a+b) print(\u0026quot;1 + 2 = %d\u0026quot; % c) 如果输出了\n‘Hello, TensorFlow!’\n1 + 2 = 3\n那么恭喜你，TensorFlow安装成功！！\nAttention!\n CPU有个利器(๑•̀_•́๑)\n当我使用sess = tf.Session()的时候，对话框告诉我：\n2018-12-26 15:03:57.708274: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n然后一脸懵，杰是个啥？\n感恩必应搜索，感恩维基百科！\n 高级矢量扩展（AVX）是英特尔在2008年3月提出的英特尔和AMD微处理器的x86指令集体系结构的扩展，英特尔首先通过Sandy Bridge处理器在2011年第一季度推出，随后由AMD推出Bulldozer处理器在2011年第三季度.AVX提供了新功能，新指令和新编码方案。 特别是，AVX引入了融合乘法累加（FMA）操作，加速了线性代数计算，即点积，矩阵乘法，卷积等。几乎所有机器学习训练都涉及大量这些操作，因此将会支持AVX和FMA的CPU（最高达300％）更快。\n 而对话框想告诉我，我的CPU支持AVX，让我赶紧用上它！\nimport tensorflow as tf import os os.environ[\u0026#39;TF_CPP_MIN_LOG_LEVEL\u0026#39;] = \u0026#39;2\u0026#39; sess = tf.Session() 这样就不会出现警告了~\n 目前觉得不重要的part(๑•̀_•́๑)\n查看Windows系统下机器的GPU信息\n首先打开“运行”对话框并在“运行”对话框中输入“dxdiag”（如图6），此时会打开“DirextX诊断工具”窗口，再通过选择“显示”标签便可查到机器的GPU信息（如图7）。\n   图6. 输入dxdiag命令   图7. 查看机器GPU信息  简单提及安装GPU版本TensorFlow\n如果你觉得运行的速度不满足你的需求，那么你可以选择用上GPU版本的TensorFlow，那将帮助你火箭般的速度运行！下面简单带过如何安装TensorFlow的GPU版本~由于具体操作复杂，暂且跳过~\npip install tensorflow-gpu —— —— —— —— —— —— —— 这是一条分割线 —— —— —— —— —— —— ——\n上面操作呢…有时候jupyter和spyder会出现一些路径的问题_(:з」∠)_\n所以我还是直接下载带Python3.5的Anaconda吧~\n点击上面Anaconda即可下载(..•˘_˘•..)\n—— —— —— —— —— —— —— 这是另一条分割线 —— —— —— —— —— —— ——\n下载Python3.5的Anaconda可能也有乱七八糟的错误_(:з」∠)_\n所以直接稳妥的方法就是用Anaconda prompt执行下面的命令~\nconda create --name python35 python=3.5 安装完成后会提示你\n# To activate this environment, use # # $ conda activate python35 # # To deactivate an active environment, use # # $ conda deactivate 接着先激活python3.5的环境，就可以用pip安装tensorflow\nconda activate python35 pip install tensorflow Jupyter下设置python3.5的内核\n如果不做一些设置操作，默认Jupyter打开还是会以默认Anaconda下的python版本，由于目前已经到了python3.7的版本了，那在Jupyter下使用Tensorflow必定会出问题。\n首先打开Anaconda Prompt并安装ipykernel：\npip install ipykernel 安装成功后，执行下面命令就可以了~\npython -m ipykernel install --user 打开Jupyter就会发现可以运行Tensorflow了！\n   ","date":1545782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545782400,"objectID":"0194b36e492a9de3af5ffa26d2f117a7","permalink":"/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/","publishdate":"2018-12-26T00:00:00Z","relpermalink":"/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/","section":"post","summary":"迈出TensorFlow世界的第一步 安装TensorFlow 鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议你跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 Anaconda，快捷高效，下载引导详见图1。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！\n 图1. 下载Anaconda  设置水土不服的Anaconda 首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过conda --version看看是否成功安装了Anaconda。一般会得到版本信息，如下所示\nconda 4.5.12 那么，Anaconda安装成功！\n下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes  创建python3.5环境 首先，由于目前TensoFlow官方Only支持python3.5版本，而且在写本文的这个时候，Anaconda官方最新版本中的python是3.7版本，所以我们需要创建一个python3.5的新环境。\n首先在系统菜单栏找到并点击Anaconda Navigator，然后选择Enviroments（如图2所示），然后点击Create创建新环境：\n 图2. Environments界面  我们命名为tensorflow，并选择python3.5的版本：\n 图3. 创建新环境窗口  安装成功后，Environments界面多了一个我们创建的命名为tensorflow的python3.5的环境，并自动预先安装一些基础的库。\n 图4. 安装成功后的python3.5环境  搞定python3.5的环境后，我们顺便在python3.5环境下安装常用的jupyter notebook和spyder。先选择Home界面，然后可以看到jupyter notebook和spyder下方均显示Install，当然就点击Install，就等着Anaconda Navigator帮我们搞定啦！安装成功后，它们下方会变成Launch（如图5所示）。\n 图5. 安装jupyter和spyder成功后的Home界面  如果要在Anaconda prompt界面启动python3.5环境，很简单，一行命令！\nconda activate tensorflow 这里的tensorflow其实是我们的python3.5环境的命名~\n 通过pip安装我们的主角TensorFlow ٩(๑\u0026gt; ₃ \u0026lt;)۶з 搞定一切基础的部分后，接下来就开始用pip安装我们TensorFlow的CPU版本了~我们先激活python3.5的环境并用pip安装tensorflow\nconda activate tensorflow pip install tensorflow 旋转跳跃~闭着眼~睁开眼后就搞定了你要的TensorFlow (●´▽｀●) 下面我们先测试一下，在激活python3.","tags":["TensorFlow"],"title":"小菜鸟的入门TensorFlow","type":"post"},{"authors":null,"categories":["Deep Learning"],"content":"\rFrom some on-line article, it is interesting that we can consider EM algorithm as some Chinese Kungfu manuals and it contains 9 levels of perspectives. With such metaphor, I can feel how this method powerful it is. Now, I want to share my view with you.\nIntroduction to the EM algorithm\rExpectation-Maximization (EM) algorithm is an important method to solve the maximum likelihood problem with latent variables in statistics. It is widely used in Machine Learning because it can simplify many difficult problems. One of the famous and classical application is gaussian mixture model.\nBasic probability theory\rLet \\(p(x|\\theta)\\) be the probability density function of random variable \\(x\\), where \\(\\theta\\) is the parameter of the density function, then we know that the basic probability property is \\[\rp(\\text{x};\\theta) \\geq 0, \\int_{-\\infty}^{+\\infty}p(\\text{x};\\theta) d\\text{x} = 1.\r\\]\nIf we take the expectation of x, we get \\[\r\\mathbb{E}[\\text{x}] = \\int\\text{x}p(\\text{x};\\theta) d\\text{x}\r\\] In the integral, we know that the \\(\\mathbb{E}[\\text{x}]\\) involves \\(\\theta\\) but not \\(\\text{x}\\).\nIf we generalize it to function and let \\(f(\\text{x})\\) be a function of \\(\\text{x}\\). Similarly, the expectation of \\(f(x)\\) is given by \\[\r\\mathbb{E}[f] = \\int f(\\text{x})p(\\text{x};\\theta) d\\text{x}\r\\]\nWith the similar result, we know that the \\(\\mathbb{E}[f]\\) involves \\(\\theta\\) but not \\(\\text{x}\\).\n\rMotivation of the EM algorithm\rAt the beginning, we denote that\n\r\\(\\text{X}\\): Set of all observed data (incomplete-data)\r\\(\\text{Z}\\): Set of all latent variables\r\\(\\theta\\): Set of all model parameters\r\\(\\{ \\text{X,Z} \\}\\): Each observation in \\(\\text{X}\\) is corresponding value of the latent variable \\(\\text{Z}\\) (complete-data)\r\rThen the log-likelihood function can be written as \\[\rL(\\text{X};\\theta) = \\ln p(\\text{X};\\theta) = \\ln \\{ \\sum_{\\text{Z}}p(\\text{X}, \\text{Z};\\theta) \\}\r\\]\nIt is too hard to straightly solve the problem with \\(\\ln\\) and \\(\\sum\\). The likelihood function for the complete data set simply takes the form \\(\\ln p(\\text{X,Z}|\\theta)\\), and we shall suppose that maximization of this complete-data log-likelihood function is straightforward.\nIn practice, we are not given the latent variable \\(\\text{Z}\\) but we know the posterior distribution \\(p(\\text{Z}|\\text{X};\\theta)\\).\n\rThe Level 1 of the EM algorithm\rIn the level 1, we just need to know the basic knowledge of EM algorithm.\nIn the \\(\\mathbb{E}\\)-step, we use the current parameter values \\(\\theta_{\\text{old}}\\) to find the posterior distribution of the latent variables given by \\(p(\\text{Z}|\\text{X};\\theta_{\\text{old}})\\).\nThen, we would use this posterior distribution to find the expectation of the complete-data log-likelihood evaluated for some general parameter value \\(\\theta\\). This expectation, denoted \\(\\mathcal{Q}(\\theta,\\theta_{\\text{old}})\\), is given by \\[\r\\mathcal{Q}(\\theta,\\theta_{\\text{old}}) = \\mathbb{E}_{\\text{Z}|\\text{X};\\theta_{\\text{old}}}[\\ln p(\\text{X,Z};\\theta)] = \\sum_{\\text{Z}} \\ln p(\\text{X,Z};\\theta)p(\\text{Z}|\\text{X};\\theta_{\\text{old}})\r\\]\nIn the \\(\\mathbb{M}\\) (Maximization) step, we determine the revised parameter estimate \\(\\theta_{\\text{new}}\\) by maximizing the function \\[\r\\theta_{\\text{new}} = \\arg \\max_\\limits{\\theta} \\mathcal{Q}(\\theta,\\theta_{\\text{old}})\r\\]\nSince the complete-data log-likelihood involves unobversed data \\(\\text{Z}\\), we use Expectation to eliminate the uncertainty, and the function \\(\\mathbb{E}_{\\text{Z}|\\text{X},\\theta_{\\text{old}}}[\\ln p(\\text{X,Z}|\\theta)]\\) does not involve \\(\\text{Z}\\) but involve \\((\\theta,\\theta_{\\text{old}})\\).\nWe can summarize the procedure as:\n\rWhile \\(\\theta_{\\text{new}} - \\theta_{old} \u0026gt; \\epsilon\\)\n\\(\\quad\\) Expectation-Step on log likelihood function: \\[\r\\mathcal{Q}(\\theta,\\theta_{\\text{old}}) = \\mathbb{E}_{\\text{Z}|\\text{X};\\theta_{\\text{old}}}[\\ln p(\\text{X,Z};\\theta)]= \\sum_{\\text{Z}} \\ln p(\\text{X,Z};\\theta)p(\\text{Z}|\\text{X};\\theta_{\\text{old}})\r\\] \\(\\quad\\) Maximization-Step on \\(\\mathcal{Q}(\\theta,\\theta_{\\text{old}})\\): \\[\r\\theta_{\\text{new}} = \\arg \\max_\\limits{\\theta} \\mathcal{Q}(\\theta,\\theta_{\\text{old}})\r\\]\n\r\rThe Level 2 of the EM algorithm\rAfter writting down the pseudocode of EM algorithm, we want to know the reason that we can use expectation to approximate the maximum log-likelihood by repeating Expectation and Maximization. In other words, we want to prove that \\[\r\\arg \\max_\\theta \\mathbb{E}_{\\text{Z}|\\text{X};\\theta_{\\text{old}}}[\\ln p(\\text{X};\\theta)] \\approx \\arg \\max_\\theta \\ln p(\\text{X};\\theta)\r\\] where the joint distribution \\(p(\\text{X}, \\text{Z};\\theta)\\) is governed by a set of parameters \\(\\theta\\).\nNext we introduce a distribution \\(q(\\text{Z})\\) defined over the latent variables.\nSince \\[\rp(\\text{X},\\text{Z};\\theta) = p(\\text{Z}|\\text{X};\\theta)p(\\text{X};\\theta)\r\\] and \\[\r\\sum_\\text{Z}q(\\text{Z}) = 1\r\\] we can get decomposition by \\[\r\\begin{align}\r\\ln p(\\text{X};\\theta) =\u0026amp;\\ \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{p(\\text{Z}|\\text{X};\\theta)}\\\\\r=\u0026amp;\\ \\ln p(\\text{X},\\text{Z};\\theta) - \\ln p(\\text{Z}|\\text{X};\\theta) + \\ln q(\\text{Z}) - \\ln q(\\text{Z})\\\\\r=\u0026amp;\\ \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})} - \\ln \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}\\\\\r=\u0026amp; \\sum_\\text{Z}q(\\text{Z}) \\{ \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})} - \\ln \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})} \\}\\\\\r=\u0026amp;\\ \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})} - \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}\\\\\r=\u0026amp;\\ \\mathcal{L}(q,\\theta) + KL(q||p)\r\\end{align}\r\\] where \\[\r\\begin{align}\r\\mathcal{L}(q,\\theta) = \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})}\\\\\rKL(q||p) = - \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}\r\\end{align}\r\\]\nWe call the \\(KL(q||p)\\) as the Kullback-Leibler divergence (KL divergence, also known as relative entropy).\nRecall that Jensen’s inequality holds for convex function \\(f(x)\\). \\[\r\\mathbb{E}[f(x)] \\geq f(\\mathbb{E}[x])\r\\]\nApplying Jensen’s inequality in KL divergence, we have \\[\r\\begin{align}\rKL(q||p) =\u0026amp; - \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})} = -\\mathbb{E}_q[\\ln\\{\\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}\\} ]\\\\\r\\geq\u0026amp; -\\ln \\mathbb{\\text{E}_q}[\\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}] = -\\ln \\sum_\\text{Z} q(\\text{Z}) \\frac{p(\\text{Z}|\\text{X};\\theta)}{q(\\text{Z})}\\\\\r=\u0026amp; -\\ln \\sum_\\text{Z} p(\\text{Z}|\\text{X};\\theta) = -\\ln 1\\\\ =\u0026amp;\\ 0\r\\end{align}\r\\]\nIf we let \\(q(\\text{Z}) = p(\\text{Z}|\\text{X};\\theta)\\), and \\(p(\\text{X},\\text{Z};\\theta) = p(\\text{Z}|\\text{X};\\theta)p(\\text{X};\\theta)\\), then \\[\r\\begin{align}\r\\mathcal{L}(q,\\theta) =\u0026amp; \\sum_\\text{Z}q(\\text{Z}) \\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})} = \\mathbb{E}_q[\\ln \\frac{p(\\text{X},\\text{Z};\\theta)}{q(\\text{Z})}]\\\\\r=\u0026amp;\\ \\mathbb{E}_{\\text{Z}|\\text{X};\\theta}[\\ln p(X;\\theta)]\r\\end{align}\r\\]\nThus, we can get the result that \\(\\ln p(\\text{X};\\theta) \\geq \\mathcal{L}(q,\\theta) = \\mathbb{E}_{\\text{Z}|\\text{X};\\theta}[\\ln p(X;\\theta)]\\), so we can say that \\(\\mathcal{L}(q,\\theta) = \\mathbb{E}_{\\text{Z}|\\text{X};\\theta}[\\ln p(X;\\theta)]\\) is the low bound of \\(\\ln p(\\text{X};\\theta)\\).\n\rFigure1. The EM algorithm involves alternatel computing a lower bound on the log likelihood for the current parameter values and then maximizing this bound to obtain the new parameter values.\r\rActually, EM algorithm is one of the special case of Minorize-Maximization (MM) algorithm, and \\(\\mathcal{L}(q,\\theta)\\) can be considered as the surrogate function in MM algorithm.\n\r\r","date":1545609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545609600,"objectID":"8ffb9edea8bf95f2a21b2f21e43bb7d1","permalink":"/post/expectation-maximization-algorithm/","publishdate":"2018-12-24T00:00:00Z","relpermalink":"/post/expectation-maximization-algorithm/","section":"post","summary":"From some on-line article, it is interesting that we can consider EM algorithm as some Chinese Kungfu manuals and it contains 9 levels of perspectives. With such metaphor, I can feel how this method powerful it is. Now, I want to share my view with you.\nIntroduction to the EM algorithm\rExpectation-Maximization (EM) algorithm is an important method to solve the maximum likelihood problem with latent variables in statistics. It is widely used in Machine Learning because it can simplify many difficult problems.","tags":["Algorithm"],"title":"Expectation-Maximization Algorithm","type":"post"},{"authors":null,"categories":["Machine Learning"],"content":"\rCoordinate Descent Framework\rAt the begining of this section, we start to discuss three different types of function.\nGiven convex, differentiable function \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\), we know \\(f(x+\\delta \\cdot e_i)\\geq f(x)\\) for all \\(\\delta\\) because \\(\\nabla f(x) = (\\frac{\\partial f}{\\partial x_1}(x),\\dots,\\frac{\\partial f}{\\partial x_n}(x)) = 0\\). Here, \\(e_i = (0,\\dots,1,\\dots,0) \\in \\mathbb{R}^n\\), the \\(i\\)th standard basis vactor.\r\r\rFigure1. Convex and differential function \\(f\\)\r\rGiven convex but not differentiable function \\(f\\), we can not found a global minimizer.\r\r\rFigure2. Convex but not differential function \\(f\\)\r\rGiven convex \\(g\\) and each convex but not differentiable \\(h_i\\), so we get \\(f(x)=g(x)+\\sum_{i=1}^n h_i(x_i)\\). In this function, the non-smooth part is called as separable.\nFor any \\(y\\), we get\r\\[\\begin{align}\rf(y) - f(x) \\geq\u0026amp; \\nabla g(x)^T (y-x) + \\sum_{i=1}^n [h_i(y_i)-h_i(x_i)]\\\\\r=\u0026amp; \\sum\\limits_{i=1}^n [\\nabla_ig(x)(y_i-x_i)+h_i(y_i)-h_i(x_i)] \\geq 0\r\\end{align}\\]\rThus, we can get global minimizer.\r\r\rFigure3. Convex, not differential but separable function \\(f\\)\r\rIf we get a function with the formula like \\(f(x) = g(x) + \\sum_{i=1}^n h_i(x_i)\\), where the \\(g\\) is convex and differentiable function, each \\(h_i\\) is convex functions, then we can use coordinate descent to find global minimizer. The procedure is following: start with some initial guess \\(x^{(0)}\\), and repeat\r\\[\\begin{align}\rx_1^{(k)} \\in\u0026amp; \\mathop{\\arg\\min}_{x_1} f(x_1,x_2^{(k-1)},x_3^{(k-1)},\\dots,x_n^{(k-1)})\\\\\rx_2^{(k)} \\in\u0026amp; \\mathop{\\arg\\min}_{x_2} f(x_1^{(k)},x_2,x_3^{(k-1)},\\dots,x_n^{(k-1)})\\\\\rx_3^{(k)} \\in\u0026amp; \\mathop{\\arg\\min}_{x_3} f(x_1^{(k)},x_2^{(k)},x_3,\\dots,x_n^{(k-1)})\\\\\r\\cdots\u0026amp; \\\\\rx_n^{(k)} \\in\u0026amp; \\mathop{\\arg\\min}_{x_n} f(x_1^{(k)},x_2^{(k)},x_3^{(k)},\\dots,x_n)\\\\\r\\end{align}\\]\rfor \\(k=1,2,3,\\dots,K\\)\nNote: after we solve for \\(x_i^{(k)}\\), we use its new value from then on.\n\rCoordinate descent for linear regression with convex penalties\r\r","date":1545264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545264000,"objectID":"a7b929a37f776a7ca16cc0156eb8ea6e","permalink":"/post/coordinate-descent-algorithm/","publishdate":"2018-12-20T00:00:00Z","relpermalink":"/post/coordinate-descent-algorithm/","section":"post","summary":"Coordinate Descent Framework\rAt the begining of this section, we start to discuss three different types of function.\nGiven convex, differentiable function \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\), we know \\(f(x+\\delta \\cdot e_i)\\geq f(x)\\) for all \\(\\delta\\) because \\(\\nabla f(x) = (\\frac{\\partial f}{\\partial x_1}(x),\\dots,\\frac{\\partial f}{\\partial x_n}(x)) = 0\\). Here, \\(e_i = (0,\\dots,1,\\dots,0) \\in \\mathbb{R}^n\\), the \\(i\\)th standard basis vactor.\r\r\rFigure1. Convex and differential function \\(f\\)\r\rGiven convex but not differentiable function \\(f\\), we can not found a global minimizer.","tags":["R","Algorithm"],"title":"Coordinate Descent Algorithm","type":"post"}]