<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on BONBON BLOG</title>
    <link>/post.html</link>
    <description>Recent content in Posts on BONBON BLOG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于Rmarkdown生成中文内容pdf的那些事</title>
      <link>/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B.html</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%85%B3%E4%BA%8Ermarkdown%E7%94%9F%E6%88%90%E4%B8%AD%E6%96%87%E5%86%85%E5%AE%B9pdf%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B.html</guid>
      <description> 缘于某人用Rmarkdown搞不出中文内容的pdf而引发一场激战之下，TT只能忍气吞声继续走上帮人帮到底的道路，于是网上搜出一大堆关于Rmarkdown生成中文pdf的麻烦事。无奈，众里寻它千百度，最终发现解决问题的YAML模板及相关的解决方案，怕在接下来的日子可能遭受同样的折磨，并以扩充Blog文章为前提，书写此文。
首先，让我们先在RStudio菜单栏选择Tools并点击Global Options。选择Sweaver并按图勾选，最后点OK~  Figure1. 可爱的Global Options窗口  然后.Rmd文件中的YAML模板如下设置：
--- title: &amp;quot;我是一个Test文档的标题&amp;quot; author: &amp;quot;我是一个Test文档的作者名称&amp;quot; date: &amp;quot;我是一个Test文档的写作日期&amp;quot; CJKmainfont: Microsoft YaHei output: pdf_document: includes: header-includes: - \usepackage{xeCJK} keep_tex: yes latex_engine: xelatex --- 注：介个模板用上了大微软的雅黑字体，如若想修改，那请继续摸索摸索。（T.T累了不想改了~）
搞定！Over！愿你的探索之路不与我一样艰辛((٩(//̀Д/́/)۶))
课外补充：
 关于Rmarkdown to pdf的美好世界
如果你也被这样的问题所困扰，那么你会发现R界的大佬谢益辉搞了个包叫rticles，直接提供template给你写中文文档。然而，无奈Tex世界的混乱，还是遇到奇奇怪怪的乱七八糟的问题，但是大佬说大家用TinyTex吧，那将提供Rmarkdown to pdf的一片美好世界。  </description>
    </item>
    
    <item>
      <title>Variational Auto-Encoder</title>
      <link>/post/variational-auto-encoder.html</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/variational-auto-encoder.html</guid>
      <description>IntroductionWe assume the observed variable \(x\) is a random sample from an unknown underlying process, whose true distribution \(p^*(x)\) is unknown. We attempt to approximate this underlying process with a chosen model \(p_{\theta}(x)\), with parameters \(\theta\): \[x\sim p_{\theta}(x)\] We always talk about learning like Deep Learning, and actually the learning is the process of searching for a value of the parameters \(\theta\) in model \(p_{\theta}(x)\), which can approximate the true distribution of the data, denoted by \(p^*(x)\).</description>
    </item>
    
    <item>
      <title>小菜鸟的入门TensorFlow</title>
      <link>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow.html</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow.html</guid>
      <description>迈出TensorFloW世界的第一步查看Windows系统下机器的GPU信息首先打开“运行”对话框并在“运行”对话框中输入“dxdiag”（如图1），此时会打开“DirextX诊断工具”窗口，再通过选择“显示”标签便可查到机器的GPU信息（如图2）。
图1. 输入dxdiag命令图2. 查看机器GPU信息安装TensorFlow鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 Anaconda，快捷高效，下载引导详见图3。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！
图3. 下载Anaconda设置水土不服的Anaconda首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过conda --version看看是否成功安装了Anaconda。一般会得到版本信息，如下所示
conda 4.5.12那么，Anaconda安装成功！
下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes通过pip安装我们的主角TensorFlow ٩(๑&amp;gt; ₃ &amp;lt;)۶з接下来就开始用pip安装我们TensorFlow的CPU版本了~ 首先，由于目前TensoFlow官方Only支持python3.5版本，所以我们用下面命令完成我们的需求。
conda create --name python35 python=3.5安装完成后会提示你
# To activate this environment, use## $ conda activate python35## To deactivate an active environment, use## $ conda deactivate所以接着我们先激活python3.</description>
    </item>
    
    <item>
      <title>Expectation-Maximization Algorithm</title>
      <link>/post/expectation-maximization-algorithm.html</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/expectation-maximization-algorithm.html</guid>
      <description>From some on-line article, it is interesting that we can consider EM algorithm as some Chinese Kungfu manuals and it contains 9 levels of perspectives. With such metaphor, I can feel how this method powerful it is. Now, I want to share my view with you.
Introduction to the EM algorithmExpectation-Maximization (EM) algorithm is an important method to solve the maximum likelihood problem with latent variables in statistics. It is widely used in Machine Learning because it can simplify many difficult problems.</description>
    </item>
    
    <item>
      <title>Coordinate Descent Algorithm</title>
      <link>/post/coordinate-descent-algorithm.html</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/coordinate-descent-algorithm.html</guid>
      <description>Coordinate Descent FrameworkAt the begining of this section, we start to discuss three different types of function.
Given convex, differentiable function \(f: \mathbb{R}^n \to \mathbb{R}\), we know \(f(x+\delta \cdot e_i)\geq f(x)\) for all \(\delta\) because \(\nabla f(x) = (\frac{\partial f}{\partial x_1}(x),\dots,\frac{\partial f}{\partial x_n}(x)) = 0\). Here, \(e_i = (0,\dots,1,\dots,0) \in \mathbb{R}^n\), the \(i\)th standard basis vactor.Figure1. Convex and differential function \(f\)Given convex but not differentiable function \(f\), we can not found a global minimizer.</description>
    </item>
    
  </channel>
</rss>