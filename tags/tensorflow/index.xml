<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TensorFlow on Bonbon Blog</title>
    <link>/tags/tensorflow/</link>
    <description>Recent content in TensorFlow on Bonbon Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 06 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TensorFlow实现YOLOv1目标检测</title>
      <link>/post/tensorflow%E5%AE%9E%E7%8E%B0yolov1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tensorflow%E5%AE%9E%E7%8E%B0yolov1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</guid>
      <description>目标检测是计算机视觉一个重要的领域，希望让计算机可以自己自动找出某张图片（某个视频的某一帧画面）中的物体，并认出它们是什么，这是一个具有挑战又有趣的任务。本文主要对YOLO(You Only Look Once)模型进行探讨并在TensorFlow上实现，YOLOv1是YOLO的第一个版本（YOLO version1），虽然它的目标检测效果不咋滴，但是现在YOLO进化到了第三个版本了，是一个极其强大的工具。为了更好的学习YOLOV3，那也需要领会它前辈YOLOv1的精髓所在。YOLOv1的作者有四个大佬，Joseph Redmon大佬喜欢用C语言，他们也用C语言搭建Darknet并实现了YOLOv1，这也让众多YOLO信徒不知如何用TensorFlow来领悟其中的奥妙。github找到零零散散几个有关于YOLOv1的，但是大多数只有检测过程，而没有训练过程。几番周折，找到了既有训练又能检测的代码。本文参照hizhangp的Github仓库代码，对模型进行介绍和探讨，同时对代码进行解读并实际完成目标检测。
You Only Look Once, 你不要看我第二次（//▽//） YOLOv1采用一个单独的CNN模型实现end-to-end的目标检测，它的思想正如它paper的标题一般，你只看一次，就能看出图片中有什么东西，达到跟人类基本一样的探索功能。就像你看到下面这只可爱的黄色电气鼠，一瞄就知道是皮卡丘！
 图1. 我是谁？皮卡丘！  YOLO(本文指YOLO version1)的大体检测框架是：首先通过转换图像为\(448\times 448\)大小的输入，在图像输入之后YOLO会将其分为\(S\times S\)的grid cell（小格子）。每一个grid cell会产生B个边界框（Bounding Box），每个Bounding Box会附带一个置信度值。原文中设定了每张图像分为\(7\times 7\)的grid cell，每个grid cell产生2个Bounding Boxes，那所有的grid cell总共会生成98($772)个边界框；另外原文设定了检测物体的类别数为20。需要注意的是，在原文中多次出现exist和appear的词，表示grid cell中包含了object，但其实更准确的是表示object的中心点出现在这个grid cell中。在完成训练阶段之后，通过非极大值抑制来去除多余的边界框并完成检测（后面会补充介绍非极大值抑制的内容）~
 图2. YOLO检测系统细节图  YOLO模型训练阶段（Traning）解析 YOLO检测网络包含了24个卷积层和2个全连接层，其中也运用了最大池化层，如图3所示：
 图3. YOLO检测网络图  其中激活函数使用了leaky relu函数： \[ \phi(x) = \left\{ \begin{array}{l} x,\quad\ \ \text{if}\ \ x&amp;gt;0\\ 0.1x,\ \text{otherwise} \end{array} \right. \]
最终模型网络输出的是一个\(7\times 7\times 30\)的张量（Tensor），这里我们可以看作49(\(7\times 7\))个grid cells，其中每个grid cell中涉及30个通道（channel）。这30个channels中有2组对应2个Bounding Boxes的信息（总共占用10(\(2\times 5\))个channels），剩下的20个channels对应的是20个检测类的概率。
前5个channels（张量的第1-5d的位置）中的参数分别是第一个Bounding Box（黄色边界框）的四个坐标值以及相应的置信度。这四个坐标(\(x,y,w,h\))中(\(x,y\))是物体中心点相对于左上角的坐标值，(\(w,h\))是Bounding Box的宽和高，以中心点坐标就可以确定Bounding Box的大小。</description>
    </item>
    
    <item>
      <title>TensorFlow&#43;Keras实现YOLOv3目标检测</title>
      <link>/post/tensorflow-keras%E5%AE%9E%E7%8E%B0yolov3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tensorflow-keras%E5%AE%9E%E7%8E%B0yolov3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</guid>
      <description>用Git下载keras-yolo3库 首先你电脑如果安装了Git，那在你希望存储的文件夹目录中打开Git Bash，接着输入一行命令就可以了~
$ git clone https://github.com/qqwweee/keras-yolo3.git Git会很快帮你下载整个仓库(Repository)~
那如果你没有安装Git也没关系，打开Github的keras-yolo3仓库，点击Clone or download后再点击Download ZIP，也是一样的。
 用pip下Python库 Github上作者qqwweee已经把代码都完成了，所以我们只需要确保所需的库也安装了，就万事俱备，只欠东风！
 TensorFlow
 Keras
 h5py
 OpenCV  通常安装库的方法会选用pip来下载安装，打开Anaconda prompt之后输入命令：
activate python35 # 激活python3.5环境 pip install tensorflow pip install keras pip install h5py pip install opencv-python 完成安装后就开始正题了！
 YOLO的实现 下载yolov3.weight和格式变换 我们可以直接从YOLO官网可以下载预训练的权重yolov3.weight，也可以通过命令行进行下载；
先打开Anaconda Prompt（或者cmd）并路径更新到当前keras-yolo3所在文件夹路径，通过下面命令行可完成对yolov3.weight的下载，并转成TensorFlow所支持的h5文件。
wget https://pjreddie.com/media/files/yolov3.weights python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5  测试demo图像文件 如果想对某张图片进行检测，可以将这张图片放在当前keras-yolo3所在文件夹，再通过Anaconda Prompt运行下面命令
python yolo_vedio.py --image 命令行运行后会弹出“Input image filename:”，输入指定图片文件即可。
举个栗子~
 大家一起放风筝~  YOLOv3的Output效果不错！！</description>
    </item>
    
    <item>
      <title>卷积神经网络 Convolutional Neural Networks</title>
      <link>/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/</guid>
      <description>简介Convolutional Neural Networks的中文名叫卷积神经网络，当然英文简称直接为CNN，它的创始人是著名的计算机科学家Yann LeCun，CNN和RNN（Recurrent Neural Networks）可以说是深度学习领域最常提及的两种网络模型。本篇博客参照知乎上问题“CNN(卷积神经网络)是什么？有入门简介或文章吗？”的回答来进行介绍~
Convolutional Neural Networks开始正文！CNN的“卷积”介绍我们假设神经网络的输入是一张彩色的图像，那通常我们输入的是\(n\times m\times 3\)的RGB图像，下面图中是\(4\times 4\times 3\)RGB图像的示例；其中的数字代表着图片的原始像素值。
图1. \(4\times 4\times 3\)RGB图像卷积核是CNN的一个重要部分，卷积则是CNN的一个重要步骤。
首先，假设我们选取的卷积核为： \[\begin{vmatrix}1 &amp;amp; 0 &amp;amp; 1\\0 &amp;amp; 1 &amp;amp; 0\\1 &amp;amp; 0 &amp;amp; 1\end{vmatrix}\]我们会从原始图像的左上角开始，选取和卷积核大小相同的区域。
通过水平和垂直移动不断获得新的区域，我们假设移动的步长为1，重复上面的步骤，我们可以一个新的矩阵 \[\begin{vmatrix}4 &amp;amp; 3 &amp;amp; 4\\2 &amp;amp; 4 &amp;amp; 3\\2 &amp;amp; 3 &amp;amp; 4\end{vmatrix}\]图2.</description>
    </item>
    
    <item>
      <title>Variational Auto-Encoder</title>
      <link>/post/variational-auto-encoder/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/variational-auto-encoder/</guid>
      <description>IntroductionWe assume the observed variable \(x\) is a random sample from an unknown underlying process, whose true distribution \(p^*(x)\) is unknown. We attempt to approximate this underlying process with a chosen model \(p_{\theta}(x)\), with parameters \(\theta\): \[x\sim p_{\theta}(x)\] We always talk about learning like Deep Learning, and actually the learning is the process of searching for a value of the parameters \(\theta\) in model \(p_{\theta}(x)\), which can approximate the true distribution of the data, denoted by \(p^*(x)\).</description>
    </item>
    
    <item>
      <title>小菜鸟的入门TensorFlow</title>
      <link>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/</guid>
      <description>迈出TensorFlow世界的第一步 安装TensorFlow 鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议你跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 Anaconda，快捷高效，下载引导详见图1。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！
 图1. 下载Anaconda  设置水土不服的Anaconda 首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过conda --version看看是否成功安装了Anaconda。一般会得到版本信息，如下所示
conda 4.5.12 那么，Anaconda安装成功！
下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes  创建python3.5环境 首先，由于目前TensoFlow官方Only支持python3.5版本，而且在写本文的这个时候，Anaconda官方最新版本中的python是3.7版本，所以我们需要创建一个python3.5的新环境。
首先在系统菜单栏找到并点击Anaconda Navigator，然后选择Enviroments（如图2所示），然后点击Create创建新环境：
 图2. Environments界面  我们命名为tensorflow，并选择python3.5的版本：
 图3. 创建新环境窗口  安装成功后，Environments界面多了一个我们创建的命名为tensorflow的python3.5的环境，并自动预先安装一些基础的库。
 图4. 安装成功后的python3.5环境  搞定python3.5的环境后，我们顺便在python3.5环境下安装常用的jupyter notebook和spyder。先选择Home界面，然后可以看到jupyter notebook和spyder下方均显示Install，当然就点击Install，就等着Anaconda Navigator帮我们搞定啦！安装成功后，它们下方会变成Launch（如图5所示）。
 图5. 安装jupyter和spyder成功后的Home界面  如果要在Anaconda prompt界面启动python3.5环境，很简单，一行命令！
conda activate tensorflow 这里的tensorflow其实是我们的python3.5环境的命名~
 通过pip安装我们的主角TensorFlow ٩(๑&amp;gt; ₃ &amp;lt;)۶з 搞定一切基础的部分后，接下来就开始用pip安装我们TensorFlow的CPU版本了~我们先激活python3.5的环境并用pip安装tensorflow
conda activate tensorflow pip install tensorflow 旋转跳跃~闭着眼~睁开眼后就搞定了你要的TensorFlow (●´▽｀●) 下面我们先测试一下，在激活python3.</description>
    </item>
    
  </channel>
</rss>