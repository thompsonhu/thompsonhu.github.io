

<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.3.0">
  <meta name="generator" content="Hugo 0.52" />
  <meta name="author" content="Thompson Hu">

  
  
  
  
    
  
  <meta name="description" content="">

  
  <link rel="alternate" hreflang="en-us" href="../../categories/deep-learning/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="../../styles.css">
  

  
  
  

  
  <link rel="alternate" href="../../categories/deep-learning/index.xml" type="application/rss+xml" title="Bonbon Blog">
  <link rel="feed" href="../../categories/deep-learning/index.xml" type="application/rss+xml" title="Bonbon Blog">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="../../categories/deep-learning/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Bonbon Blog">
  <meta property="og:url" content="/categories/deep-learning/">
  <meta property="og:title" content="Deep Learning | Bonbon Blog">
  <meta property="og:description" content=""><meta property="og:image" content="/img/portrait.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2019-02-01T00:00:00&#43;00:00">
  

  

  

  <title>Deep Learning | Bonbon Blog</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="../../">Bonbon Blog</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>















  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1 itemprop="name">Deep Learning</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
  <div>
    <h2><a href="../../post/recurrent-nerual-network-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">Recurrent Nerual Network 循环神经网络</a></h2>
    <div class="article-style">
      
      前言 循环神经网络（Recurrent Nerual Network, RNN）在Deep Learning领域中是一个经典有很重要的神经网络模型。RNN是在自然语言处理（Natural Language Processing, NLP）领域最先被使用发展起来的。在NLP中通常会处理一些文字句子，比如我们想做一个机器翻译，把中文转换成英文。初中生可能在翻译的时候只会逐个中文词翻译成英文，但高中生就可能会对翻译中的词进行调整，结合前后的词汇，那我们也希望机器这样做。
假设有一段对话：
A：你好吗？
B：我很好。
我们想让机器翻译成英文，对于A而言，机器可能在一些训练后很容易翻译成“How are you?”，但对于B可能就翻译成了“I’m ok.”。那就相当尴尬了~（想起某军的Are you ok?╭(●｀∀´●)╯）机器其实需要参考A问了什么，再来对B的回答进行翻译，才能获得比较好的回答翻译“I’m fine.”
RNN就是专门解决了处理序列化数据的问题，像上面这样的小例子。
 简单循环神经网络 对于简单RNN，它由输入层，一个隐藏层和一个输出层构成的，像这样子：  图1. 简单RNN示意图  先看左边的图时会觉得不能理解，但是如果将其展开得到右边的图，就比较好理解了。在\(t\)时刻，\(x_t\)作为输入的同时，还有上一个时刻隐藏层的\(h_{t-1}\)，以\(V\)为权重作为第\(t\)时刻的输入。我们用计算公式来表示，可以表示为： \[ h_t = f (U x_t + V h_{t-1})\\ o_t = \sigma (W h_t) \] 其中\(f\)和\(\sigma\)是激活函数（Activation function）。
如果将上面两个式子联合可以得到： \[ \begin{align} o_t &amp;= \sigma (W h_t)\\ &amp;= \sigma (W f (U x_t + V h_{t-1}))\\ &amp;= \sigma (W f (U x_t + V f (U x_{t-1} + V h_{t-2})))\\ &amp;=\ .
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks/">卷积神经网络 Convolutional Neural Networks</a></h2>
    <div class="article-style">
      
      简介 Convolutional Neural Networks的中文名叫卷积神经网络，当然英文简称直接为CNN，它的创始人是著名的计算机科学家Yann LeCun，CNN和RNN（Recurrent Neural Networks）可以说是深度学习领域最常提及的两种网络模型。本篇博客参照知乎上问题“CNN(卷积神经网络)是什么？有入门简介或文章吗？”的回答来进行介绍~
 Convolutional Neural Networks开始正文！ CNN的“卷积”介绍 我们假设神经网络的输入是一张彩色的图像，那通常我们输入的是\(n\times m\times 3\)的RGB图像，下面图中是\(4\times 4\times 3\)RGB图像的示例；其中的数字代表着图片的原始像素值。
 图1. \(4\times 4\times 3\)RGB图像  卷积核是CNN的一个重要部分，卷积则是CNN的一个重要步骤。
 首先，假设我们选取的卷积核为： \[ \begin{vmatrix} 1 &amp; 0 &amp; 1\\ 0 &amp; 1 &amp; 0\\ 1 &amp; 0 &amp; 1 \end{vmatrix} \]  我们会从原始图像的左上角开始，选取和卷积核大小相同的区域。
 通过水平和垂直移动不断获得新的区域，我们假设移动的步长为1，重复上面的步骤，我们可以一个新的矩阵 \[ \begin{vmatrix} 4 &amp; 3 &amp; 4\\ 2 &amp; 4 &amp; 3\\ 2 &amp; 3 &amp; 4 \end{vmatrix} \]   图2.
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%BA%8Cpart/">生成对抗网络的第二Part</a></h2>
    <div class="article-style">
      
      我们认为每张图片对应的是一个高维向量，我们希望能找出这一类图片所在的图像空间的分布\(P\)，GAN的目的其实就是在寻找这个分布\(P\)。
传统的方法我们会想到用最大似然估计：
首先给定一些样本数据，可以得到它的分布\(P_{data}(x)\)；接着我们假定有一个由参数\(\theta\)决定的分布\(P_G(x;\theta)\)；我们希望能够找到\(\theta\)，满足分布\(P_G(x;\theta)\)尽可能靠近分布\(P_{data}(x)\)；假设\(P_G(x;\theta)\)是高斯分布（正态分布），那\(\theta\)就是均值和方差。
从分布\(P_{data}(x)\)中进行抽样获得一组样本数据\(\{x_1,x_2,\dots,x_m\}\)，我们可以得到似然值的表达式 \[L = \prod_{i=1}^{m} P_G(x^i;\theta)\]我们希望能够找到\(\theta^*\)能够使得似然值\(L\)最大。
最大似然估计与最小KL散度的等价性通过对\(L\)取对数，我们可以得到对数似然值，同时\(\theta^*\)可以通过下式得到： \[\begin{align}\theta^* &amp;=\ \arg \max_{\theta} \log L\\ &amp;=\ \arg \max_{\theta} \log \prod_{i=1}^{m} P_G(x^i;\theta)\\&amp;=\ \arg \max_{\theta} \sum_{i=1}^m \log P_G(x^i;\theta)\end{align}\]
由于样本\(\{x^1,x^2,\dots,x^m\}\)是随机抽取来自于分布\(P_{data}(x)\)，上式可以近似求\(\log P_G(x;\theta)\)的期望的最大点，可以表示为 \[\begin{align}\theta^* &amp;\approx\ \arg \max_{\theta} E_{x\sim P_{data}}[\log P_G(x;\theta)]\\&amp;=\ \arg \max_{\theta} \int\limits_x P_{data}(x) \log P_G(x;\theta) dx\end{align}\]
从式子中知道，我们所求的\(\theta^*\)只跟分布\(P_G(x;\theta)\)相关，我们可以在后面加上一项\(-\int\limits_x P_{data}(x) \log P_{data}(x)dx\)，这不影响求最大化下对应得\(\theta^*\)，那么由上式就可以得到 \[\begin{align}\theta^* &amp;\approx\ \arg \max_{\theta} \int\limits_x P_{data}(x) \log P_G(x;\theta) dx - \int\limits_x P_{data}(x) \log P_{data}(x)dx\\&amp;=\ \arg \max_{\theta} \int\limits_x P_{data}(x) \Big[\log P_G(x;\theta) - \log P_{data}(x)\Big] dx\\&amp;=\ \arg \min_{\theta} \int\limits_x P_{data}(x) \Big[\log P_{data}(x) - \log P_G(x;\theta)\Big] dx\\&amp;=\ \arg \min_{\theta} \int\limits_x P_{data}(x) \log \frac{P_{data}(x)}{P_G(x;\theta)} dx\\&amp;=\ \arg \min_{\theta} KL(P_{data}||P_G)\end{align}\]
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AC%AC%E4%B8%80part/">生成对抗网络的第一Part</a></h2>
    <div class="article-style">
      
      从知乎上了解到台大有位著名的教授李宏毅超级会讲Generative Adversarial Networks, GAN技术，所以慕名而到Youtube找到他的上课视频成为他的“课外学生”。李教授真的厉害，形象生动地讲解GAN的各个知识点。那么，我把我学到的整理为一篇博客，尝试作为一名“GAN路上的导游”。
Yann LeCun是Facebook的AI研究部门的Director，同时也是NYU（New York University）的一位教授，维基百科上是这么介绍他：
He is the Chief Artificial Intelligence Scientist at Facebook AI Research, and he is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNN), and is a founding father of convolutional nets.
做Deep Learning的人多多少少会听过这个名字，他曾经这样回答了Quora论坛上的一个问题（What are some recent and potentially upcoming breakthroughs in unsupervised learning?）：
Adversarial training is the coolest thing since sliced bread.
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">深度神经网络基础</a></h2>
    <div class="article-style">
      
      神经元及神经网络基础结构  图1. 神经元的组成（源自维基百科）  神经元这个图大多数理科生在高中生物课本都学过~神经网络则由许许多多的神经元所组成，通常一个神经元具有多个树突，主要用来接收消息；轴突只有一条，相当于我们定义的一个计算过程；而轴突尾部的许许多多轴突末梢，将传递信息给其他神经元。
 图2. 神经网络基础结构  通常这里的非线性函数会用上各式各样的激活函数，比如Sigmoid函数，tanh函数和ReLu函数。
Sigmoid函数
\[f(z) = \frac{1}{1+e^{-z}}\] tanh函数
\[f(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}\] ReLu函数
\[f(z) = \max(0,z)\]
 神经网络基础认知 我们把许多神经元组合起来就可以得到一个神经网络，由于有输入的数据和我们想得到的输出数据，便会有“输入层”（Input layer）和“输出层”（Output layer）；中间的神经元则组成了“隐藏层”（Hidden layer）。在下面图3中，输入层有3个神经元，隐藏层有4个神经元，输出层有2个神经元。在实际情况中，输入层和输出层通常是固定的，而隐藏层的层数和节点数则可以自由调节。  图3. 神经网络基础层级结构  我们假设一个全连接的网络结构，其中隐藏层只有一层。另外，假设输入层和隐藏层之间的边的权值构成的矩阵为 \[ \left [ \begin{matrix} w_{11} &amp; w_{12} &amp; w_{13} \\ w_{21} &amp; w_{22} &amp; w_{23} \\ w_{31} &amp; w_{32} &amp; w_{33} \end{matrix} \right ] \] 其中，第一列的\(w_{11}, w_{21}, w_{31}\)代表的是输入层的点\(x_1\)分别连接隐藏层的三个节点的边的权值；第二列的\(w_{12}, w_{22}, w_{32}\)代表的是输入层的点\(x_2\)分别连接隐藏层的三个节点的边的权值；第三列的\(w_{13}, w_{23}, w_{33}\)代表的是输入层的点\(x_3\)分别连接隐藏层的三个节点的边的权值。
图中的“+1”点代表我们添加了一个值b，称其为偏置项。那么，隐藏层的节点可以由下计算得到： \[ \begin{align} a_1 = w_{11}\times x_1 + w_{12}\times x_2 + w_{13}\times x_3 + b_1\\ a_2 = w_{21}\times x_1 + w_{22}\times x_2 + w_{23}\times x_3 + b_2\\ a_3 = w_{31}\times x_1 + w_{32}\times x_2 + w_{33}\times x_3 + b_3 \end{align} \tag{1} \] 由于线性计算的表现能力比较差，所以考虑用非线性函数进行计算，即使用激活函数\(f(\cdot)\)（前面已提及）。（1）式可以变换为（2）式： \[ \begin{align} a_1 = f(w_{11}\times x_1 + w_{12}\times x_2 + w_{13}\times x_3 + b_1)\\ a_2 = f(w_{21}\times x_1 + w_{22}\times x_2 + w_{23}\times x_3 + b_2)\\ a_3 = f(w_{31}\times x_1 + w_{32}\times x_2 + w_{33}\times x_3 + b_3) \end{align} \tag{2} \] 将（2）式改写为矩阵运算形式（3）式： \[ \begin{align} \boldsymbol{a} = f \begin{pmatrix} \begin{pmatrix} w_{11},w_{12},w_{13}\\w_{21},w_{22},w_{23}\\w_{31},w_{32},w_{33} \end{pmatrix} \begin{pmatrix} x_1\\x_2\\x_3 \end{pmatrix} + \begin{pmatrix} b_1\\b_2\\b_3 \end{pmatrix} \end{pmatrix} = f(\boldsymbol{W}x+\boldsymbol{B}) \end{align} \tag{3} \]
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/variational-auto-encoder/">Variational Auto-Encoder</a></h2>
    <div class="article-style">
      
      IntroductionWe assume the observed variable \(x\) is a random sample from an unknown underlying process, whose true distribution \(p^*(x)\) is unknown. We attempt to approximate this underlying process with a chosen model \(p_{\theta}(x)\), with parameters \(\theta\): \[x\sim p_{\theta}(x)\] We always talk about learning like Deep Learning, and actually the learning is the process of searching for a value of the parameters \(\theta\) in model \(p_{\theta}(x)\), which can approximate the true distribution of the data, denoted by \(p^*(x)\).
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/%E5%B0%8F%E8%8F%9C%E9%B8%9F%E7%9A%84%E5%85%A5%E9%97%A8tensorflow/">小菜鸟的入门TensorFlow</a></h2>
    <div class="article-style">
      
      迈出TensorFlow世界的第一步 安装TensorFlow 鉴于python3更高级（传闻python2最终会被淘汰，所以希望选择能陪伴更久的工具:)），本文中会以python3为基准，屏幕前的读者你！也建议你跟我用上python3！另外，如果你刚起步使用python的话，那建议你直接下载 Anaconda，快捷高效，下载引导详见图1。Anaconda会帮助我们省去下载很多库的时间，把时间留给TensorFlow吧！
 图1. 下载Anaconda  设置水土不服的Anaconda 首先，在安装Anaconda后，先打开Anaconda Prompt（一般在你的应用目录可以找到），打开后是一个跟CMD一样黑乎乎的界面 ╮(๑•́ ₃•̀๑)╭ 打开后呢~通过conda --version看看是否成功安装了Anaconda。一般会得到版本信息，如下所示
conda 4.5.12 那么，Anaconda安装成功！
下一步我们设置下Anaconda的仓库(Repository)镜像，因为默认连接的是境外镜像地址，会超慢（我记得我当时只有10kb的网速T_T），我们把镜像地址改为境内的清华大学开源软件镜像站，所以通过下面指令就可以提高你的下载速度(´•灬•‘)。
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes  创建python3.5环境 首先，由于目前TensoFlow官方Only支持python3.5版本，而且在写本文的这个时候，Anaconda官方最新版本中的python是3.7版本，所以我们需要创建一个python3.5的新环境。
首先在系统菜单栏找到并点击Anaconda Navigator，然后选择Enviroments（如图2所示），然后点击Create创建新环境：
 图2. Environments界面  我们命名为tensorflow，并选择python3.5的版本：
 图3. 创建新环境窗口  安装成功后，Environments界面多了一个我们创建的命名为tensorflow的python3.5的环境，并自动预先安装一些基础的库。
 图4. 安装成功后的python3.5环境  搞定python3.5的环境后，我们顺便在python3.5环境下安装常用的jupyter notebook和spyder。先选择Home界面，然后可以看到jupyter notebook和spyder下方均显示Install，当然就点击Install，就等着Anaconda Navigator帮我们搞定啦！安装成功后，它们下方会变成Launch（如图5所示）。
 图5. 安装jupyter和spyder成功后的Home界面  如果要在Anaconda prompt界面启动python3.5环境，很简单，一行命令！
conda activate tensorflow 这里的tensorflow其实是我们的python3.5环境的命名~
 通过pip安装我们的主角TensorFlow ٩(๑&gt; ₃ &lt;)۶з 搞定一切基础的部分后，接下来就开始用pip安装我们TensorFlow的CPU版本了~我们先激活python3.5的环境并用pip安装tensorflow
conda activate tensorflow pip install tensorflow 旋转跳跃~闭着眼~睁开眼后就搞定了你要的TensorFlow (●´▽｀●) 下面我们先测试一下，在激活python3.
      
    </div>
  </div>
  
  <div>
    <h2><a href="../../post/expectation-maximization-algorithm/">Expectation-Maximization Algorithm</a></h2>
    <div class="article-style">
      
      From some on-line article, it is interesting that we can consider EM algorithm as some Chinese Kungfu manuals and it contains 9 levels of perspectives. With such metaphor, I can feel how this method powerful it is. Now, I want to share my view with you.
Introduction to the EM algorithmExpectation-Maximization (EM) algorithm is an important method to solve the maximum likelihood problem with latent variables in statistics. It is widely used in Machine Learning because it can simplify many difficult problems.
      
    </div>
  </div>
  

  

</div>
<div class="container">
  <footer class="site-footer">
  
  <p class="powered-by">
    <a href="../../privacy/">Made by Thompson</a>
  </p>
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="../../js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//thompsonhu.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="../../js/academic.min.70f0041f5a24c6a675ac218c98d7ef71.js"></script>

    

  </body>
</html>



